{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFM Tensorflow Parameter Server on SageMaker Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this sample, we will demo how to run a deepfm sample code in tensorflow parameter server on sagemaker\n",
    "\n",
    "Notice:\n",
    "\n",
    "1. Dataset format is TFRecord\n",
    "\n",
    "2. This model training we will use **CPU** instances based on our experience, DeepFM script TF PS on CPU will more effective and saving cost. \n",
    "\n",
    "3. Using [SageMaker Python SDK 2.x](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "int(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面用多个spot实例进行parameter server方式的分布式训练。\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "import time\n",
    "import os\n",
    "\n",
    "checkpoint_s3_uri = 's3://sagemaker-us-west-2-169088282855/deepfm-checkpoint' #Change to your own path if you want to save ckpt during training\n",
    "checkpoint_local_path = '/opt/ml/checkpoints'\n",
    "model_dir = 's3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt/{}'.format(int(time.time()))\n",
    "output_path= 's3://sagemaker-us-west-2-169088282855/deepfm-2021'\n",
    "\n",
    "training_channel_name = 'training'\n",
    "evaluation_channel_name = 'evaluation'\n",
    "\n",
    "train_instance_type = 'ml.c5.18xlarge'\n",
    "train_instance_count= 2\n",
    "\n",
    "train_use_spot_instances = True\n",
    "enable_s3_shard = True\n",
    "\n",
    "train_max_run=36000*2\n",
    "train_max_wait = 72000 if train_use_spot_instances else None\n",
    "\n",
    "distributions={'parameter_server': {'enabled': True}}\n",
    "\n",
    "deep_layer = '128,64,32'\n",
    "\n",
    "batch_size = 1024\n",
    "feature_size = 117581\n",
    "\n",
    "base_job_name='tf-scriptmode-deepfm'\n",
    "\n",
    "hyperparameters = {'servable_model_dir': '/opt/ml/model', 'training_data_dir': '/opt/ml/input/data/training/',\n",
    "                   'val_data_dir': '/opt/ml/input/data/evaluation/', 'log_steps': 10, 'num_epochs': 10, \n",
    "                   'field_size': 39, 'feature_size': feature_size, 'deep_layers': deep_layer,\n",
    "                   'perform_shuffle': 0, 'batch_size': batch_size, 'pipe_mode': 0, 'enable_s3_shard': enable_s3_shard,\n",
    "                   'training_channel_name': training_channel_name, 'evaluation_channel_name': evaluation_channel_name\n",
    "                  }\n",
    "\n",
    "estimator = TensorFlow(\n",
    "                       #source_dir='./',\n",
    "                       entry_point='DeepFM-dist-ps-for-multipleCPU-multiInstance.py',\n",
    "                       model_dir=model_dir,\n",
    "                       #checkpoint_s3_uri = checkpoint_s3_uri,\n",
    "                       #checkpoint_local_path = checkpoint_local_path,\n",
    "                       output_path= output_path,\n",
    "                       instance_type=train_instance_type,\n",
    "                       instance_count=train_instance_count,\n",
    "                       #volume_size = 500,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       base_job_name=base_job_name,\n",
    "                       framework_version='1.14',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True,\n",
    "                       #input_mode='Pipe',\n",
    "                       distribution=distributions,\n",
    "                       use_spot_instances=train_use_spot_instances,\n",
    "                       max_wait=train_max_wait,\n",
    "                       max_run=train_max_run,\n",
    "                       debugger_hook_config = False,\n",
    "                       disable_profiler=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-20 14:41:52 Starting - Starting the training job...\n",
      "2021-02-20 14:41:54 Starting - Launching requested ML instances......\n",
      "2021-02-20 14:43:01 Starting - Preparing the instances for training......\n",
      "2021-02-20 14:44:12 Downloading - Downloading input data...\n",
      "2021-02-20 14:44:46 Training - Training image download completed. Training in progress..\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mWARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34mW0220 14:44:49.451177 139656046491392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0220 14:44:49.451533 139656046491392 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mWARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34mW0220 14:44:52.806430 139959645521664 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:453: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0220 14:44:52.806658 139959645521664 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:453: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0220 14:44:52.806736 139959645521664 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:454: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\u001b[0m\n",
      "\u001b[34m['DeepFM-dist-ps-for-multipleCPU-multiInstance.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', 's3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/']\u001b[0m\n",
      "\u001b[34mchannel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34mfirst channel evaluation\u001b[0m\n",
      "\u001b[34mlast channel name training\u001b[0m\n",
      "\u001b[34mLD_LIBRARY_PATH is as following:  /usr/local/openmpi/lib:\u001b[0m\n",
      "\u001b[34mtask_type  train\u001b[0m\n",
      "\u001b[34mmodel_dir  s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\u001b[0m\n",
      "\u001b[34mtraining_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34mval_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34mnum_epochs  10\u001b[0m\n",
      "\u001b[34mfeature_size  117581\u001b[0m\n",
      "\u001b[34mfield_size  39\u001b[0m\n",
      "\u001b[34membedding_size  32\u001b[0m\n",
      "\u001b[34mbatch_size  1024\u001b[0m\n",
      "\u001b[34mdeep_layers  128,64,32\u001b[0m\n",
      "\u001b[34mdropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34mloss_type  log_loss\u001b[0m\n",
      "\u001b[34moptimizer  Adam\u001b[0m\n",
      "\u001b[34mlearning_rate  0.0005\u001b[0m\n",
      "\u001b[34mbatch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34mbatch_norm  False\u001b[0m\n",
      "\u001b[34ml2_reg  0.0001\u001b[0m\n",
      "\u001b[34mtr_files: ['/opt/ml/input/data/training/data-1/train.tfrecords', '/opt/ml/input/data/training/data-3/train.tfrecords']\u001b[0m\n",
      "\u001b[34mva_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[34mte_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[34mcurrent host is  algo-1\u001b[0m\n",
      "\u001b[34mhost is  ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34mW0220 14:44:52.808205 139959645521664 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:414: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34mI0220 14:44:52.808453 139959645521664 run_config.py:528] TF_CONFIG environment variable: {'cluster': {'master': ['algo-1:2222'], 'ps': ['algo-1:2223', 'algo-2:2223'], 'worker': ['algo-2:2222']}, 'environment': 'cloud', 'task': {'index': 0, 'type': 'master'}}\u001b[0m\n",
      "\u001b[34mI0220 14:44:52.809236 139959645521664 estimator.py:209] Using config: {'_model_dir': 's3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"CPU\"\n",
      "  value: 72\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mintra_op_parallelism_threads: 72\u001b[0m\n",
      "\u001b[34minter_op_parallelism_threads: 72\u001b[0m\n",
      "\u001b[34m, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4a6787b2b0>, '_task_type': 'master', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://algo-1:2222', '_evaluation_master': '', '_num_ps_replicas': 2, '_num_worker_replicas': 2, '_is_chief': True}\u001b[0m\n",
      "\u001b[34mI0220 14:44:52.810229 139959645521664 estimator_training.py:186] Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[34mI0220 14:44:52.810545 139959645521664 training.py:744] Start Tensorflow server.\n",
      "\u001b[0m\n",
      "\u001b[34mUser settings:\n",
      "\n",
      "   KMP_AFFINITY=verbose,disabled\n",
      "   KMP_BLOCKTIME=1\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=72\n",
      "\u001b[0m\n",
      "\u001b[34mEffective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=288\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=1\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_HAND_THREAD=false\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=false\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_FORKJOIN_FRAMES=true\n",
      "   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_INIT_WAIT=2048\n",
      "   KMP_ITT_PREPARE_DELAY=0\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NEXT_WAIT=1024\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=4M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=72\n",
      "   KMP_TOPOLOGY_METHOD=default\n",
      "   KMP_USER_LEVEL_MWAIT=false\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED=false\n",
      "   OMP_NUM_THREADS='72'\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='false'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=4M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_TOOL=enabled\n",
      "   OMP_TOOL_LIBRARIES: value is not defined\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,disabled'\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[35mW0220 14:44:52.711564 139869837289216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 14:44:52.711985 139869837289216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0220 14:44:52.873958 139959645521664 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34mW0220 14:44:52.920690 139959645521664 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:81: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0220 14:44:52.920882 139959645521664 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:83: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0220 14:44:52.934716 139959645521664 deprecation.py:323] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:131: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\u001b[0m\n",
      "\u001b[34mI0220 14:44:52.948242 139959645521664 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mW0220 14:44:52.948384 139959645521664 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:166: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0220 14:44:52.951648 139959645521664 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34mW0220 14:44:52.964566 139959645521664 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:177: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0220 14:44:53.216451 139959645521664 deprecation.py:506] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:218: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34mW0220 14:44:53.289506 139959645521664 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:235: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0220 14:44:53.291785 139959645521664 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mW0220 14:44:53.301468 139959645521664 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:250: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0220 14:44:53.360213 139959645521664 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:809: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mDeprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34mW0220 14:44:53.393607 139959645521664 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:261: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0220 14:44:53.393791 139959645521664 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:269: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[34mI0220 14:44:53.750907 139959645521664 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI0220 14:44:53.752212 139959645521664 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mI0220 14:44:54.432891 139959645521664 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34mW0220 14:44:54.531927 139959645521664 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1282: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse standard file APIs to check for files with this prefix.\u001b[0m\n",
      "\u001b[34mI0220 14:44:54.619566 139959645521664 saver.py:1286] Restoring parameters from s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt/model.ckpt-7800\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35mWARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[35mW0220 14:44:57.053470 139920681113344 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:453: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 14:44:57.053692 139920681113344 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:453: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 14:44:57.053772 139920681113344 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:454: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\u001b[0m\n",
      "\u001b[35m['DeepFM-dist-ps-for-multipleCPU-multiInstance.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', 's3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/']\u001b[0m\n",
      "\u001b[35mchannel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[35mfirst channel evaluation\u001b[0m\n",
      "\u001b[35mlast channel name training\u001b[0m\n",
      "\u001b[35mLD_LIBRARY_PATH is as following:  /usr/local/openmpi/lib:\u001b[0m\n",
      "\u001b[35mtask_type  train\u001b[0m\n",
      "\u001b[35mmodel_dir  s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\u001b[0m\n",
      "\u001b[35mtraining_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[35mval_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[35mnum_epochs  10\u001b[0m\n",
      "\u001b[35mfeature_size  117581\u001b[0m\n",
      "\u001b[35mfield_size  39\u001b[0m\n",
      "\u001b[35membedding_size  32\u001b[0m\n",
      "\u001b[35mbatch_size  1024\u001b[0m\n",
      "\u001b[35mdeep_layers  128,64,32\u001b[0m\n",
      "\u001b[35mdropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[35mloss_type  log_loss\u001b[0m\n",
      "\u001b[35moptimizer  Adam\u001b[0m\n",
      "\u001b[35mlearning_rate  0.0005\u001b[0m\n",
      "\u001b[35mbatch_norm_decay  0.9\u001b[0m\n",
      "\u001b[35mbatch_norm  False\u001b[0m\n",
      "\u001b[35ml2_reg  0.0001\u001b[0m\n",
      "\u001b[35mtr_files: ['/opt/ml/input/data/training/data-4/train.tfrecords', '/opt/ml/input/data/training/data-2/train.tfrecords']\u001b[0m\n",
      "\u001b[35mva_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[35mte_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[35mcurrent host is  algo-2\u001b[0m\n",
      "\u001b[35mhost is  ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[35mW0220 14:44:57.055300 139920681113344 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:414: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35mI0220 14:44:57.055552 139920681113344 run_config.py:528] TF_CONFIG environment variable: {'cluster': {'master': ['algo-1:2222'], 'ps': ['algo-1:2223', 'algo-2:2223'], 'worker': ['algo-2:2222']}, 'environment': 'cloud', 'task': {'index': 0, 'type': 'worker'}}\u001b[0m\n",
      "\u001b[35mI0220 14:44:57.056344 139920681113344 estimator.py:209] Using config: {'_model_dir': 's3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"CPU\"\n",
      "  value: 72\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mintra_op_parallelism_threads: 72\u001b[0m\n",
      "\u001b[35minter_op_parallelism_threads: 72\u001b[0m\n",
      "\u001b[35m, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f415ca5d240>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 1, '_master': 'grpc://algo-2:2222', '_evaluation_master': '', '_num_ps_replicas': 2, '_num_worker_replicas': 2, '_is_chief': False}\u001b[0m\n",
      "\u001b[35mI0220 14:44:57.057322 139920681113344 estimator_training.py:186] Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[35mI0220 14:44:57.057634 139920681113344 training.py:744] Start Tensorflow server.\n",
      "\u001b[0m\n",
      "\u001b[35mUser settings:\n",
      "\n",
      "   KMP_AFFINITY=verbose,disabled\n",
      "   KMP_BLOCKTIME=1\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=72\n",
      "\u001b[0m\n",
      "\u001b[35mEffective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=288\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=1\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_HAND_THREAD=false\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=false\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_FORKJOIN_FRAMES=true\n",
      "   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_INIT_WAIT=2048\n",
      "   KMP_ITT_PREPARE_DELAY=0\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NEXT_WAIT=1024\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=4M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=72\n",
      "   KMP_TOPOLOGY_METHOD=default\n",
      "   KMP_USER_LEVEL_MWAIT=false\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED=false\n",
      "   OMP_NUM_THREADS='72'\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='false'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=4M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_TOOL=enabled\n",
      "   OMP_TOOL_LIBRARIES: value is not defined\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,disabled'\n",
      "\u001b[0m\n",
      "\u001b[35mI0220 14:44:57.105175 139920681113344 training.py:789] Waiting 5 secs before starting training.\u001b[0m\n",
      "\u001b[34m2021-02-20 14:44:57.516558: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34mW0220 14:44:59.518909 139959645521664 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1072: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34mI0220 14:44:59.961085 139959645521664 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34mI0220 14:44:59.991437 139959645521664 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34mI0220 14:45:00.562551 139959645521664 basic_session_run_hooks.py:606] Saving checkpoints for 7800 into s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt/model.ckpt.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mW0220 14:45:02.122279 139920681113344 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[35mW0220 14:45:02.159732 139920681113344 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:81: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 14:45:02.159915 139920681113344 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:83: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 14:45:02.174629 139920681113344 deprecation.py:323] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:131: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\u001b[0m\n",
      "\u001b[35mI0220 14:45:02.189174 139920681113344 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[35mW0220 14:45:02.189325 139920681113344 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:166: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 14:45:02.192834 139920681113344 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[35mW0220 14:45:02.206863 139920681113344 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:177: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 14:45:02.466979 139920681113344 deprecation.py:506] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:218: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[35mW0220 14:45:02.544566 139920681113344 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:235: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 14:45:02.546984 139920681113344 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[35mW0220 14:45:02.560650 139920681113344 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:250: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 14:45:02.621675 139920681113344 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:809: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mDeprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[35mW0220 14:45:02.656300 139920681113344 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:261: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 14:45:02.656444 139920681113344 deprecation_wrapper.py:119] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:269: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[35mI0220 14:45:03.041075 139920681113344 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[35mI0220 14:45:03.042431 139920681113344 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34mI0220 14:45:03.553465 139959645521664 basic_session_run_hooks.py:262] loss = 0.09875166, step = 7800\u001b[0m\n",
      "\u001b[35mI0220 14:45:03.718182 139920681113344 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[35m2021-02-20 14:45:03.821474: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[35mI0220 14:45:03.861662 139920681113344 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[35mI0220 14:45:03.890202 139920681113344 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[35mI0220 14:45:05.005249 139920681113344 basic_session_run_hooks.py:262] loss = 0.116454445, step = 7804\u001b[0m\n",
      "\u001b[35mI0220 14:45:11.045960 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 17.9988\u001b[0m\n",
      "\u001b[35mI0220 14:45:14.563129 139920681113344 basic_session_run_hooks.py:260] loss = 0.13441992, step = 7983 (9.558 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:45:15.931710 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 20.4679\u001b[0m\n",
      "\u001b[34mI0220 14:45:16.660828 139959645521664 basic_session_run_hooks.py:260] loss = 0.10147105, step = 8030 (13.107 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:45:20.491015 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.1529\u001b[0m\n",
      "\u001b[35mI0220 14:45:21.498718 139920681113344 basic_session_run_hooks.py:260] loss = 0.10045561, step = 8138 (6.936 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:45:24.918519 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.5856\u001b[0m\n",
      "\u001b[35mI0220 14:45:28.373495 139920681113344 basic_session_run_hooks.py:260] loss = 0.10917318, step = 8292 (6.875 sec)\u001b[0m\n",
      "\u001b[34mI0220 14:45:29.387359 139959645521664 basic_session_run_hooks.py:260] loss = 0.111667044, step = 8313 (12.726 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:45:29.408878 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.4926\u001b[0m\n",
      "\u001b[35mI0220 14:45:33.909748 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.4401\u001b[0m\n",
      "\u001b[35mI0220 14:45:35.230494 139920681113344 basic_session_run_hooks.py:260] loss = 0.10549157, step = 8446 (6.857 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:45:38.423839 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.3749\u001b[0m\n",
      "\u001b[35mI0220 14:45:42.073667 139920681113344 basic_session_run_hooks.py:260] loss = 0.09827289, step = 8600 (6.843 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:45:42.901050 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.5584\u001b[0m\n",
      "\u001b[34mI0220 14:45:42.086116 139959645521664 basic_session_run_hooks.py:260] loss = 0.098922506, step = 8599 (12.699 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:45:47.294676 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.9876\u001b[0m\n",
      "\u001b[35mI0220 14:45:48.822106 139920681113344 basic_session_run_hooks.py:260] loss = 0.10084337, step = 8754 (6.748 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:45:51.776199 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.5374\u001b[0m\n",
      "\u001b[34mI0220 14:45:54.705009 139959645521664 basic_session_run_hooks.py:260] loss = 0.1159461, step = 8886 (12.619 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:45:55.610874 139920681113344 basic_session_run_hooks.py:260] loss = 0.09882584, step = 8907 (6.789 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:45:56.229087 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.6815\u001b[0m\n",
      "\u001b[35mI0220 14:46:00.704860 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.3425\u001b[0m\n",
      "\u001b[35mI0220 14:46:02.522061 139920681113344 basic_session_run_hooks.py:260] loss = 0.130322, step = 9062 (6.911 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:46:05.192458 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.5066\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mI0220 14:46:07.325784 139959645521664 basic_session_run_hooks.py:260] loss = 0.09591542, step = 9167 (12.621 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:46:09.460313 139920681113344 basic_session_run_hooks.py:260] loss = 0.102742985, step = 9217 (6.938 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:46:09.740459 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 21.9877\u001b[0m\n",
      "\u001b[35mI0220 14:46:14.143340 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.7128\u001b[0m\n",
      "\u001b[35mI0220 14:46:16.251148 139920681113344 basic_session_run_hooks.py:260] loss = 0.10439545, step = 9370 (6.791 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:46:18.606248 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.6311\u001b[0m\n",
      "\u001b[34mI0220 14:46:20.013451 139959645521664 basic_session_run_hooks.py:260] loss = 0.11969514, step = 9454 (12.688 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:46:23.051071 139920681113344 basic_session_run_hooks.py:260] loss = 0.100048274, step = 9524 (6.800 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:46:23.053619 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.7094\u001b[0m\n",
      "\u001b[35mI0220 14:46:27.557745 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.424\u001b[0m\n",
      "\u001b[35mI0220 14:46:29.951784 139920681113344 basic_session_run_hooks.py:260] loss = 0.11043577, step = 9679 (6.901 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:46:32.058239 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.442\u001b[0m\n",
      "\u001b[34mI0220 14:46:32.586323 139959645521664 basic_session_run_hooks.py:260] loss = 0.095404476, step = 9738 (12.573 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:46:36.491750 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.7811\u001b[0m\n",
      "\u001b[35mI0220 14:46:36.756343 139920681113344 basic_session_run_hooks.py:260] loss = 0.09937261, step = 9833 (6.805 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:46:40.922463 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.7958\u001b[0m\n",
      "\u001b[35mI0220 14:46:43.570492 139920681113344 basic_session_run_hooks.py:260] loss = 0.102759466, step = 9987 (6.814 sec)\u001b[0m\n",
      "\u001b[34mI0220 14:46:45.213473 139959645521664 basic_session_run_hooks.py:260] loss = 0.086013265, step = 10023 (12.627 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:46:45.437845 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.3676\u001b[0m\n",
      "\u001b[35mI0220 14:46:49.882464 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.7241\u001b[0m\n",
      "\u001b[35mI0220 14:46:50.355914 139920681113344 basic_session_run_hooks.py:260] loss = 0.09775615, step = 10141 (6.785 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:46:54.409511 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.3105\u001b[0m\n",
      "\u001b[35mI0220 14:46:57.156879 139920681113344 basic_session_run_hooks.py:260] loss = 0.1123231, step = 10295 (6.801 sec)\u001b[0m\n",
      "\u001b[34mI0220 14:46:57.812246 139959645521664 basic_session_run_hooks.py:260] loss = 0.10825021, step = 10308 (12.599 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:46:58.805504 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.9753\u001b[0m\n",
      "\u001b[35mI0220 14:47:03.247991 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.5099\u001b[0m\n",
      "\u001b[35mI0220 14:47:04.093743 139920681113344 basic_session_run_hooks.py:260] loss = 0.08120367, step = 10449 (6.937 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:47:07.884574 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 21.5683\u001b[0m\n",
      "\u001b[34mI0220 14:47:10.534196 139959645521664 basic_session_run_hooks.py:260] loss = 0.0951387, step = 10591 (12.722 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:47:11.065182 139920681113344 basic_session_run_hooks.py:260] loss = 0.10943586, step = 10604 (6.971 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:47:12.321661 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.5371\u001b[0m\n",
      "\u001b[35mI0220 14:47:16.707355 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.8009\u001b[0m\n",
      "\u001b[35mI0220 14:47:17.788588 139920681113344 basic_session_run_hooks.py:260] loss = 0.094210744, step = 10757 (6.723 sec)\u001b[0m\n",
      "\u001b[35mI0220 14:47:21.111467 139920681113344 basic_session_run_hooks.py:692] global_step/sec: 22.7061\u001b[0m\n",
      "\u001b[34m2021-02-20 14:47:21.116280: W tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc:510] RecvTensor cancelled for 54807638065925976\u001b[0m\n",
      "\u001b[34m2021-02-20 14:47:21.116338: W tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc:510] RecvTensor cancelled for 54807638065925976\u001b[0m\n",
      "\u001b[35mI0220 14:47:21.291361 139920681113344 estimator.py:368] Loss for final step: 0.0883653.\u001b[0m\n",
      "\u001b[34mI0220 14:47:23.071029 139959645521664 basic_session_run_hooks.py:260] loss = 0.10106707, step = 10850 (12.537 sec)\u001b[0m\n",
      "\u001b[34mI0220 14:47:34.899247 139959645521664 basic_session_run_hooks.py:260] loss = 0.09710947, step = 10950 (11.828 sec)\u001b[0m\n",
      "\u001b[34mI0220 14:47:46.684387 139959645521664 basic_session_run_hooks.py:260] loss = 0.0912226, step = 11050 (11.785 sec)\u001b[0m\n",
      "\u001b[34mI0220 14:47:58.535499 139959645521664 basic_session_run_hooks.py:260] loss = 0.10531795, step = 11150 (11.851 sec)\u001b[0m\n",
      "\u001b[34mI0220 14:48:10.541601 139959645521664 basic_session_run_hooks.py:260] loss = 0.08698134, step = 11250 (12.006 sec)\u001b[0m\n",
      "\u001b[34mI0220 14:48:22.375811 139959645521664 basic_session_run_hooks.py:260] loss = 0.09618575, step = 11350 (11.834 sec)\u001b[0m\n",
      "\u001b[34mI0220 14:48:34.274533 139959645521664 basic_session_run_hooks.py:260] loss = 0.08521988, step = 11450 (11.899 sec)\u001b[0m\n",
      "\u001b[34mI0220 14:48:46.184802 139959645521664 basic_session_run_hooks.py:260] loss = 0.08712773, step = 11550 (11.910 sec)\u001b[0m\n",
      "\u001b[34mI0220 14:48:58.100557 139959645521664 basic_session_run_hooks.py:260] loss = 0.08449693, step = 11650 (11.916 sec)\u001b[0m\n",
      "\u001b[35m2021-02-20 14:49:03.957123: W tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc:510] RecvTensor cancelled for 42794586941896109\u001b[0m\n",
      "\u001b[34m2021-02-20 14:49:03.960085: W tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc:510] RecvTensor cancelled for 42794586941896109\u001b[0m\n",
      "\u001b[34m2021-02-20 14:49:03.960138: W tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc:510] RecvTensor cancelled for 42794586941896109\u001b[0m\n",
      "\u001b[34mI0220 14:49:03.986320 139959645521664 basic_session_run_hooks.py:606] Saving checkpoints for 11700 into s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt/model.ckpt.\u001b[0m\n",
      "\u001b[34mI0220 14:49:06.913671 139959645521664 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34mI0220 14:49:07.097170 139959645521664 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34mI0220 14:49:07.113495 139959645521664 evaluation.py:255] Starting evaluation at 2021-02-20T14:49:07Z\u001b[0m\n",
      "\u001b[34mI0220 14:49:07.189544 139959645521664 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34mI0220 14:49:07.260393 139959645521664 saver.py:1286] Restoring parameters from s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt/model.ckpt-11700\u001b[0m\n",
      "\u001b[34mI0220 14:49:07.772827 139959645521664 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34mI0220 14:49:07.798459 139959645521664 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34mI0220 14:49:08.305584 139959645521664 evaluation.py:275] Finished evaluation at 2021-02-20-14:49:08\u001b[0m\n",
      "\u001b[34mI0220 14:49:08.305850 139959645521664 estimator.py:2039] Saving dict for global step 11700: auc = 0.6733313, global_step = 11700, loss = 3.6199214\u001b[0m\n",
      "\u001b[34mI0220 14:49:08.631700 139959645521664 estimator.py:2099] Saving 'checkpoint_path' summary for global step 11700: s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt/model.ckpt-11700\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#下面这个测试file mode\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/training/'\n",
    "validate_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/val/'\n",
    "\n",
    "if enable_s3_shard:\n",
    "    train_input = TrainingInput(train_s3_uri, distribution='ShardedByS3Key')\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "else :\n",
    "    train_input = TrainingInput(train_s3_uri)\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "\n",
    "inputs = {training_channel_name : train_input, evaluation_channel_name : val_input}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipe mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面用多个spot实例进行parameter server方式的分布式训练。\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "import time\n",
    "import os\n",
    "\n",
    "checkpoint_s3_uri = 's3://sagemaker-us-west-2-169088282855/deepfm-checkpoint' #Change to your own path if you want to save ckpt during training\n",
    "checkpoint_local_path = '/opt/ml/checkpoints'\n",
    "model_dir = 's3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt/{}'.format(int(time.time()))\n",
    "output_path= 's3://sagemaker-us-west-2-169088282855/deepfm-2021'\n",
    "\n",
    "training_channel_name = 'training'\n",
    "evaluation_channel_name = 'evaluation'\n",
    "\n",
    "train_instance_type = 'ml.c5.18xlarge'\n",
    "train_instance_count= 2\n",
    "\n",
    "train_use_spot_instances = True\n",
    "enable_s3_shard = True\n",
    "\n",
    "train_max_run=36000*2\n",
    "train_max_wait = 72000 if train_use_spot_instances else None\n",
    "\n",
    "distributions={'parameter_server': {'enabled': True}}\n",
    "\n",
    "deep_layer = '128,64,32'\n",
    "\n",
    "batch_size = 1024\n",
    "feature_size = 117581\n",
    "\n",
    "base_job_name='tf-scriptmode-deepfm'\n",
    "\n",
    "hyperparameters = {'servable_model_dir': '/opt/ml/model', 'training_data_dir': '/opt/ml/input/data/training/',\n",
    "                   'val_data_dir': '/opt/ml/input/data/evaluation/', 'log_steps': 10, 'num_epochs': 10, \n",
    "                   'field_size': 39, 'feature_size': feature_size, 'deep_layers': deep_layer,\n",
    "                   'perform_shuffle': 0, 'batch_size': batch_size, 'pipe_mode': 1, 'enable_s3_shard': enable_s3_shard,\n",
    "                   'training_channel_name': training_channel_name, 'evaluation_channel_name': evaluation_channel_name\n",
    "                  }\n",
    "\n",
    "estimator = TensorFlow(\n",
    "                       #source_dir='./',\n",
    "                       entry_point='DeepFM-dist-ps-for-multipleCPU-multiInstance.py',\n",
    "                       model_dir=model_dir,\n",
    "                       #checkpoint_s3_uri = checkpoint_s3_uri,\n",
    "                       #checkpoint_local_path = checkpoint_local_path,\n",
    "                       output_path= output_path,\n",
    "                       instance_type=train_instance_type,\n",
    "                       instance_count=train_instance_count,\n",
    "                       #volume_size = 500,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       base_job_name=base_job_name,\n",
    "                       framework_version='1.15',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True,\n",
    "                       input_mode='Pipe',\n",
    "                       distribution=distributions,\n",
    "                       use_spot_instances=train_use_spot_instances,\n",
    "                       max_wait=train_max_wait,\n",
    "                       max_run=train_max_run,\n",
    "                       debugger_hook_config = False,\n",
    "                       disable_profiler=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-20 10:18:12 Starting - Starting the training job...\n",
      "2021-02-20 10:18:14 Starting - Launching requested ML instances......\n",
      "2021-02-20 10:19:24 Starting - Preparing the instances for training.........\n",
      "2021-02-20 10:21:05 Downloading - Downloading input data\n",
      "2021-02-20 10:21:05 Training - Downloading the training image...\n",
      "2021-02-20 10:21:20 Training - Training image download completed. Training in progress.\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2021-02-20 10:21:25,098 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[35m2021-02-20 10:21:25,108 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-02-20 10:21:25,449 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[35m2021-02-20 10:21:25,449 sagemaker_tensorflow_container.training INFO     Launching parameter server process\u001b[0m\n",
      "\u001b[35m2021-02-20 10:21:25,449 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:95: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2021-02-20 10:21:25,449 tensorflow   WARNING  From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:95: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:97: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2021-02-20 10:21:25,450 tensorflow   WARNING  From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:97: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2021-02-20 10:21:25,598 sagemaker_tensorflow_container.training INFO     Launching worker process\u001b[0m\n",
      "\u001b[35m2021-02-20 10:21:25,741 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-02-20 10:21:25,764 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-02-20 10:21:25,783 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-02-20 10:21:25,793 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[35mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"evaluation\": \"/opt/ml/input/data/evaluation\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 1024,\n",
      "        \"val_data_dir\": \"/opt/ml/input/data/evaluation/\",\n",
      "        \"log_steps\": 10,\n",
      "        \"field_size\": 39,\n",
      "        \"deep_layers\": \"128,64,32\",\n",
      "        \"training_channel_name\": \"training\",\n",
      "        \"training_data_dir\": \"/opt/ml/input/data/training/\",\n",
      "        \"perform_shuffle\": 0,\n",
      "        \"evaluation_channel_name\": \"evaluation\",\n",
      "        \"feature_size\": 117581,\n",
      "        \"pipe_mode\": 1,\n",
      "        \"servable_model_dir\": \"/opt/ml/model\",\n",
      "        \"model_dir\": \"s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\",\n",
      "        \"num_epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"evaluation\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"ShardedByS3Key\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"tf-scriptmode-deepfm-2021-02-20-10-18-12-695\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-20-10-18-12-695/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"DeepFM-dist-ps-for-multipleCPU-multiInstance\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 72,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"DeepFM-dist-ps-for-multipleCPU-multiInstance.py\"\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"batch_size\":1024,\"deep_layers\":\"128,64,32\",\"evaluation_channel_name\":\"evaluation\",\"feature_size\":117581,\"field_size\":39,\"log_steps\":10,\"model_dir\":\"s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\",\"num_epochs\":10,\"perform_shuffle\":0,\"pipe_mode\":1,\"servable_model_dir\":\"/opt/ml/model\",\"training_channel_name\":\"training\",\"training_data_dir\":\"/opt/ml/input/data/training/\",\"val_data_dir\":\"/opt/ml/input/data/evaluation/\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=DeepFM-dist-ps-for-multipleCPU-multiInstance.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"evaluation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"ShardedByS3Key\",\"TrainingInputMode\":\"Pipe\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"evaluation\",\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=DeepFM-dist-ps-for-multipleCPU-multiInstance\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=72\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-20-10-18-12-695/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"evaluation\":\"/opt/ml/input/data/evaluation\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":1024,\"deep_layers\":\"128,64,32\",\"evaluation_channel_name\":\"evaluation\",\"feature_size\":117581,\"field_size\":39,\"log_steps\":10,\"model_dir\":\"s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\",\"num_epochs\":10,\"perform_shuffle\":0,\"pipe_mode\":1,\"servable_model_dir\":\"/opt/ml/model\",\"training_channel_name\":\"training\",\"training_data_dir\":\"/opt/ml/input/data/training/\",\"val_data_dir\":\"/opt/ml/input/data/evaluation/\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"evaluation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"ShardedByS3Key\",\"TrainingInputMode\":\"Pipe\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"tf-scriptmode-deepfm-2021-02-20-10-18-12-695\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-20-10-18-12-695/source/sourcedir.tar.gz\",\"module_name\":\"DeepFM-dist-ps-for-multipleCPU-multiInstance\",\"network_interface_name\":\"eth0\",\"num_cpus\":72,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-2\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"DeepFM-dist-ps-for-multipleCPU-multiInstance.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--batch_size\",\"1024\",\"--deep_layers\",\"128,64,32\",\"--evaluation_channel_name\",\"evaluation\",\"--feature_size\",\"117581\",\"--field_size\",\"39\",\"--log_steps\",\"10\",\"--model_dir\",\"s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\",\"--num_epochs\",\"10\",\"--perform_shuffle\",\"0\",\"--pipe_mode\",\"1\",\"--servable_model_dir\",\"/opt/ml/model\",\"--training_channel_name\",\"training\",\"--training_data_dir\",\"/opt/ml/input/data/training/\",\"--val_data_dir\",\"/opt/ml/input/data/evaluation/\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_EVALUATION=/opt/ml/input/data/evaluation\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_BATCH_SIZE=1024\u001b[0m\n",
      "\u001b[35mSM_HP_VAL_DATA_DIR=/opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[35mSM_HP_LOG_STEPS=10\u001b[0m\n",
      "\u001b[35mSM_HP_FIELD_SIZE=39\u001b[0m\n",
      "\u001b[35mSM_HP_DEEP_LAYERS=128,64,32\u001b[0m\n",
      "\u001b[35mSM_HP_TRAINING_CHANNEL_NAME=training\u001b[0m\n",
      "\u001b[35mSM_HP_TRAINING_DATA_DIR=/opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[35mSM_HP_PERFORM_SHUFFLE=0\u001b[0m\n",
      "\u001b[35mSM_HP_EVALUATION_CHANNEL_NAME=evaluation\u001b[0m\n",
      "\u001b[35mSM_HP_FEATURE_SIZE=117581\u001b[0m\n",
      "\u001b[35mSM_HP_PIPE_MODE=1\u001b[0m\n",
      "\u001b[35mSM_HP_SERVABLE_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_HP_MODEL_DIR=s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\u001b[0m\n",
      "\u001b[35mSM_HP_NUM_EPOCHS=10\u001b[0m\n",
      "\u001b[35mTF_CONFIG={\"cluster\": {\"master\": [\"algo-1:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"worker\": [\"algo-2:2222\"]}, \"environment\": \"cloud\", \"task\": {\"index\": 0, \"type\": \"worker\"}}\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[35m/usr/local/bin/python3.6 DeepFM-dist-ps-for-multipleCPU-multiInstance.py --batch_size 1024 --deep_layers 128,64,32 --evaluation_channel_name evaluation --feature_size 117581 --field_size 39 --log_steps 10 --model_dir s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt --num_epochs 10 --perform_shuffle 0 --pipe_mode 1 --servable_model_dir /opt/ml/model --training_channel_name training --training_data_dir /opt/ml/input/data/training/ --val_data_dir /opt/ml/input/data/evaluation/\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m['DeepFM-dist-ps-for-multipleCPU-multiInstance.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', 's3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '1', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/']\u001b[0m\n",
      "\u001b[35mchannel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[35mfirst channel evaluation\u001b[0m\n",
      "\u001b[35mlast channel name training\u001b[0m\n",
      "\u001b[35mLD_LIBRARY_PATH is as following:  /usr/local/openmpi/lib:\u001b[0m\n",
      "\u001b[35mtask_type  train\u001b[0m\n",
      "\u001b[35mmodel_dir  s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\u001b[0m\n",
      "\u001b[35mtraining_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[35mval_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[35mnum_epochs  10\u001b[0m\n",
      "\u001b[35mfeature_size  117581\u001b[0m\n",
      "\u001b[35mfield_size  39\u001b[0m\n",
      "\u001b[35membedding_size  32\u001b[0m\n",
      "\u001b[35mbatch_size  1024\u001b[0m\n",
      "\u001b[35mdeep_layers  128,64,32\u001b[0m\n",
      "\u001b[35mdropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[35mloss_type  log_loss\u001b[0m\n",
      "\u001b[35moptimizer  Adam\u001b[0m\n",
      "\u001b[35mlearning_rate  0.0005\u001b[0m\n",
      "\u001b[35mbatch_norm_decay  0.9\u001b[0m\n",
      "\u001b[35mbatch_norm  False\u001b[0m\n",
      "\u001b[35ml2_reg  0.0001\u001b[0m\n",
      "\u001b[35mcurrent host is  algo-2\u001b[0m\n",
      "\u001b[35mhost is  ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-02-20 10:21:29,189 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-02-20 10:21:29,198 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-02-20 10:21:29,873 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34m2021-02-20 10:21:29,873 sagemaker_tensorflow_container.training INFO     Launching parameter server process\u001b[0m\n",
      "\u001b[34m2021-02-20 10:21:29,873 sagemaker_tensorflow_container.training INFO     Running distributed training job with parameter servers\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:95: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-02-20 10:21:29,874 tensorflow   WARNING  From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:95: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:97: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-02-20 10:21:29,874 tensorflow   WARNING  From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:97: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-02-20 10:21:30,035 sagemaker_tensorflow_container.training INFO     Launching worker process\u001b[0m\n",
      "\u001b[34m2021-02-20 10:21:30,201 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-02-20 10:21:30,222 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-02-20 10:21:30,243 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-02-20 10:21:30,253 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_parameter_server_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"evaluation\": \"/opt/ml/input/data/evaluation\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 1024,\n",
      "        \"val_data_dir\": \"/opt/ml/input/data/evaluation/\",\n",
      "        \"log_steps\": 10,\n",
      "        \"field_size\": 39,\n",
      "        \"deep_layers\": \"128,64,32\",\n",
      "        \"training_channel_name\": \"training\",\n",
      "        \"training_data_dir\": \"/opt/ml/input/data/training/\",\n",
      "        \"perform_shuffle\": 0,\n",
      "        \"evaluation_channel_name\": \"evaluation\",\n",
      "        \"feature_size\": 117581,\n",
      "        \"pipe_mode\": 1,\n",
      "        \"servable_model_dir\": \"/opt/ml/model\",\n",
      "        \"model_dir\": \"s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\",\n",
      "        \"num_epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"evaluation\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"Pipe\",\n",
      "            \"S3DistributionType\": \"ShardedByS3Key\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tf-scriptmode-deepfm-2021-02-20-10-18-12-695\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-20-10-18-12-695/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"DeepFM-dist-ps-for-multipleCPU-multiInstance\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 72,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"DeepFM-dist-ps-for-multipleCPU-multiInstance.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":1024,\"deep_layers\":\"128,64,32\",\"evaluation_channel_name\":\"evaluation\",\"feature_size\":117581,\"field_size\":39,\"log_steps\":10,\"model_dir\":\"s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\",\"num_epochs\":10,\"perform_shuffle\":0,\"pipe_mode\":1,\"servable_model_dir\":\"/opt/ml/model\",\"training_channel_name\":\"training\",\"training_data_dir\":\"/opt/ml/input/data/training/\",\"val_data_dir\":\"/opt/ml/input/data/evaluation/\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=DeepFM-dist-ps-for-multipleCPU-multiInstance.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"evaluation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"ShardedByS3Key\",\"TrainingInputMode\":\"Pipe\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"evaluation\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=DeepFM-dist-ps-for-multipleCPU-multiInstance\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=72\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-20-10-18-12-695/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":true},\"channel_input_dirs\":{\"evaluation\":\"/opt/ml/input/data/evaluation\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch_size\":1024,\"deep_layers\":\"128,64,32\",\"evaluation_channel_name\":\"evaluation\",\"feature_size\":117581,\"field_size\":39,\"log_steps\":10,\"model_dir\":\"s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\",\"num_epochs\":10,\"perform_shuffle\":0,\"pipe_mode\":1,\"servable_model_dir\":\"/opt/ml/model\",\"training_channel_name\":\"training\",\"training_data_dir\":\"/opt/ml/input/data/training/\",\"val_data_dir\":\"/opt/ml/input/data/evaluation/\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"evaluation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"Pipe\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"ShardedByS3Key\",\"TrainingInputMode\":\"Pipe\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-scriptmode-deepfm-2021-02-20-10-18-12-695\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-20-10-18-12-695/source/sourcedir.tar.gz\",\"module_name\":\"DeepFM-dist-ps-for-multipleCPU-multiInstance\",\"network_interface_name\":\"eth0\",\"num_cpus\":72,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\",\"algo-2\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"DeepFM-dist-ps-for-multipleCPU-multiInstance.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"1024\",\"--deep_layers\",\"128,64,32\",\"--evaluation_channel_name\",\"evaluation\",\"--feature_size\",\"117581\",\"--field_size\",\"39\",\"--log_steps\",\"10\",\"--model_dir\",\"s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\",\"--num_epochs\",\"10\",\"--perform_shuffle\",\"0\",\"--pipe_mode\",\"1\",\"--servable_model_dir\",\"/opt/ml/model\",\"--training_channel_name\",\"training\",\"--training_data_dir\",\"/opt/ml/input/data/training/\",\"--val_data_dir\",\"/opt/ml/input/data/evaluation/\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_EVALUATION=/opt/ml/input/data/evaluation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=1024\u001b[0m\n",
      "\u001b[34mSM_HP_VAL_DATA_DIR=/opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34mSM_HP_LOG_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_FIELD_SIZE=39\u001b[0m\n",
      "\u001b[34mSM_HP_DEEP_LAYERS=128,64,32\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_CHANNEL_NAME=training\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_DATA_DIR=/opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34mSM_HP_PERFORM_SHUFFLE=0\u001b[0m\n",
      "\u001b[34mSM_HP_EVALUATION_CHANNEL_NAME=evaluation\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURE_SIZE=117581\u001b[0m\n",
      "\u001b[34mSM_HP_PIPE_MODE=1\u001b[0m\n",
      "\u001b[34mSM_HP_SERVABLE_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_EPOCHS=10\u001b[0m\n",
      "\u001b[34mTF_CONFIG={\"cluster\": {\"master\": [\"algo-1:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"worker\": [\"algo-2:2222\"]}, \"environment\": \"cloud\", \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 DeepFM-dist-ps-for-multipleCPU-multiInstance.py --batch_size 1024 --deep_layers 128,64,32 --evaluation_channel_name evaluation --feature_size 117581 --field_size 39 --log_steps 10 --model_dir s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt --num_epochs 10 --perform_shuffle 0 --pipe_mode 1 --servable_model_dir /opt/ml/model --training_channel_name training --training_data_dir /opt/ml/input/data/training/ --val_data_dir /opt/ml/input/data/evaluation/\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m['DeepFM-dist-ps-for-multipleCPU-multiInstance.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', 's3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '1', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/']\u001b[0m\n",
      "\u001b[34mchannel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34mfirst channel evaluation\u001b[0m\n",
      "\u001b[34mlast channel name training\u001b[0m\n",
      "\u001b[34mLD_LIBRARY_PATH is as following:  /usr/local/openmpi/lib:\u001b[0m\n",
      "\u001b[34mtask_type  train\u001b[0m\n",
      "\u001b[34mmodel_dir  s3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt\u001b[0m\n",
      "\u001b[34mtraining_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34mval_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34mnum_epochs  10\u001b[0m\n",
      "\u001b[34mfeature_size  117581\u001b[0m\n",
      "\u001b[34mfield_size  39\u001b[0m\n",
      "\u001b[34membedding_size  32\u001b[0m\n",
      "\u001b[34mbatch_size  1024\u001b[0m\n",
      "\u001b[34mdeep_layers  128,64,32\u001b[0m\n",
      "\u001b[34mdropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34mloss_type  log_loss\u001b[0m\n",
      "\u001b[34moptimizer  Adam\u001b[0m\n",
      "\u001b[34mlearning_rate  0.0005\u001b[0m\n",
      "\u001b[34mbatch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34mbatch_norm  False\u001b[0m\n",
      "\u001b[34ml2_reg  0.0001\u001b[0m\n",
      "\u001b[34mcurrent host is  algo-1\u001b[0m\n",
      "\u001b[34mhost is  ['algo-1', 'algo-2']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2021-02-20 10:23:44.708785: W tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc:510] RecvTensor cancelled for 17810557842545804\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:439: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:439: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:440: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:400: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 10:21:29.063510 140180574773504 module_wrapper.py:139] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:400: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:TF_CONFIG environment variable: {'cluster': {'master': ['algo-1:2222'], 'ps': ['algo-1:2223', 'algo-2:2223'], 'worker': ['algo-2:2222']}, 'environment': 'cloud', 'task': {'index': 0, 'type': 'worker'}}\u001b[0m\n",
      "\u001b[35mI0220 10:21:29.063748 140180574773504 run_config.py:535] TF_CONFIG environment variable: {'cluster': {'master': ['algo-1:2222'], 'ps': ['algo-1:2223', 'algo-2:2223'], 'worker': ['algo-2:2222']}, 'environment': 'cloud', 'task': {'index': 0, 'type': 'worker'}}\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Using config: {'_model_dir': 's3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"CPU\"\n",
      "  value: 72\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mintra_op_parallelism_threads: 72\u001b[0m\n",
      "\u001b[35minter_op_parallelism_threads: 72\u001b[0m\n",
      "\u001b[35m, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7e0090bf98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 1, '_master': 'grpc://algo-2:2222', '_evaluation_master': '', '_num_ps_replicas': 2, '_num_worker_replicas': 2, '_is_chief': False}\u001b[0m\n",
      "\u001b[35mI0220 10:21:29.064539 140180574773504 estimator.py:212] Using config: {'_model_dir': 's3://sagemaker-us-west-2-169088282855/deepfm-ps-ckpt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"CPU\"\n",
      "  value: 72\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mintra_op_parallelism_threads: 72\u001b[0m\n",
      "\u001b[35minter_op_parallelism_threads: 72\u001b[0m\n",
      "\u001b[35m, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7e0090bf98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 1, '_master': 'grpc://algo-2:2222', '_evaluation_master': '', '_num_ps_replicas': 2, '_num_worker_replicas': 2, '_is_chief': False}\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[35mI0220 10:21:29.065621 140180574773504 estimator_training.py:186] Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Start Tensorflow server.\u001b[0m\n",
      "\u001b[35mI0220 10:21:29.065905 140180574773504 training.py:744] Start Tensorflow server.\n",
      "\u001b[0m\n",
      "\u001b[35mUser settings:\n",
      "\n",
      "   KMP_AFFINITY=verbose,disabled\n",
      "   KMP_BLOCKTIME=1\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=72\n",
      "\u001b[0m\n",
      "\u001b[35mEffective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=288\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=1\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_HAND_THREAD=false\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=false\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_FORKJOIN_FRAMES=true\n",
      "   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_ITT_PREPARE_DELAY=0\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_MWAIT_HINTS=0\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=72\n",
      "   KMP_TOPOLOGY_METHOD=default\n",
      "   KMP_USER_LEVEL_MWAIT=false\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEBUG=disabled\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED=false\n",
      "   OMP_NUM_THREADS='72'\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='false'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_TOOL=enabled\n",
      "   OMP_TOOL_LIBRARIES: value is not defined\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,disabled'\n",
      "\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Waiting 5 secs before starting training.\u001b[0m\n",
      "\u001b[35mI0220 10:21:29.110476 140180574773504 training.py:789] Waiting 5 secs before starting training.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.400280 140180574773504 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow/pipemode.py:100: scalar (from tensorflow.python.framework.tensor_shape) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse tf.TensorShape([]).\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.419128 140180574773504 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow/pipemode.py:100: scalar (from tensorflow.python.framework.tensor_shape) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse tf.TensorShape([]).\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.463773 140180574773504 module_wrapper.py:139] From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.464037 140180574773504 module_wrapper.py:139] From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[35mI0220 10:21:34.561920 140180574773504 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:153: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.562254 140180574773504 module_wrapper.py:139] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:153: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:164: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.577527 140180574773504 module_wrapper.py:139] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:164: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:\u001b[0m\n",
      "\u001b[35mThe TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[35mFor more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[35mIf you depend on functionality not listed there, please file an issue.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.591535 140180574773504 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[35mThe TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[35mFor more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[35mIf you depend on functionality not listed there, please file an issue.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.593270 140180574773504 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:205: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.606431 140180574773504 deprecation.py:506] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:205: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:222: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.669142 140180574773504 module_wrapper.py:139] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:222: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.671224 140180574773504 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:237: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.680034 140180574773504 module_wrapper.py:139] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:237: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mDeprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.734885 140180574773504 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mDeprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:248: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.763582 140180574773504 module_wrapper.py:139] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:248: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:256: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 10:21:34.763753 140180574773504 module_wrapper.py:139] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:256: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[35mI0220 10:21:35.064150 140180574773504 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[35mI0220 10:21:35.065331 140180574773504 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[35mI0220 10:21:35.811134 140180574773504 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  Variables not initialized: global_step, fm_bias, fm_w, fm_v, Deep-part/mlp0/weights, Deep-part/mlp0/biases, Deep-part/mlp1/weights, Deep-part/mlp1/biases, Deep-part/mlp2/weights, Deep-part/mlp2/biases, Deep-part/deep_out/weights, Deep-part/deep_out/biases, beta1_power, beta2_power, fm_bias/Adam, fm_bias/Adam_1, fm_w/Adam, fm_w/Adam_1, fm_v/Adam, fm_v/Adam_1, Deep-part/mlp0/weights/Adam, Deep-part/mlp0/weights/Adam_1, Deep-part/mlp0/biases/Adam, Deep-part/mlp0/biases/Adam_1, Deep-part/mlp1/weights/Adam, Deep-part/mlp1/weights/Adam_1, Deep-part/mlp1/biases/Adam, Deep-part/mlp1/biases/Adam_1, Deep-part/mlp2/weights/Adam, Deep-part/mlp2/weights/Adam_1, Deep-part/mlp2/biases/Adam, Deep-part/mlp2/biases/Adam_1, Deep-part/deep_out/weights/Adam, Deep-part/deep_out/weights/Adam_1, Deep-part/deep_out/biases/Adam, Deep-part/deep_out/biases/Adam_1, ready: None\u001b[0m\n",
      "\u001b[35mI0220 10:21:36.012709 140180574773504 session_manager.py:436] Waiting for model to be ready.  Ready_for_local_init_op:  Variables not initialized: global_step, fm_bias, fm_w, fm_v, Deep-part/mlp0/weights, Deep-part/mlp0/biases, Deep-part/mlp1/weights, Deep-part/mlp1/biases, Deep-part/mlp2/weights, Deep-part/mlp2/biases, Deep-part/deep_out/weights, Deep-part/deep_out/biases, beta1_power, beta2_power, fm_bias/Adam, fm_bias/Adam_1, fm_w/Adam, fm_w/Adam_1, fm_v/Adam, fm_v/Adam_1, Deep-part/mlp0/weights/Adam, Deep-part/mlp0/weights/Adam_1, Deep-part/mlp0/biases/Adam, Deep-part/mlp0/biases/Adam_1, Deep-part/mlp1/weights/Adam, Deep-part/mlp1/weights/Adam_1, Deep-part/mlp1/biases/Adam, Deep-part/mlp1/biases/Adam_1, Deep-part/mlp2/weights/Adam, Deep-part/mlp2/weights/Adam_1, Deep-part/mlp2/biases/Adam, Deep-part/mlp2/biases/Adam_1, Deep-part/deep_out/weights/Adam, Deep-part/deep_out/weights/Adam_1, Deep-part/deep_out/biases/Adam, Deep-part/deep_out/biases/Adam_1, ready: None\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[35mI0220 10:22:06.173382 140180574773504 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[35mI0220 10:22:06.214094 140180574773504 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[35m2021-02-20 10:22:06.348946: W tensorflow/core/framework/dataset.cc:382] Input of PipeModeDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12755616, step = 4041\u001b[0m\n",
      "\u001b[35mI0220 10:22:07.089159 140180574773504 basic_session_run_hooks.py:262] loss = 0.12755616, step = 4041\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 29.3156\u001b[0m\n",
      "\u001b[35mI0220 10:22:10.852683 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 29.3156\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13757625, step = 4251 (7.024 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:22:14.113149 140180574773504 basic_session_run_hooks.py:260] loss = 0.13757625, step = 4251 (7.024 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 30.7567\u001b[0m\n",
      "\u001b[35mI0220 10:22:14.169014 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 30.7567\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 34.9203\u001b[0m\n",
      "\u001b[35mI0220 10:22:17.089949 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 34.9203\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11886272, step = 4427 (5.010 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:22:19.122833 140180574773504 basic_session_run_hooks.py:260] loss = 0.11886272, step = 4427 (5.010 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.3848\u001b[0m\n",
      "\u001b[35mI0220 10:22:19.972538 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.3848\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.3334\u001b[0m\n",
      "\u001b[35mI0220 10:22:22.802847 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.3334\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10400233, step = 4601 (4.935 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:22:24.057565 140180574773504 basic_session_run_hooks.py:260] loss = 0.10400233, step = 4601 (4.935 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.3099\u001b[0m\n",
      "\u001b[35mI0220 10:22:25.663145 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.3099\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.4043\u001b[0m\n",
      "\u001b[35mI0220 10:22:28.487661 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.4043\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.16075021, step = 4774 (4.853 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:22:28.910314 140180574773504 basic_session_run_hooks.py:260] loss = 0.16075021, step = 4774 (4.853 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.7558\u001b[0m\n",
      "\u001b[35mI0220 10:22:31.312513 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.7558\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1065066, step = 4949 (4.910 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:22:33.820652 140180574773504 basic_session_run_hooks.py:260] loss = 0.1065066, step = 4949 (4.910 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.4251\u001b[0m\n",
      "\u001b[35mI0220 10:22:34.163557 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.4251\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.8491\u001b[0m\n",
      "\u001b[35mI0220 10:22:36.980853 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.8491\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10513505, step = 5122 (4.909 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:22:38.729175 140180574773504 basic_session_run_hooks.py:260] loss = 0.10513505, step = 5122 (4.909 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 34.9888\u001b[0m\n",
      "\u001b[35mI0220 10:22:39.838925 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 34.9888\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.4312\u001b[0m\n",
      "\u001b[35mI0220 10:22:42.689473 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.4312\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.14057985, step = 5295 (4.904 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:22:43.633105 140180574773504 basic_session_run_hooks.py:260] loss = 0.14057985, step = 5295 (4.904 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.0629\u001b[0m\n",
      "\u001b[35mI0220 10:22:45.570030 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.0629\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.4483\u001b[0m\n",
      "\u001b[35mI0220 10:22:48.419315 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.4483\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.11375022, step = 5470 (4.944 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:22:48.576895 140180574773504 basic_session_run_hooks.py:260] loss = 0.11375022, step = 5470 (4.944 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.2558\u001b[0m\n",
      "\u001b[35mI0220 10:22:51.255744 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.2558\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12109031, step = 5643 (4.859 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:22:53.435918 140180574773504 basic_session_run_hooks.py:260] loss = 0.12109031, step = 5643 (4.859 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 36.0744\u001b[0m\n",
      "\u001b[35mI0220 10:22:54.055448 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 36.0744\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.7543\u001b[0m\n",
      "\u001b[35mI0220 10:22:56.880275 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.7543\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.0943295, step = 5817 (4.889 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:22:58.324883 140180574773504 basic_session_run_hooks.py:260] loss = 0.0943295, step = 5817 (4.889 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.4689\u001b[0m\n",
      "\u001b[35mI0220 10:22:59.756069 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.4689\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.8136\u001b[0m\n",
      "\u001b[35mI0220 10:23:02.576204 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.8136\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12573251, step = 5990 (4.838 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:23:03.162848 140180574773504 basic_session_run_hooks.py:260] loss = 0.12573251, step = 5990 (4.838 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 34.6238\u001b[0m\n",
      "\u001b[35mI0220 10:23:05.493271 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 34.6238\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.1199493, step = 6165 (5.022 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:23:08.185069 140180574773504 basic_session_run_hooks.py:260] loss = 0.1199493, step = 6165 (5.022 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.1142\u001b[0m\n",
      "\u001b[35mI0220 10:23:08.369568 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.1142\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.0794\u001b[0m\n",
      "\u001b[35mI0220 10:23:11.248752 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.0794\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13942167, step = 6337 (4.849 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:23:13.034160 140180574773504 basic_session_run_hooks.py:260] loss = 0.13942167, step = 6337 (4.849 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.9348\u001b[0m\n",
      "\u001b[35mI0220 10:23:14.059493 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.9348\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 36.331\u001b[0m\n",
      "\u001b[35mI0220 10:23:16.866920 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 36.331\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10360416, step = 6509 (4.773 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:23:17.807611 140180574773504 basic_session_run_hooks.py:260] loss = 0.10360416, step = 6509 (4.773 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.8392\u001b[0m\n",
      "\u001b[35mI0220 10:23:19.712981 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.8392\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.8747\u001b[0m\n",
      "\u001b[35mI0220 10:23:22.528316 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.8747\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13171588, step = 6682 (4.818 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:23:22.625937 140180574773504 basic_session_run_hooks.py:260] loss = 0.13171588, step = 6682 (4.818 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.5944\u001b[0m\n",
      "\u001b[35mI0220 10:23:25.393943 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.5944\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10685609, step = 6854 (4.856 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:23:27.481810 140180574773504 basic_session_run_hooks.py:260] loss = 0.10685609, step = 6854 (4.856 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.4532\u001b[0m\n",
      "\u001b[35mI0220 10:23:28.270972 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.4532\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 36.0453\u001b[0m\n",
      "\u001b[35mI0220 10:23:31.073064 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 36.0453\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.10135543, step = 7026 (4.813 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:23:32.295270 140180574773504 basic_session_run_hooks.py:260] loss = 0.10135543, step = 7026 (4.813 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.6241\u001b[0m\n",
      "\u001b[35mI0220 10:23:33.908164 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.6241\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.5048\u001b[0m\n",
      "\u001b[35mI0220 10:23:36.752844 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.5048\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.13631324, step = 7204 (5.169 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:23:37.464248 140180574773504 basic_session_run_hooks.py:260] loss = 0.13631324, step = 7204 (5.169 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 33.8506\u001b[0m\n",
      "\u001b[35mI0220 10:23:39.766147 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 33.8506\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:loss = 0.12451861, step = 7377 (4.824 sec)\u001b[0m\n",
      "\u001b[35mI0220 10:23:42.288586 140180574773504 basic_session_run_hooks.py:260] loss = 0.12451861, step = 7377 (4.824 sec)\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:global_step/sec: 35.5365\u001b[0m\n",
      "\u001b[35mI0220 10:23:42.580142 140180574773504 basic_session_run_hooks.py:692] global_step/sec: 35.5365\u001b[0m\n",
      "\u001b[35mINFO:tensorflow:Loss for final step: 0.11273042.\u001b[0m\n",
      "\u001b[35mI0220 10:23:44.975026 140180574773504 estimator.py:371] Loss for final step: 0.11273042.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:428: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0220 10:23:44.975868 140180574773504 module_wrapper.py:139] From DeepFM-dist-ps-for-multipleCPU-multiInstance.py:428: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021-02-20 10:23:45,824 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2021-02-20 10:23:55,868 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:30:05,825 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:30:15,877 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:30:25,929 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:30:35,974 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:30:46,027 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:30:56,080 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:31:06,124 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:31:16,178 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:31:26,231 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:31:36,283 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:31:46,336 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:31:56,383 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:32:06,422 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:32:16,474 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:32:26,525 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:32:36,577 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:32:46,629 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:32:56,681 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:33:06,725 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:33:16,777 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:33:26,830 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:33:36,882 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:33:46,934 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:33:56,978 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:34:07,030 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:34:17,082 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:34:27,135 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:34:37,184 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:34:47,236 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:34:57,283 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:35:07,331 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:35:17,377 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:35:27,429 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:35:37,481 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:35:47,531 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:35:57,584 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:36:07,636 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:36:17,689 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:36:27,741 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:36:37,792 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:36:47,845 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:36:57,897 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:37:07,949 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:37:17,996 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:37:28,043 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:37:38,095 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:37:48,144 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:37:58,198 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:38:08,248 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:38:18,295 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:38:28,344 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:38:38,395 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:38:48,448 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:38:58,500 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:39:08,552 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:39:18,605 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:39:28,657 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:39:38,709 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:39:48,761 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:39:58,813 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:40:08,866 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:40:18,919 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2021-02-20 11:40:28,972 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:40:39,024 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:40:49,076 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:40:59,130 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:41:09,182 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:41:19,231 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:41:29,284 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:41:39,336 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:41:49,388 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:41:59,441 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:42:09,493 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:42:19,540 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:42:29,586 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:42:39,628 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:42:49,680 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:42:59,732 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n",
      "\u001b[35m2021-02-20 11:43:09,773 sagemaker_tensorflow_container.training INFO     master algo-1 is still up, waiting for it to exit\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e75a79a2e5d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'evaluation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1586\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1588\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1589\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3588\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOB_COMPLETE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#下面这个测试pipe mode\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/training/'\n",
    "validate_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/val/'\n",
    "\n",
    "if enable_s3_shard:\n",
    "    train_input = TrainingInput(train_s3_uri, distribution='ShardedByS3Key')\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "else :\n",
    "    train_input = TrainingInput(train_s3_uri)\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "\n",
    "inputs = {training_channel_name : train_input, evaluation_channel_name : val_input}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
