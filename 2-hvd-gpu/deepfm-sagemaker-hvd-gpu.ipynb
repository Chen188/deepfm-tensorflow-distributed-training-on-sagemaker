{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFM Tensorflow Horovod on SageMaker Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this sample, we will demo how to run a deepfm sample code in tensorflow horovod on sagemaker\n",
    "\n",
    "Notice:\n",
    "\n",
    "1. Dataset format is TFRecord\n",
    "\n",
    "2. This model training we will use **GPU** instances\n",
    "\n",
    "3. Using [SageMaker Python SDK 2.x](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.25.1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面用多个spot实例进行parameter server方式的分布式训练。\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "dt_now = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "bucket = 'sagemaker-us-west-2-169088282855'\n",
    "checkpoint_s3_uri = 's3://{}/deepfm-checkpoint/{}'.format(bucket, dt_now) #Change to your own path if you want to save ckpt during training\n",
    "checkpoint_local_path = '/opt/ml/checkpoints'\n",
    "model_dir = '/opt/ml/model'\n",
    "output_path= 's3://{}/deepfm-2021'.format(bucket)\n",
    "\n",
    "training_channel_name = 'training'\n",
    "evaluation_channel_name = 'evaluation'\n",
    "\n",
    "train_instance_type = 'ml.p3.8xlarge'\n",
    "hvd_processes_per_host = 4\n",
    "train_instance_count= 1\n",
    "\n",
    "train_use_spot_instances = True\n",
    "enable_s3_shard = True\n",
    "enable_data_multi_path = True\n",
    "\n",
    "train_max_run=36000*2\n",
    "train_max_wait = 72000 if train_use_spot_instances else None\n",
    "\n",
    "distributions = {'mpi': {\n",
    "                    'enabled': True,\n",
    "                    'processes_per_host': hvd_processes_per_host,\n",
    "                    'custom_mpi_options': '-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none'\n",
    "                        }\n",
    "                }\n",
    "\n",
    "deep_layer = '128,64,32'\n",
    "\n",
    "batch_size = 1024\n",
    "feature_size = 117581\n",
    "\n",
    "base_job_name='tf-scriptmode-deepfm'\n",
    "\n",
    "hyperparameters = {'servable_model_dir': '/opt/ml/model', 'training_data_dir': '/opt/ml/input/data/training/',\n",
    "                   'val_data_dir': '/opt/ml/input/data/evaluation/', 'log_steps': 10, 'num_epochs': 10, \n",
    "                   'field_size': 39, 'feature_size': feature_size, 'deep_layers': deep_layer,\n",
    "                   'perform_shuffle': 0, 'batch_size': batch_size, 'pipe_mode': 0, 'enable_s3_shard': enable_s3_shard,\n",
    "                   'training_channel_name': training_channel_name, 'evaluation_channel_name': evaluation_channel_name,\n",
    "                   'worker_per_host': hvd_processes_per_host, 'enable_data_multi_path': enable_data_multi_path\n",
    "                  }\n",
    "\n",
    "estimator = TensorFlow(\n",
    "                       #source_dir='./',\n",
    "                       entry_point='DeepFM-hvd-tfrecord-vectorized-map.py',\n",
    "                       model_dir=model_dir,\n",
    "                       checkpoint_s3_uri = checkpoint_s3_uri,\n",
    "                       checkpoint_local_path = checkpoint_local_path,\n",
    "                       output_path= output_path,\n",
    "                       instance_type=train_instance_type,\n",
    "                       instance_count=train_instance_count,\n",
    "                       #volume_size = 500,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       base_job_name=base_job_name,\n",
    "                       framework_version='1.15.2',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True,\n",
    "                       #input_mode='Pipe',\n",
    "                       distribution=distributions,\n",
    "                       use_spot_instances=train_use_spot_instances,\n",
    "                       max_wait=train_max_wait,\n",
    "                       max_run=train_max_run,\n",
    "                       debugger_hook_config =False,\n",
    "                       disable_profiler=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-22 15:20:46 Starting - Starting the training job...\n",
      "2021-02-22 15:20:48 Starting - Launching requested ML instances.........\n",
      "2021-02-22 15:22:26 Starting - Preparing the instances for training......\n",
      "2021-02-22 15:23:27 Downloading - Downloading input data\n",
      "2021-02-22 15:23:27 Training - Downloading the training image......\n",
      "2021-02-22 15:24:35 Training - Training image download completed. Training in progress..\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-02-22 15:24:40,950 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-02-22 15:24:41,483 sagemaker-containers INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2021-02-22 15:24:41,483 sagemaker-containers INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2021-02-22 15:24:41,490 sagemaker-containers INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2021-02-22 15:24:41,490 sagemaker-containers INFO     Env Hosts: ['algo-1'] Hosts: ['algo-1:4'] process_per_hosts: 4 num_processes: 4\u001b[0m\n",
      "\u001b[34m2021-02-22 15:24:41,492 sagemaker-containers INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2021-02-22 15:24:41,538 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_mpi_num_of_processes_per_host\": 4,\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none\",\n",
      "        \"sagemaker_mpi_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"evaluation\": \"/opt/ml/input/data/evaluation\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 1024,\n",
      "        \"val_data_dir\": \"/opt/ml/input/data/evaluation/\",\n",
      "        \"log_steps\": 10,\n",
      "        \"field_size\": 39,\n",
      "        \"worker_per_host\": 4,\n",
      "        \"deep_layers\": \"128,64,32\",\n",
      "        \"training_channel_name\": \"training\",\n",
      "        \"training_data_dir\": \"/opt/ml/input/data/training/\",\n",
      "        \"perform_shuffle\": 0,\n",
      "        \"evaluation_channel_name\": \"evaluation\",\n",
      "        \"feature_size\": 117581,\n",
      "        \"pipe_mode\": 0,\n",
      "        \"servable_model_dir\": \"/opt/ml/model\",\n",
      "        \"model_dir\": \"/opt/ml/model\",\n",
      "        \"enable_s3_shard\": true,\n",
      "        \"num_epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"evaluation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"ShardedByS3Key\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tf-scriptmode-deepfm-2021-02-22-15-20-46-020\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-22-15-20-46-020/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"DeepFM-hvd-tfrecord-vectorized-map\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"DeepFM-hvd-tfrecord-vectorized-map.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":1024,\"deep_layers\":\"128,64,32\",\"enable_s3_shard\":true,\"evaluation_channel_name\":\"evaluation\",\"feature_size\":117581,\"field_size\":39,\"log_steps\":10,\"model_dir\":\"/opt/ml/model\",\"num_epochs\":10,\"perform_shuffle\":0,\"pipe_mode\":0,\"servable_model_dir\":\"/opt/ml/model\",\"training_channel_name\":\"training\",\"training_data_dir\":\"/opt/ml/input/data/training/\",\"val_data_dir\":\"/opt/ml/input/data/evaluation/\",\"worker_per_host\":4}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=DeepFM-hvd-tfrecord-vectorized-map.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_mpi_custom_mpi_options\":\"-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":4}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"evaluation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"ShardedByS3Key\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"evaluation\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=DeepFM-hvd-tfrecord-vectorized-map\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-22-15-20-46-020/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":4},\"channel_input_dirs\":{\"evaluation\":\"/opt/ml/input/data/evaluation\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":1024,\"deep_layers\":\"128,64,32\",\"enable_s3_shard\":true,\"evaluation_channel_name\":\"evaluation\",\"feature_size\":117581,\"field_size\":39,\"log_steps\":10,\"model_dir\":\"/opt/ml/model\",\"num_epochs\":10,\"perform_shuffle\":0,\"pipe_mode\":0,\"servable_model_dir\":\"/opt/ml/model\",\"training_channel_name\":\"training\",\"training_data_dir\":\"/opt/ml/input/data/training/\",\"val_data_dir\":\"/opt/ml/input/data/evaluation/\",\"worker_per_host\":4},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"evaluation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"ShardedByS3Key\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-scriptmode-deepfm-2021-02-22-15-20-46-020\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-22-15-20-46-020/source/sourcedir.tar.gz\",\"module_name\":\"DeepFM-hvd-tfrecord-vectorized-map\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"DeepFM-hvd-tfrecord-vectorized-map.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"1024\",\"--deep_layers\",\"128,64,32\",\"--enable_s3_shard\",\"True\",\"--evaluation_channel_name\",\"evaluation\",\"--feature_size\",\"117581\",\"--field_size\",\"39\",\"--log_steps\",\"10\",\"--model_dir\",\"/opt/ml/model\",\"--num_epochs\",\"10\",\"--perform_shuffle\",\"0\",\"--pipe_mode\",\"0\",\"--servable_model_dir\",\"/opt/ml/model\",\"--training_channel_name\",\"training\",\"--training_data_dir\",\"/opt/ml/input/data/training/\",\"--val_data_dir\",\"/opt/ml/input/data/evaluation/\",\"--worker_per_host\",\"4\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_EVALUATION=/opt/ml/input/data/evaluation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=1024\u001b[0m\n",
      "\u001b[34mSM_HP_VAL_DATA_DIR=/opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34mSM_HP_LOG_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_FIELD_SIZE=39\u001b[0m\n",
      "\u001b[34mSM_HP_WORKER_PER_HOST=4\u001b[0m\n",
      "\u001b[34mSM_HP_DEEP_LAYERS=128,64,32\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_CHANNEL_NAME=training\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_DATA_DIR=/opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34mSM_HP_PERFORM_SHUFFLE=0\u001b[0m\n",
      "\u001b[34mSM_HP_EVALUATION_CHANNEL_NAME=evaluation\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURE_SIZE=117581\u001b[0m\n",
      "\u001b[34mSM_HP_PIPE_MODE=0\u001b[0m\n",
      "\u001b[34mSM_HP_SERVABLE_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_ENABLE_S3_SHARD=true\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:4 -np 4 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to socket -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/usr/local/lib/python3.6/dist-packages/gethostname.cpython-36m-x86_64-linux-gnu.so -verbose -x OMPI_MCA_btl_vader_single_copy_mechanism=none -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_EVALUATION -x SM_CHANNEL_TRAINING -x SM_HP_BATCH_SIZE -x SM_HP_VAL_DATA_DIR -x SM_HP_LOG_STEPS -x SM_HP_FIELD_SIZE -x SM_HP_WORKER_PER_HOST -x SM_HP_DEEP_LAYERS -x SM_HP_TRAINING_CHANNEL_NAME -x SM_HP_TRAINING_DATA_DIR -x SM_HP_PERFORM_SHUFFLE -x SM_HP_EVALUATION_CHANNEL_NAME -x SM_HP_FEATURE_SIZE -x SM_HP_PIPE_MODE -x SM_HP_SERVABLE_MODEL_DIR -x SM_HP_MODEL_DIR -x SM_HP_ENABLE_S3_SHARD -x SM_HP_NUM_EPOCHS -x PYTHONPATH /usr/bin/python3 -m mpi4py DeepFM-hvd-tfrecord-vectorized-map.py --batch_size 1024 --deep_layers 128,64,32 --enable_s3_shard True --evaluation_channel_name evaluation --feature_size 117581 --field_size 39 --log_steps 10 --model_dir /opt/ml/model --num_epochs 10 --perform_shuffle 0 --pipe_mode 0 --servable_model_dir /opt/ml/model --training_channel_name training --training_data_dir /opt/ml/input/data/training/ --val_data_dir /opt/ml/input/data/evaluation/ --worker_per_host 4\n",
      "\n",
      "\n",
      " Data for JOB [53495,1] offset 0 Total slots allocated 4\n",
      "\n",
      " ========================   JOB MAP   ========================\n",
      "\n",
      " Data for node: ip-10-0-228-231#011Num slots: 4#011Max slots: 0#011Num procs: 4\n",
      " #011Process OMPI jobid: [53495,1] App: 0 Process rank: 0 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [53495,1] App: 0 Process rank: 1 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [53495,1] App: 0 Process rank: 2 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [53495,1] App: 0 Process rank: 3 Bound: UNBOUND\n",
      "\n",
      " =============================================================\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mWARNING: Open MPI tried to bind a process but failed.  This is a\u001b[0m\n",
      "\u001b[34mwarning only; your job will continue, though performance may\u001b[0m\n",
      "\u001b[34mbe degraded.\n",
      "\n",
      "  Local host:        ip-10-0-228-231\n",
      "  Application name:  /usr/bin/python3\n",
      "  Error message:     failed to bind memory\n",
      "  Location:          rtc_hwloc.c:447\n",
      "\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:427: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:427: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:427: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:427: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:427: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:428: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:427: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:427: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:428: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:428: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:427: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:428: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:tr_files: ['/opt/ml/input/data/training/data-2/train.tfrecords', '/opt/ml/input/data/training/data-4/train.tfrecords', '/opt/ml/input/data/training/data-3/train.tfrecords', '/opt/ml/input/data/training/data-1/train.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:va_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:te_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:tr_files: ['/opt/ml/input/data/training/data-4/train.tfrecords', '/opt/ml/input/data/training/data-3/train.tfrecords', '/opt/ml/input/data/training/data-1/train.tfrecords', '/opt/ml/input/data/training/data-2/train.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:va_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:te_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:345: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:345: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:45.666574 140056840611648 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:345: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:tr_files: ['/opt/ml/input/data/training/data-1/train.tfrecords', '/opt/ml/input/data/training/data-2/train.tfrecords', '/opt/ml/input/data/training/data-3/train.tfrecords', '/opt/ml/input/data/training/data-4/train.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:va_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:te_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:45.666629 139968104699712 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:345: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:tr_files: ['/opt/ml/input/data/training/data-4/train.tfrecords', '/opt/ml/input/data/training/data-1/train.tfrecords', '/opt/ml/input/data/training/data-3/train.tfrecords', '/opt/ml/input/data/training/data-2/train.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:va_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:te_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:345: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:45.666898 139881550567232 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:345: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:345: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:current horovod rank is  1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:current horovod rank is  3\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:current horovod rank is  0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:45.667021 140673257371456 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:345: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:current horovod rank is  2\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp936t2t4o\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:45.667579 140056840611648 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp936t2t4o\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpwps4ir50\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:45.667673 139968104699712 estimator.py:1821] Using temporary folder as model directory: /tmp/tmpwps4ir50\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpjuf2r6qv\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Using config: {'_model_dir': '/opt/ml/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  visible_device_list: \"0\"\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f382998a978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:45.667859 140673257371456 estimator.py:1821] Using temporary folder as model directory: /tmp/tmpjuf2r6qv\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:45.667804 139881550567232 estimator.py:212] Using config: {'_model_dir': '/opt/ml/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  visible_device_list: \"0\"\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f382998a978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp936t2t4o', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  visible_device_list: \"1\"\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f60e4b8dbe0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpwps4ir50', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  visible_device_list: \"3\"\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4c4a9a3be0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:45.668400 140056840611648 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp936t2t4o', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  visible_device_list: \"1\"\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:channel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:last channel name training\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:channel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:channel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:last channel name training\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:last channel name training\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:channel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:last channel name training\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f60e4b8dbe0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:45.668442 139968104699712 estimator.py:212] Using config: {'_model_dir': '/tmp/tmpwps4ir50', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  visible_device_list: \"3\"\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4c4a9a3be0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpjuf2r6qv', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  visible_device_list: \"2\"\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff07effcbe0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:45.668579 140673257371456 estimator.py:212] Using config: {'_model_dir': '/tmp/tmpjuf2r6qv', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  visible_device_list: \"2\"\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff07effcbe0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:45.794674 140673257371456 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:45.794636 139881550567232 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:45.794868 139968104699712 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:45.794836 140056840611648 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:45.870958 140056840611648 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:45.871103 140673257371456 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:45.871128 139881550567232 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:45.871314 140056840611648 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:45.871440 140673257371456 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:45.871650 139881550567232 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:45.872185 139968104699712 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:45.872595 139968104699712 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:45.969788 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:148: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:45.970092 139881550567232 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:148: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:45.971078 140673257371456 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:148: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:45.971347 140673257371456 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:148: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:45.972706 139968104699712 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:148: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:45.972967 139968104699712 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:148: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:45.973699 140056840611648 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:148: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:45.974046 140056840611648 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:148: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:45.989766 139881550567232 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:45.992413 140673257371456 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:45.994356 139968104699712 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:45.995189 140056840611648 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:46.005838 139881550567232 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:46.007481 139881550567232 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:46.009130 140673257371456 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:46.010488 139968104699712 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:46.010931 140673257371456 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:46.012168 139968104699712 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:46.016669 140056840611648 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:46.018494 140056840611648 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:200: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:46.024871 139881550567232 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:200: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:200: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:46.028490 140673257371456 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:200: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:200: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:46.030201 139968104699712 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:200: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:200: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:46.035853 140056840611648 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:200: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:217: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:46.103498 139881550567232 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:217: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:46.105923 139881550567232 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:217: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:46.110970 140673257371456 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:217: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:46.113502 140673257371456 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:217: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:46.114028 139968104699712 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:217: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:217: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:46.114257 140056840611648 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:217: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:232: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:46.115508 139881550567232 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:232: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:46.116679 140056840611648 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:46.116744 139968104699712 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:232: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:46.123687 140673257371456 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:232: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:232: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:46.126082 140056840611648 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:232: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:232: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:46.126895 139968104699712 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:232: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:46.180495 139881550567232 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:46.191505 140056840611648 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:46.192597 140673257371456 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:46.196570 139968104699712 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:46.214657 139881550567232 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:46.214929 139881550567232 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:46.225894 140056840611648 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:46.226148 140056840611648 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:46.229077 140673257371456 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:46.229304 140673257371456 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:46.233355 139968104699712 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:46.233605 139968104699712 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:46.595952 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:46.597349 139881550567232 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:46.598010 140056840611648 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:46.599364 140056840611648 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:46.604666 140673257371456 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:46.606113 140673257371456 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:46.619689 139968104699712 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:46.621113 139968104699712 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[ip-10-0-228-231.us-west-2.compute.internal:00084] 3 more processes have sent help message help-orte-odls-default.txt / memory not bound\u001b[0m\n",
      "\u001b[34m[ip-10-0-228-231.us-west-2.compute.internal:00084] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:46.876822 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:46.878323 140056840611648 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:46.895023 140673257371456 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:46.915012 139968104699712 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:49.888450 139968104699712 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:49.888441 140673257371456 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:49.897702 140056840611648 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:49.913689 140673257371456 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:49.914006 139968104699712 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:49.921714 140056840611648 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:49.925776 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:49.948683 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:50.406215 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:50.415779 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:50.418612 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:50.420537 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.228.231<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL version 2.4.7+cuda10.0\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.228.231<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.228.231<0>\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.228.231<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Channel 00 :    0   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Channel 01 :    0   2   1   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Channel 02 :    0   3   1   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Channel 03 :    0   3   2   1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Channel 04 :    0   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Channel 05 :    0   2   1   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Channel 06 :    0   3   1   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Channel 07 :    0   3   2   1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] NCCL INFO Ring 00 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Ring 00 : 0[0] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] NCCL INFO Ring 00 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 00 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] NCCL INFO Ring 01 : 1[1] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Ring 01 : 0[0] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] NCCL INFO Ring 01 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 01 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Ring 02 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] NCCL INFO Ring 02 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] NCCL INFO Ring 02 : 3[3] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 02 : 2[2] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] NCCL INFO Ring 03 : 1[1] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Ring 03 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 03 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] NCCL INFO Ring 03 : 3[3] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] NCCL INFO Ring 04 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Ring 04 : 0[0] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] NCCL INFO Ring 04 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 04 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] NCCL INFO Ring 05 : 1[1] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Ring 05 : 0[0] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] NCCL INFO Ring 05 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 05 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Ring 06 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] NCCL INFO Ring 06 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] NCCL INFO Ring 06 : 3[3] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 06 : 2[2] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] NCCL INFO Ring 07 : 1[1] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Ring 07 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] NCCL INFO Ring 07 : 3[3] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 07 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO comm 0x7f37d871d4a0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:371 [1] NCCL INFO comm 0x7f60a870db90 rank 1 nranks 4 cudaDev 1 nvmlDev 1 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:372 [3] NCCL INFO comm 0x7f4c0070c260 rank 3 nranks 4 cudaDev 3 nvmlDev 3 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO comm 0x7ff03070cf40 rank 2 nranks 4 cudaDev 2 nvmlDev 2 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:369 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.6943944, step = 0\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.69365454, step = 0\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:51.788891 140673257371456 basic_session_run_hooks.py:262] loss = 0.69365454, step = 0\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.6935237, step = 0\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.6937627, step = 0\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:51.789034 139968104699712 basic_session_run_hooks.py:262] loss = 0.6935237, step = 0\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:51.788904 139881550567232 basic_session_run_hooks.py:262] loss = 0.6943944, step = 0\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:51.789038 140056840611648 basic_session_run_hooks.py:262] loss = 0.6937627, step = 0\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:53.554712 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:53.554768 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:53.557054 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:53.557064 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.3946376.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:53.692542 140056840611648 estimator.py:371] Loss for final step: 0.3946376.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.37752947.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:53.694094 139881550567232 estimator.py:371] Loss for final step: 0.37752947.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.41241243.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:53.697297 139968104699712 estimator.py:371] Loss for final step: 0.41241243.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.38846108.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:53.704674 140673257371456 estimator.py:371] Loss for final step: 0.38846108.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:53.739218 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:53.740992 140056840611648 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:53.774466 139968104699712 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:53.782423 140673257371456 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:53.969497 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-22T15:24:53Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:53.989476 139881550567232 evaluation.py:255] Starting evaluation at 2021-02-22T15:24:53Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:54.082386 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:54.090322 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:54.172391 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:54.192772 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:54.341959 140056840611648 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:54.343328 140056840611648 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:54.381080 139968104699712 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:54.382460 139968104699712 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:54.478903 140673257371456 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:54.480343 140673257371456 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-22-15:24:54\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:54.495081 139881550567232 evaluation.py:275] Finished evaluation at 2021-02-22-15:24:54\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 97: auc = 0.7457037, global_step = 97, loss = 0.57336247\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:54.495309 139881550567232 estimator.py:2049] Saving dict for global step 97: auc = 0.7457037, global_step = 97, loss = 0.57336247\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 97: /opt/ml/model/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:54.551012 139881550567232 estimator.py:2109] Saving 'checkpoint_path' summary for global step 97: /opt/ml/model/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:54.593255 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:54.620574 140056840611648 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:54.629152 140056840611648 saver.py:1290] Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:54.651295 139968104699712 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:54.660272 139968104699712 saver.py:1290] Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:24:54.746314 140056840611648 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:24:54.776369 139968104699712 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:54.782111 140673257371456 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:54.790780 140673257371456 saver.py:1290] Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:54.815468 140056840611648 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:54.839367 140056840611648 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:54.843729 139968104699712 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:54.867649 139968104699712 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:24:54.916141 140673257371456 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:54.989676 140673257371456 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:55.014965 140673257371456 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:55.280483 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:55.281866 139881550567232 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:55.331409 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:55.373142 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:55.471419 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:55.479976 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:55.553603 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:24:55.600495 139881550567232 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:55.669731 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:55.697227 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:56.179673 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.36822578, step = 97\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.39297128, step = 97\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.3928118, step = 97\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:56.726689 139968104699712 basic_session_run_hooks.py:262] loss = 0.36822578, step = 97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.41246474, step = 97\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:56.726760 140673257371456 basic_session_run_hooks.py:262] loss = 0.3928118, step = 97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:56.726828 139881550567232 basic_session_run_hooks.py:262] loss = 0.41246474, step = 97\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:56.726677 140056840611648 basic_session_run_hooks.py:262] loss = 0.39297128, step = 97\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:58.855982 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:58.857591 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:58.862053 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:58.863891 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.33387458.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:58.996141 139968104699712 estimator.py:371] Loss for final step: 0.33387458.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.30866474.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:59.001882 139881550567232 estimator.py:371] Loss for final step: 0.30866474.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.3364853.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:59.002642 140673257371456 estimator.py:371] Loss for final step: 0.3364853.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.30432734.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:59.005461 140056840611648 estimator.py:371] Loss for final step: 0.30432734.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:59.036066 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:59.037537 139968104699712 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:59.045051 140673257371456 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:59.047147 140056840611648 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:59.243743 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-22T15:24:59Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:59.262385 139881550567232 evaluation.py:255] Starting evaluation at 2021-02-22T15:24:59Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:59.349954 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:59.357773 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:59.431283 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:59.449922 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:59.629412 139968104699712 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:59.630782 139968104699712 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:59.642440 140056840611648 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:59.643782 140056840611648 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:59.658409 140673257371456 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:59.659850 140673257371456 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-22-15:24:59\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:59.691317 139881550567232 evaluation.py:275] Finished evaluation at 2021-02-22-15:24:59\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 194: auc = 0.7168311, global_step = 194, loss = 0.817937\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:59.691528 139881550567232 estimator.py:2049] Saving dict for global step 194: auc = 0.7168311, global_step = 194, loss = 0.817937\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 194: /opt/ml/model/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:59.691906 139881550567232 estimator.py:2109] Saving 'checkpoint_path' summary for global step 194: /opt/ml/model/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:24:59.731743 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:59.817139 139968104699712 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:24:59.825134 139968104699712 saver.py:1290] Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:59.830509 140056840611648 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:24:59.838927 140056840611648 saver.py:1290] Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:59.852471 140673257371456 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:24:59.860752 140673257371456 saver.py:1290] Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:00.008668 139968104699712 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:00.032801 139968104699712 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:00.036206 140056840611648 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:00.069013 140056840611648 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:00.076472 140673257371456 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:00.100820 140673257371456 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:00.327431 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:00.328814 139881550567232 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:00.514853 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:00.523352 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:00.536283 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:00.559314 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:00.634979 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:00.717363 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:00.760399 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:01.256433 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.32387498, step = 194\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.2947387, step = 194\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.32068095, step = 194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.33767414, step = 194\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:01.813840 140056840611648 basic_session_run_hooks.py:262] loss = 0.32068095, step = 194\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:01.813838 140673257371456 basic_session_run_hooks.py:262] loss = 0.32387498, step = 194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:01.813862 139881550567232 basic_session_run_hooks.py:262] loss = 0.33767414, step = 194\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:01.813819 139968104699712 basic_session_run_hooks.py:262] loss = 0.2947387, step = 194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:04.092134 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:04.092180 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:04.092221 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:04.097657 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.29401863.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:04.230659 139968104699712 estimator.py:371] Loss for final step: 0.29401863.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.27087474.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:04.234992 139881550567232 estimator.py:371] Loss for final step: 0.27087474.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.2742606.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:04.237093 140056840611648 estimator.py:371] Loss for final step: 0.2742606.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.29181245.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:04.239436 140673257371456 estimator.py:371] Loss for final step: 0.29181245.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:04.271328 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:04.273393 139968104699712 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:04.280110 140056840611648 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:04.282480 140673257371456 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:04.487738 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-22T15:25:04Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:04.507262 139881550567232 evaluation.py:255] Starting evaluation at 2021-02-22T15:25:04Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:04.597988 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:04.606160 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:04.682428 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:04.701332 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:04.874987 139968104699712 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:04.876335 139968104699712 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:04.879162 140056840611648 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:04.880512 140056840611648 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:04.894942 140673257371456 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:04.896320 140673257371456 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-22-15:25:04\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:04.954101 139881550567232 evaluation.py:275] Finished evaluation at 2021-02-22-15:25:04\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 291: auc = 0.71206015, global_step = 291, loss = 1.0838904\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:04.954337 139881550567232 estimator.py:2049] Saving dict for global step 291: auc = 0.71206015, global_step = 291, loss = 1.0838904\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 291: /opt/ml/model/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:04.954807 139881550567232 estimator.py:2109] Saving 'checkpoint_path' summary for global step 291: /opt/ml/model/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:04.995995 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:05.067300 139968104699712 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:05.069082 140056840611648 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:05.080926 139968104699712 saver.py:1290] Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:05.083079 140056840611648 saver.py:1290] Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:05.090498 140673257371456 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:05.098970 140673257371456 saver.py:1290] Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:05.269031 140056840611648 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:05.274285 139968104699712 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:05.294954 140673257371456 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:05.295018 140056840611648 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:05.298966 139968104699712 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:05.320458 140673257371456 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:05.601207 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:05.602621 139881550567232 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:05.790797 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:05.791507 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:05.800100 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:05.809787 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:05.853649 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:05.992584 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:06.016884 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:06.504737 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.2727826, step = 291\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.24343872, step = 291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.29794997, step = 291\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:07.063090 139968104699712 basic_session_run_hooks.py:262] loss = 0.24343872, step = 291\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:07.063009 140056840611648 basic_session_run_hooks.py:262] loss = 0.2727826, step = 291\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.28028357, step = 291\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:07.063226 140673257371456 basic_session_run_hooks.py:262] loss = 0.28028357, step = 291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:07.063120 139881550567232 basic_session_run_hooks.py:262] loss = 0.29794997, step = 291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:09.176705 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:09.178293 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:09.178537 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:09.186361 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.24384609.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:09.320733 140056840611648 estimator.py:371] Loss for final step: 0.24384609.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.28246987.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:09.321046 139968104699712 estimator.py:371] Loss for final step: 0.28246987.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.24491888.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:09.322906 139881550567232 estimator.py:371] Loss for final step: 0.24491888.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.25299513.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:09.332716 140673257371456 estimator.py:371] Loss for final step: 0.25299513.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:09.358609 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:09.362219 139968104699712 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:09.363851 140056840611648 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:09.375689 140673257371456 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:09.691318 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-22T15:25:09Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:09.710354 139881550567232 evaluation.py:255] Starting evaluation at 2021-02-22T15:25:09Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:09.798882 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:09.806934 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:09.885833 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:09.905075 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:09.959006 139968104699712 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:09.960404 139968104699712 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:09.987961 140673257371456 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:09.989339 140673257371456 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:09.991497 140056840611648 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:09.992905 140056840611648 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:10.153995 139968104699712 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-22-15:25:10\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:10.162373 139881550567232 evaluation.py:275] Finished evaluation at 2021-02-22-15:25:10\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 388: auc = 0.70954746, global_step = 388, loss = 1.2868143\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:10.162539 139968104699712 saver.py:1290] Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:10.162606 139881550567232 estimator.py:2049] Saving dict for global step 388: auc = 0.70954746, global_step = 388, loss = 1.2868143\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 388: /opt/ml/model/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:10.163075 139881550567232 estimator.py:2109] Saving 'checkpoint_path' summary for global step 388: /opt/ml/model/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:10.183047 140673257371456 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:10.190232 140056840611648 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:10.192250 140673257371456 saver.py:1290] Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:10.198727 140056840611648 saver.py:1290] Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:10.205072 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:10.357319 139968104699712 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:10.381038 139968104699712 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:10.392082 140056840611648 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:10.395561 140673257371456 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:10.416352 140056840611648 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:10.418758 140673257371456 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:10.824354 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:10.825820 139881550567232 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:10.876104 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:10.902886 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:10.932557 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:11.023131 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:11.033312 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:11.233786 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:11.259345 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:11.747436 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.29251713, step = 388\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.25320512, step = 388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.27359617, step = 388\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:12.303546 139968104699712 basic_session_run_hooks.py:262] loss = 0.25320512, step = 388\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:12.303546 140673257371456 basic_session_run_hooks.py:262] loss = 0.29251713, step = 388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:12.303589 139881550567232 basic_session_run_hooks.py:262] loss = 0.27359617, step = 388\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.26565394, step = 388\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:12.303673 140056840611648 basic_session_run_hooks.py:262] loss = 0.26565394, step = 388\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:14.433297 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:14.434646 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:14.434745 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:14.440004 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:25:14.496603 139968104699712 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:25:14.499420 139881550567232 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:25:14.500884 140673257371456 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:25:14.502478 140056840611648 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.25693443.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:14.585196 139968104699712 estimator.py:371] Loss for final step: 0.25693443.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.23769873.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:14.586658 139881550567232 estimator.py:371] Loss for final step: 0.23769873.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.25302693.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:14.590476 140673257371456 estimator.py:371] Loss for final step: 0.25302693.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.2537822.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:14.593017 140056840611648 estimator.py:371] Loss for final step: 0.2537822.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:14.621256 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:14.625879 139968104699712 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:14.632229 140673257371456 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:14.633597 140056840611648 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:14.828372 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-22T15:25:14Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:14.846986 139881550567232 evaluation.py:255] Starting evaluation at 2021-02-22T15:25:14Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:14.935609 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:14.943705 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:15.021480 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:15.040297 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-22-15:25:15\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:15.285092 139881550567232 evaluation.py:275] Finished evaluation at 2021-02-22-15:25:15\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 485: auc = 0.6966761, global_step = 485, loss = 1.2423573\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:15.285315 139881550567232 estimator.py:2049] Saving dict for global step 485: auc = 0.6966761, global_step = 485, loss = 1.2423573\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 485: /opt/ml/model/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:15.285735 139881550567232 estimator.py:2109] Saving 'checkpoint_path' summary for global step 485: /opt/ml/model/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:15.326361 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:15.353946 139968104699712 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:15.355321 139968104699712 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:15.365528 140056840611648 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:15.366983 140056840611648 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:15.372681 140673257371456 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:15.374094 140673257371456 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:15.544117 139968104699712 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:15.552746 139968104699712 saver.py:1290] Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:15.556362 140056840611648 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:15.564889 140056840611648 saver.py:1290] Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:15.567301 140673257371456 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:15.575681 140673257371456 saver.py:1290] Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:15.743076 139968104699712 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:15.754706 140056840611648 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:15.767318 139968104699712 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:15.777443 140673257371456 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:15.778751 140056840611648 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:15.801662 140673257371456 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:15.921927 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:15.923299 139881550567232 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:16.109202 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:16.117810 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:16.268307 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:16.271175 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:16.301106 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:16.319385 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:16.326924 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:16.847817 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.23874158, step = 485\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.2481941, step = 485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.23532146, step = 485\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.23004073, step = 485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:17.419432 139881550567232 basic_session_run_hooks.py:262] loss = 0.23532146, step = 485\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:17.419468 139968104699712 basic_session_run_hooks.py:262] loss = 0.23004073, step = 485\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:17.419399 140056840611648 basic_session_run_hooks.py:262] loss = 0.2481941, step = 485\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:17.419400 140673257371456 basic_session_run_hooks.py:262] loss = 0.23874158, step = 485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:19.550589 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:19.550760 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:19.550914 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:19.555937 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.21320534.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:19.699468 139881550567232 estimator.py:371] Loss for final step: 0.21320534.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.21636078.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:19.706008 139968104699712 estimator.py:371] Loss for final step: 0.21636078.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.19972792.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:19.719864 140056840611648 estimator.py:371] Loss for final step: 0.19972792.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.21033365.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:19.729302 140673257371456 estimator.py:371] Loss for final step: 0.21033365.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:19.734170 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:19.749387 139968104699712 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:19.760106 140056840611648 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:19.772035 140673257371456 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:19.940414 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-22T15:25:19Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:19.959047 139881550567232 evaluation.py:255] Starting evaluation at 2021-02-22T15:25:19Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:20.046165 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:20.054174 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:20.129209 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:20.148245 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:20.351077 140056840611648 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:20.352405 140056840611648 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:20.382674 139968104699712 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:20.384138 139968104699712 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:20.384931 140673257371456 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:20.386333 140673257371456 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-22-15:25:20\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:20.388010 139881550567232 evaluation.py:275] Finished evaluation at 2021-02-22-15:25:20\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 582: auc = 0.6999034, global_step = 582, loss = 1.5914452\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:20.388233 139881550567232 estimator.py:2049] Saving dict for global step 582: auc = 0.6999034, global_step = 582, loss = 1.5914452\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 582: /opt/ml/model/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:20.388604 139881550567232 estimator.py:2109] Saving 'checkpoint_path' summary for global step 582: /opt/ml/model/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:20.428056 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:20.537981 140056840611648 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:20.546479 140056840611648 saver.py:1290] Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:20.577375 140673257371456 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:20.582660 139968104699712 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:20.586282 140673257371456 saver.py:1290] Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:20.591856 139968104699712 saver.py:1290] Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:20.731047 140056840611648 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:20.754429 140056840611648 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:20.775440 140673257371456 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:20.787229 139968104699712 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:20.799155 140673257371456 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:20.812172 139968104699712 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:21.133831 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:21.135194 139881550567232 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:21.242241 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:21.309609 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:21.320787 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:21.329389 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:21.330804 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:21.527380 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:21.554370 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:22.042295 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.22403768, step = 582\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.20208186, step = 582\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:22.593784 139968104699712 basic_session_run_hooks.py:262] loss = 0.20208186, step = 582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:22.593733 139881550567232 basic_session_run_hooks.py:262] loss = 0.22403768, step = 582\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.21647167, step = 582\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:22.593950 140056840611648 basic_session_run_hooks.py:262] loss = 0.21647167, step = 582\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.20174739, step = 582\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:22.594417 140673257371456 basic_session_run_hooks.py:262] loss = 0.20174739, step = 582\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:24.724201 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:24.724243 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:24.724417 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:24.730021 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.21962357.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:24.878312 140673257371456 estimator.py:371] Loss for final step: 0.21962357.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.2026425.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:24.880469 139881550567232 estimator.py:371] Loss for final step: 0.2026425.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.1846335.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:24.894593 140056840611648 estimator.py:371] Loss for final step: 0.1846335.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.2101298.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:24.898248 139968104699712 estimator.py:371] Loss for final step: 0.2101298.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:24.917840 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:24.920324 140673257371456 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:24.935096 140056840611648 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:24.938871 139968104699712 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:25.138258 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-22T15:25:25Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:25.158760 139881550567232 evaluation.py:255] Starting evaluation at 2021-02-22T15:25:25Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:25.250530 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:25.258503 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:25.338905 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:25.359095 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:25.526300 140056840611648 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:25.527623 140056840611648 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:25.531987 140673257371456 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:25.533360 140673257371456 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:25.535329 139968104699712 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:25.536716 139968104699712 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-22-15:25:25\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:25.609607 139881550567232 evaluation.py:275] Finished evaluation at 2021-02-22-15:25:25\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 679: auc = 0.6902439, global_step = 679, loss = 1.645525\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:25.609844 139881550567232 estimator.py:2049] Saving dict for global step 679: auc = 0.6902439, global_step = 679, loss = 1.645525\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 679: /opt/ml/model/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:25.610285 139881550567232 estimator.py:2109] Saving 'checkpoint_path' summary for global step 679: /opt/ml/model/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:25.652057 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:25.715755 140056840611648 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:25.724200 140056840611648 saver.py:1290] Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:25.727618 140673257371456 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:25.727884 139968104699712 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:25.742459 140673257371456 saver.py:1290] Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:25.743501 139968104699712 saver.py:1290] Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:25.906872 140056840611648 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:25.929767 140056840611648 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:25.930475 140673257371456 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:25.932682 139968104699712 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:25.955062 140673257371456 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:25.956866 139968104699712 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:26.274815 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:26.276213 139881550567232 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:26.412936 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:26.468817 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:26.471165 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:26.480378 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:26.492459 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:26.684484 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:26.708715 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:27.184118 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.20656705, step = 679\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.1974219, step = 679\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:27.736428 140056840611648 basic_session_run_hooks.py:262] loss = 0.20656705, step = 679\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:27.736469 139968104699712 basic_session_run_hooks.py:262] loss = 0.1974219, step = 679\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.20434833, step = 679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.22429606, step = 679\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:27.736599 140673257371456 basic_session_run_hooks.py:262] loss = 0.20434833, step = 679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:27.736599 139881550567232 basic_session_run_hooks.py:262] loss = 0.22429606, step = 679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:29.852524 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:29.852643 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:29.852826 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:29.864190 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.19657604.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:29.997763 140673257371456 estimator.py:371] Loss for final step: 0.19657604.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.21327323.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:30.000607 139881550567232 estimator.py:371] Loss for final step: 0.21327323.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.2044187.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:30.001700 140056840611648 estimator.py:371] Loss for final step: 0.2044187.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.21665958.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:30.018456 139968104699712 estimator.py:371] Loss for final step: 0.21665958.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:30.036247 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:30.042568 140056840611648 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:30.049463 140673257371456 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:30.060958 139968104699712 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:30.244125 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-22T15:25:30Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:30.262807 139881550567232 evaluation.py:255] Starting evaluation at 2021-02-22T15:25:30Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:30.349661 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:30.357648 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:30.432010 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:30.451547 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:30.633130 140056840611648 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:30.634499 140056840611648 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:30.666117 139968104699712 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:30.667470 139968104699712 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-22-15:25:30\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:30.696603 139881550567232 evaluation.py:275] Finished evaluation at 2021-02-22-15:25:30\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 776: auc = 0.6801913, global_step = 776, loss = 1.6055737\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:30.696831 139881550567232 estimator.py:2049] Saving dict for global step 776: auc = 0.6801913, global_step = 776, loss = 1.6055737\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 776: /opt/ml/model/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:30.697295 139881550567232 estimator.py:2109] Saving 'checkpoint_path' summary for global step 776: /opt/ml/model/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:30.707014 140673257371456 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:30.708505 140673257371456 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:30.739773 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:30.960908 140056840611648 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:30.969491 140056840611648 saver.py:1290] Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:30.994769 139968104699712 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:31.004081 139968104699712 saver.py:1290] Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:31.054611 140673257371456 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:31.063473 140673257371456 saver.py:1290] Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:31.163790 140056840611648 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:31.189860 140056840611648 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:31.196517 139968104699712 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:31.222786 139968104699712 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:31.271495 140673257371456 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:31.297657 140673257371456 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:31.344123 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:31.345456 139881550567232 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:31.532925 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:31.541337 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:31.690354 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:31.724030 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:31.747563 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:31.750814 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:31.853055 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:32.255768 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.19555151, step = 776\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.20299262, step = 776\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:32.805054 139881550567232 basic_session_run_hooks.py:262] loss = 0.19555151, step = 776\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.19765249, step = 776\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:32.805160 140056840611648 basic_session_run_hooks.py:262] loss = 0.20299262, step = 776\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.19027945, step = 776\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:32.805268 140673257371456 basic_session_run_hooks.py:262] loss = 0.19765249, step = 776\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:32.805330 139968104699712 basic_session_run_hooks.py:262] loss = 0.19027945, step = 776\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-02-22 15:25:42 Uploading - Uploading generated training model\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:34.919904 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:34.919940 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:34.919984 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:34.922157 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.1983267.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:35.070937 139968104699712 estimator.py:371] Loss for final step: 0.1983267.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.18079913.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:35.072360 140056840611648 estimator.py:371] Loss for final step: 0.18079913.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.19570827.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:35.095901 139881550567232 estimator.py:371] Loss for final step: 0.19570827.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.19169688.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:35.098666 140673257371456 estimator.py:371] Loss for final step: 0.19169688.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:35.112883 139968104699712 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:35.113507 140056840611648 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:35.130518 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:35.141138 140673257371456 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:35.339272 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-22T15:25:35Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:35.358006 139881550567232 evaluation.py:255] Starting evaluation at 2021-02-22T15:25:35Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:35.445424 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:35.453410 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:35.527224 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:35.545750 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:35.699406 140056840611648 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:35.700725 140056840611648 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:35.709718 139968104699712 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:35.711087 139968104699712 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:35.750462 140673257371456 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:35.751873 140673257371456 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-22-15:25:35\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:35.785423 139881550567232 evaluation.py:275] Finished evaluation at 2021-02-22-15:25:35\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 873: auc = 0.6754233, global_step = 873, loss = 1.6236144\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:35.785675 139881550567232 estimator.py:2049] Saving dict for global step 873: auc = 0.6754233, global_step = 873, loss = 1.6236144\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 873: /opt/ml/model/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:35.786123 139881550567232 estimator.py:2109] Saving 'checkpoint_path' summary for global step 873: /opt/ml/model/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:35.826211 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:35.885876 140056840611648 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:35.894438 140056840611648 saver.py:1290] Restoring parameters from /tmp/tmp936t2t4o/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:35.900035 139968104699712 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:35.908376 139968104699712 saver.py:1290] Restoring parameters from /tmp/tmpwps4ir50/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:35.945009 140673257371456 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:35.953667 140673257371456 saver.py:1290] Restoring parameters from /tmp/tmpjuf2r6qv/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:36.081318 140056840611648 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:36.099678 139968104699712 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:36.105467 140056840611648 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:36.123927 139968104699712 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:36.145477 140673257371456 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:36.169486 140673257371456 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:36.559486 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:36.560880 139881550567232 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:36.584541 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:36.620608 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:36.681198 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:36.782649 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:36.792227 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:36.985080 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:37.010158 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:37.483721 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.19829196, step = 873\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.21080428, step = 873\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.20711556, step = 873\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:38.034440 140056840611648 basic_session_run_hooks.py:262] loss = 0.21080428, step = 873\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:38.034380 139968104699712 basic_session_run_hooks.py:262] loss = 0.19829196, step = 873\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:38.034504 140673257371456 basic_session_run_hooks.py:262] loss = 0.20711556, step = 873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.20949084, step = 873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:38.034755 139881550567232 basic_session_run_hooks.py:262] loss = 0.20949084, step = 873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 970 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:40.170547 139881550567232 basic_session_run_hooks.py:606] Saving checkpoints for 970 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 970 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:40.170815 140673257371456 basic_session_run_hooks.py:606] Saving checkpoints for 970 into /tmp/tmpjuf2r6qv/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 970 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:40.171266 140056840611648 basic_session_run_hooks.py:606] Saving checkpoints for 970 into /tmp/tmp936t2t4o/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 970 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:40.176007 139968104699712 basic_session_run_hooks.py:606] Saving checkpoints for 970 into /tmp/tmpwps4ir50/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.18793565.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:40.318441 139881550567232 estimator.py:371] Loss for final step: 0.18793565.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.20555563.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 15:25:40.321931 140056840611648 estimator.py:371] Loss for final step: 0.20555563.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.18777938.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:416: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 15:25:40.322194 140673257371456 estimator.py:371] Loss for final step: 0.18777938.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 15:25:40.322329 140056840611648 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:416: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:416: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 15:25:40.322520 140673257371456 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:416: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.1809.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 15:25:40.324326 139968104699712 estimator.py:371] Loss for final step: 0.1809.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:416: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 15:25:40.324661 139968104699712 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:416: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:40.354587 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:40.566996 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-22T15:25:40Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:40.585906 139881550567232 evaluation.py:255] Starting evaluation at 2021-02-22T15:25:40Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:40.673950 139881550567232 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-970\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:40.681981 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-970\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:40.760334 139881550567232 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:40.781352 139881550567232 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-22-15:25:41\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.035430 139881550567232 evaluation.py:275] Finished evaluation at 2021-02-22-15:25:41\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 970: auc = 0.6791789, global_step = 970, loss = 1.826312\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.035650 139881550567232 estimator.py:2049] Saving dict for global step 970: auc = 0.6791789, global_step = 970, loss = 1.826312\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 970: /opt/ml/model/model.ckpt-970\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.036091 139881550567232 estimator.py:2109] Saving 'checkpoint_path' summary for global step 970: /opt/ml/model/model.ckpt-970\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:416: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:25:41.036628 139881550567232 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:416: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:424: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:This function has been renamed, use `export_saved_model` instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:25:41.038217 139881550567232 deprecation.py:323] From DeepFM-hvd-tfrecord-vectorized-map.py:424: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:This function has been renamed, use `export_saved_model` instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.045809 139881550567232 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.146121 139881550567232 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 15:25:41.146379 139881550567232 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.146702 139881550567232 export_utils.py:170] Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.146810 139881550567232 export_utils.py:170] Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.146895 139881550567232 export_utils.py:170] Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.146962 139881550567232 export_utils.py:170] Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.147021 139881550567232 export_utils.py:170] Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/model/model.ckpt-970\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.191919 139881550567232 saver.py:1290] Restoring parameters from /opt/ml/model/model.ckpt-970\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets added to graph.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.260353 139881550567232 builder_impl.py:665] Assets added to graph.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.260551 139881550567232 builder_impl.py:460] No assets to write.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:SavedModel written to: /opt/ml/model/temp-1614007541/saved_model.pb\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 15:25:41.317967 139881550567232 builder_impl.py:425] SavedModel written to: /opt/ml/model/temp-1614007541/saved_model.pb\u001b[0m\n",
      "\u001b[34m2021-02-22 15:25:41,879 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-02-22 15:26:18 Completed - Training job completed\n",
      "Training seconds: 177\n",
      "Billable seconds: 53\n",
      "Managed Spot Training savings: 70.1%\n"
     ]
    }
   ],
   "source": [
    "#下面这个测试file mode\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/training/'\n",
    "validate_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/val/'\n",
    "\n",
    "if enable_s3_shard:\n",
    "    train_input = TrainingInput(train_s3_uri, distribution='ShardedByS3Key')\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "else :\n",
    "    train_input = TrainingInput(train_s3_uri)\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "\n",
    "inputs = {training_channel_name : train_input, evaluation_channel_name : val_input}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipe mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面用多个spot实例进行parameter server方式的分布式训练。\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "dt_now = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "bucket = 'sagemaker-us-west-2-169088282855'\n",
    "checkpoint_s3_uri = 's3://{}/deepfm-checkpoint/{}'.format(bucket, dt_now) #Change to your own path if you want to save ckpt during training\n",
    "checkpoint_local_path = '/opt/ml/checkpoints'\n",
    "model_dir = '/opt/ml/model'\n",
    "output_path= 's3://{}/deepfm-2021'.format(bucket)\n",
    "\n",
    "training_channel_name = 'training'\n",
    "evaluation_channel_name = 'evaluation'\n",
    "\n",
    "train_instance_type = 'ml.p3.8xlarge'\n",
    "hvd_processes_per_host = 4\n",
    "train_instance_count= 1\n",
    "\n",
    "train_use_spot_instances = True\n",
    "enable_s3_shard = True\n",
    "enable_data_multi_path = False\n",
    "\n",
    "train_max_run=36000*2\n",
    "train_max_wait = 72000 if train_use_spot_instances else None\n",
    "\n",
    "distributions = {'mpi': {\n",
    "                    'enabled': True,\n",
    "                    'processes_per_host': hvd_processes_per_host,\n",
    "                    'custom_mpi_options': '-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none'\n",
    "                        }\n",
    "                }\n",
    "\n",
    "deep_layer = '128,64,32'\n",
    "\n",
    "batch_size = 1024\n",
    "feature_size = 117581\n",
    "\n",
    "base_job_name='tf-scriptmode-deepfm'\n",
    "\n",
    "hyperparameters = {'servable_model_dir': '/opt/ml/model', 'training_data_dir': '/opt/ml/input/data/training/',\n",
    "                   'val_data_dir': '/opt/ml/input/data/evaluation/', 'log_steps': 10, 'num_epochs': 10, \n",
    "                   'field_size': 39, 'feature_size': feature_size, 'deep_layers': deep_layer,\n",
    "                   'perform_shuffle': 0, 'batch_size': batch_size, 'pipe_mode': 1, 'enable_s3_shard': enable_s3_shard,\n",
    "                   'training_channel_name': training_channel_name, 'evaluation_channel_name': evaluation_channel_name,\n",
    "                   'worker_per_host': hvd_processes_per_host, 'enable_data_multi_path': enable_data_multi_path\n",
    "                  }\n",
    "\n",
    "estimator = TensorFlow(\n",
    "                       #source_dir='./',\n",
    "                       entry_point='DeepFM-hvd-tfrecord-vectorized-map.py',\n",
    "                       model_dir=model_dir,\n",
    "                       #checkpoint_s3_uri = checkpoint_s3_uri,\n",
    "                       #checkpoint_local_path = checkpoint_local_path,\n",
    "                       output_path= output_path,\n",
    "                       instance_type=train_instance_type,\n",
    "                       instance_count=train_instance_count,\n",
    "                       #volume_size = 500,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       base_job_name=base_job_name,\n",
    "                       framework_version='1.14',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True,\n",
    "                       input_mode='Pipe',\n",
    "                       distribution=distributions,\n",
    "                       use_spot_instances=train_use_spot_instances,\n",
    "                       max_wait=train_max_wait,\n",
    "                       max_run=train_max_run,\n",
    "                       debugger_hook_config =False,\n",
    "                       disable_profiler=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-22 16:22:47 Starting - Starting the training job...\n",
      "2021-02-22 16:22:50 Starting - Launching requested ML instances.........\n",
      "2021-02-22 16:24:31 Starting - Preparing the instances for training...\n",
      "2021-02-22 16:25:07 Downloading - Downloading input data...\n",
      "2021-02-22 16:25:39 Training - Downloading the training image...\n",
      "2021-02-22 16:26:11 Training - Training image download completed. Training in progress..\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      " Data for JOB [60595,1] offset 0 Total slots allocated 4\n",
      "\n",
      " ========================   JOB MAP   ========================\n",
      "\n",
      " Data for node: ip-10-0-138-82#011Num slots: 4#011Max slots: 0#011Num procs: 4\n",
      " #011Process OMPI jobid: [60595,1] App: 0 Process rank: 0 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [60595,1] App: 0 Process rank: 1 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [60595,1] App: 0 Process rank: 2 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [60595,1] App: 0 Process rank: 3 Bound: UNBOUND\n",
      "\n",
      " =============================================================\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mWARNING: Open MPI tried to bind a process but failed.  This is a\u001b[0m\n",
      "\u001b[34mwarning only; your job will continue, though performance may\u001b[0m\n",
      "\u001b[34mbe degraded.\n",
      "\n",
      "  Local host:        ip-10-0-138-82\n",
      "  Application name:  /usr/local/bin/python3.6\n",
      "  Error message:     failed to bind memory\n",
      "  Location:          rtc_hwloc.c:447\n",
      "\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:18.361292 140014048130816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:18.361295 140121141290752 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:18.361276 140432338822912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:18.361561 140121141290752 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:18.361559 140014048130816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:18.361575 140432338822912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:18.396287 140389551736576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:18.396631 140389551736576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:19.996749 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:19.996992 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:19.997004 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:19.997122 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:439: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:19.997040 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:19.997065 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:19.997264 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:19.997274 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:19.997294 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:19.997411 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:439: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:19.997408 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:439: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:19.997412 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:439: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_data_multi_path', 'False', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '1', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_data_multi_path', 'False', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '1', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_data_multi_path', 'False', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '1', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_data_multi_path', 'False', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '1', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:tr_files: \u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:va_files: \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:te_files: \u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:tr_files: \u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:va_files: \u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:te_files: \u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.090069 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:356: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.090591 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:356: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.091612 140389551736576 estimator.py:1811] Using temporary folder as model directory: /tmp/tmprf6zrzsz\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:20.092479 140389551736576 estimator.py:209] Using config: {'_model_dir': '/tmp/tmprf6zrzsz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  visible_device_list: \"2\"\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fae5492b0f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.090213 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:356: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.091440 140121141290752 estimator.py:1811] Using temporary folder as model directory: /tmp/tmp2i5sxaku\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:20.092334 140121141290752 estimator.py:209] Using config: {'_model_dir': '/tmp/tmp2i5sxaku', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  visible_device_list: \"3\"\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6fd6255080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.090919 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:356: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:20.091127 140014048130816 estimator.py:209] Using config: {'_model_dir': '/opt/ml/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  visible_device_list: \"0\"\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f56e6e940b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.091942 140432338822912 estimator.py:1811] Using temporary folder as model directory: /tmp/tmprvma3v0m\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:20.092905 140432338822912 estimator.py:209] Using config: {'_model_dir': '/tmp/tmprvma3v0m', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  visible_device_list: \"1\"\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb84afac0f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:tr_files: \u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:va_files: \u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:te_files: \u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:current horovod rank is  2\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:tr_files: \u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:va_files: \u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:te_files: \u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:current horovod rank is  1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:current horovod rank is  0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:channel name ['evaluation', 'training', 'training-1', 'training-2', 'training-3']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:last channel name training-3\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:current horovod rank is  3\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:channel name ['evaluation', 'training', 'training-1', 'training-2', 'training-3']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:last channel name training-3\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:channel name ['evaluation', 'training', 'training-1', 'training-2', 'training-3']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:last channel name training-3\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:channel name ['evaluation', 'training', 'training-1', 'training-2', 'training-3']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:last channel name training-3\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.100745 140389551736576 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.100884 140432338822912 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.100951 140121141290752 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.101020 140014048130816 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:-------enter into pipe mode branch!------------\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:-------enter into pipe mode branch!------------\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:-------enter into pipe mode branch!------------\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:-------enter into pipe mode branch!------------\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.125456 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:79: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.125614 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:79: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.125602 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:79: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.125629 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:81: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.125696 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:79: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.125771 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:81: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.125796 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:81: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.125869 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:81: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:20.159722 140014048130816 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.159947 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:20.160100 140121141290752 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:20.160261 140432338822912 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.160330 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.160579 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:20.160579 140389551736576 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.160793 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.164354 140014048130816 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Call initializer instance with the dtype argument instead of passing it to the constructor[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.164913 140121141290752 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Call initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.165301 140432338822912 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Call initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.165369 140389551736576 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Call initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.182970 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:170: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.184206 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:170: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.184588 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:170: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.184691 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:170: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.539232 140014048130816 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:211: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.540126 140121141290752 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:211: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.540920 140432338822912 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:211: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.543314 140389551736576 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:211: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.639772 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:228: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.642248 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:228: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.642913 140014048130816 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.643095 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:228: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.645245 140389551736576 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.646180 140432338822912 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.649877 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:228: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.652972 140121141290752 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.655019 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.656904 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.658213 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.665008 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.733983 140014048130816 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:809: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.734456 140389551736576 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:809: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.738294 140432338822912 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:809: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.745431 140121141290752 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:809: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.777171 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:254: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.777302 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:254: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.777377 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:264: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.777507 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:264: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.782551 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:254: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.782762 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:264: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.789524 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:254: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.789731 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:264: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[ip-10-0-138-82.us-west-2.compute.internal:00051] 3 more processes have sent help message help-orte-odls-default.txt / memory not bound\u001b[0m\n",
      "\u001b[34m[ip-10-0-138-82.us-west-2.compute.internal:00051] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:21.307508 140432338822912 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:21.307945 140121141290752 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:21.309148 140432338822912 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:21.309573 140121141290752 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:21.317654 140389551736576 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:21.319292 140389551736576 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:21.321895 140014048130816 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:21.323568 140014048130816 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:21.741265 140432338822912 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:21.741542 140121141290752 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:21.758707 140389551736576 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:21.759711 140014048130816 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 16:26:24.836808: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:2021-02-22 16:26:24.846965: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:24.850627 140014048130816 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:24.853578 140432338822912 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:2021-02-22 16:26:24.869854: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:24.872532 140014048130816 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:24.874199 140432338822912 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:24.876677 140389551736576 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:2021-02-22 16:26:24.887848: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:24.894602 140121141290752 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:24.897580 140389551736576 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:24.915534 140121141290752 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:25.460556 140432338822912 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmprvma3v0m/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:25.488250 140014048130816 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:25.500613 140389551736576 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmprf6zrzsz/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:25.523600 140121141290752 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmp2i5sxaku/model.ckpt.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,1]<stderr>:2021-02-22 16:26:25.744873: W tensorflow/core/framework/dataset.cc:404] Input of PipeModeDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:2021-02-22 16:26:25.756013: W tensorflow/core/framework/dataset.cc:404] Input of PipeModeDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 16:26:25.759490: W tensorflow/core/framework/dataset.cc:404] Input of PipeModeDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:2021-02-22 16:26:25.783438: W tensorflow/core/framework/dataset.cc:404] Input of PipeModeDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.138.82<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL version 2.4.7+cuda10.0\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.138.82<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.138.82<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.138.82<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 00 :    0   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 01 :    0   2   1   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 02 :    0   3   1   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 03 :    0   3   2   1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 04 :    0   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 05 :    0   2   1   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 06 :    0   3   1   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 07 :    0   3   2   1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 00 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 00 : 0[0] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 00 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 00 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 01 : 1[1] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 01 : 0[0] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 01 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 01 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 02 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 02 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 02 : 2[2] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 02 : 3[3] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 03 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 03 : 1[1] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 03 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 03 : 3[3] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 04 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 04 : 0[0] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 04 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 04 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 05 : 1[1] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 05 : 0[0] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 05 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 05 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 06 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 06 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 06 : 2[2] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 06 : 3[3] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 07 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 07 : 1[1] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 07 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 07 : 3[3] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO comm 0x7f56e0710aa0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO comm 0x7fb8447028b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO comm 0x7fae507021b0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO comm 0x7f6fd0701c30 rank 3 nranks 4 cudaDev 3 nvmlDev 3 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:27.305060 140432338822912 basic_session_run_hooks.py:262] loss = 0.69678795, step = 0\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:27.307405 140014048130816 basic_session_run_hooks.py:262] loss = 0.6964474, step = 0\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:27.311202 140389551736576 basic_session_run_hooks.py:262] loss = 0.69663006, step = 0\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:27.311527 140121141290752 basic_session_run_hooks.py:262] loss = 0.6965787, step = 0\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:35.797043 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 11.7751\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:35.797960 140432338822912 basic_session_run_hooks.py:260] loss = 0.5119243, step = 100 (8.493 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:35.808963 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 11.7619\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:35.809897 140014048130816 basic_session_run_hooks.py:260] loss = 0.5075308, step = 100 (8.503 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:35.821233 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 11.7505\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:35.822079 140121141290752 basic_session_run_hooks.py:260] loss = 0.5024146, step = 100 (8.511 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:35.822091 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 11.749\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:35.822960 140389551736576 basic_session_run_hooks.py:260] loss = 0.5087091, step = 100 (8.512 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:43.631709 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7638\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:43.632644 140432338822912 basic_session_run_hooks.py:260] loss = 0.49920604, step = 200 (7.835 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:43.643676 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.7637\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:43.644498 140014048130816 basic_session_run_hooks.py:260] loss = 0.5013862, step = 200 (7.835 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:43.655025 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7652\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:43.655913 140121141290752 basic_session_run_hooks.py:260] loss = 0.4995842, step = 200 (7.834 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:43.656290 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7645\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:43.657090 140389551736576 basic_session_run_hooks.py:260] loss = 0.49970508, step = 200 (7.834 sec)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,2]<stderr>:I0222 16:26:51.539284 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6856\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:51.540243 140389551736576 basic_session_run_hooks.py:260] loss = 0.4352495, step = 300 (7.883 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:51.540313 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6636\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:51.541116 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6806\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:51.541151 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6432\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:51.541295 140014048130816 basic_session_run_hooks.py:260] loss = 0.43264875, step = 300 (7.897 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:51.542168 140121141290752 basic_session_run_hooks.py:260] loss = 0.43114898, step = 300 (7.886 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:51.542221 140432338822912 basic_session_run_hooks.py:260] loss = 0.4257103, step = 300 (7.910 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:59.575684 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.4463\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:59.576633 140432338822912 basic_session_run_hooks.py:260] loss = 0.4327226, step = 400 (8.034 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:59.588627 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.425\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:59.588677 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.4261\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:59.588753 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.4232\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:59.589495 140121141290752 basic_session_run_hooks.py:260] loss = 0.44197372, step = 400 (8.047 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:59.589504 140014048130816 basic_session_run_hooks.py:260] loss = 0.43155897, step = 400 (8.048 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:59.589662 140389551736576 basic_session_run_hooks.py:260] loss = 0.44487563, step = 400 (8.049 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:07.639246 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.4216\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:07.639312 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.4013\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:07.640050 140389551736576 basic_session_run_hooks.py:260] loss = 0.38178706, step = 500 (8.050 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:07.640127 140432338822912 basic_session_run_hooks.py:260] loss = 0.3654773, step = 500 (8.063 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:07.661875 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.3866\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:07.662686 140121141290752 basic_session_run_hooks.py:260] loss = 0.39600113, step = 500 (8.073 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:07.662947 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.3849\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:07.663893 140014048130816 basic_session_run_hooks.py:260] loss = 0.36893976, step = 500 (8.074 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:15.552218 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6738\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:15.552396 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6752\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:15.552551 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.637\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:15.553211 140121141290752 basic_session_run_hooks.py:260] loss = 0.3566168, step = 600 (7.891 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:15.553354 140389551736576 basic_session_run_hooks.py:260] loss = 0.34837553, step = 600 (7.913 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:15.553353 140014048130816 basic_session_run_hooks.py:260] loss = 0.35300466, step = 600 (7.889 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:15.554471 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.634\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:15.555454 140432338822912 basic_session_run_hooks.py:260] loss = 0.36142638, step = 600 (7.915 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:23.573162 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.4709\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:23.574174 140432338822912 basic_session_run_hooks.py:260] loss = 0.33269083, step = 700 (8.019 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:23.581357 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.4549\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:23.582233 140014048130816 basic_session_run_hooks.py:260] loss = 0.33478916, step = 700 (8.029 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:23.597620 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.4299\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:23.597778 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.4292\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:23.598392 140389551736576 basic_session_run_hooks.py:260] loss = 0.34054667, step = 700 (8.045 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:23.598531 140121141290752 basic_session_run_hooks.py:260] loss = 0.34801847, step = 700 (8.045 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:31.515629 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6035\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:31.515554 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6299\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:31.515874 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5902\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:31.516441 140014048130816 basic_session_run_hooks.py:260] loss = 0.32547107, step = 800 (7.934 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:31.516622 140121141290752 basic_session_run_hooks.py:260] loss = 0.33292928, step = 800 (7.918 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:31.516751 140432338822912 basic_session_run_hooks.py:260] loss = 0.32196587, step = 800 (7.943 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:31.529746 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.607\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:31.530596 140389551736576 basic_session_run_hooks.py:260] loss = 0.343571, step = 800 (7.932 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:39.296270 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.8523\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:39.296826 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.8515\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:39.297236 140121141290752 basic_session_run_hooks.py:260] loss = 0.32076162, step = 900 (7.781 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:39.297694 140014048130816 basic_session_run_hooks.py:260] loss = 0.32229495, step = 900 (7.781 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:39.321034 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.8349\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:39.321860 140389551736576 basic_session_run_hooks.py:260] loss = 0.32272172, step = 900 (7.791 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:39.321863 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.8106\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:39.322617 140432338822912 basic_session_run_hooks.py:260] loss = 0.32189885, step = 900 (7.806 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:47.206103 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6822\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:47.206102 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6836\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:47.206972 140389551736576 basic_session_run_hooks.py:260] loss = 0.33881783, step = 1000 (7.885 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:47.207065 140432338822912 basic_session_run_hooks.py:260] loss = 0.33682638, step = 1000 (7.884 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:47.210842 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6349\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:47.211686 140121141290752 basic_session_run_hooks.py:260] loss = 0.34686518, step = 1000 (7.914 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:47.212406 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6333\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:47.213577 140014048130816 basic_session_run_hooks.py:260] loss = 0.34639478, step = 1000 (7.916 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:55.186566 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5405\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:55.186655 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5305\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:55.187495 140014048130816 basic_session_run_hooks.py:260] loss = 0.3478163, step = 1100 (7.974 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:55.187504 140432338822912 basic_session_run_hooks.py:260] loss = 0.34920353, step = 1100 (7.980 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:55.198556 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5192\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:55.198687 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5116\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:55.199410 140389551736576 basic_session_run_hooks.py:260] loss = 0.34924465, step = 1100 (7.992 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:55.199514 140121141290752 basic_session_run_hooks.py:260] loss = 0.3614805, step = 1100 (7.988 sec)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,2]<stderr>:I0222 16:28:03.062580 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7164\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:03.062526 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6971\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:03.063098 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6959\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:03.063445 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7147\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:03.063532 140389551736576 basic_session_run_hooks.py:260] loss = 0.34033877, step = 1200 (7.864 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:03.063655 140432338822912 basic_session_run_hooks.py:260] loss = 0.33552784, step = 1200 (7.876 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:03.064073 140014048130816 basic_session_run_hooks.py:260] loss = 0.33531767, step = 1200 (7.877 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:03.064216 140121141290752 basic_session_run_hooks.py:260] loss = 0.3347452, step = 1200 (7.865 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:11.045060 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5283\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:11.045262 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5269\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:11.045262 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5271\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:11.045739 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5277\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:11.046025 140432338822912 basic_session_run_hooks.py:260] loss = 0.30754536, step = 1300 (7.982 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:11.046049 140014048130816 basic_session_run_hooks.py:260] loss = 0.31530946, step = 1300 (7.982 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:11.046091 140389551736576 basic_session_run_hooks.py:260] loss = 0.31074572, step = 1300 (7.983 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:11.046573 140121141290752 basic_session_run_hooks.py:260] loss = 0.3242435, step = 1300 (7.982 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:18.908675 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7173\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:18.908877 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7168\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:18.909511 140432338822912 basic_session_run_hooks.py:260] loss = 0.2866537, step = 1400 (7.863 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:18.909737 140389551736576 basic_session_run_hooks.py:260] loss = 0.28406906, step = 1400 (7.864 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:18.922043 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6963\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:18.923029 140121141290752 basic_session_run_hooks.py:260] loss = 0.28637108, step = 1400 (7.876 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:18.936532 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6719\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:18.937456 140014048130816 basic_session_run_hooks.py:260] loss = 0.29061317, step = 1400 (7.891 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:26.825997 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6519\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:26.826431 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6302\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:26.827045 140121141290752 basic_session_run_hooks.py:260] loss = 0.29711172, step = 1500 (7.904 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:26.827585 140389551736576 basic_session_run_hooks.py:260] loss = 0.29231125, step = 1500 (7.918 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:26.853291 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6314\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:26.853686 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5864\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:26.854288 140014048130816 basic_session_run_hooks.py:260] loss = 0.29624107, step = 1500 (7.917 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:26.854575 140432338822912 basic_session_run_hooks.py:260] loss = 0.29949203, step = 1500 (7.945 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:34.764771 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6405\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:34.765227 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6391\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:34.765751 140432338822912 basic_session_run_hooks.py:260] loss = 0.25211748, step = 1600 (7.911 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:34.766136 140014048130816 basic_session_run_hooks.py:260] loss = 0.25739542, step = 1600 (7.912 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:34.775932 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5787\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:34.776347 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5787\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:34.776855 140121141290752 basic_session_run_hooks.py:260] loss = 0.2568985, step = 1600 (7.950 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:34.777178 140389551736576 basic_session_run_hooks.py:260] loss = 0.25540927, step = 1600 (7.950 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:42.677149 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6392\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:42.678130 140014048130816 basic_session_run_hooks.py:260] loss = 0.26949447, step = 1700 (7.912 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:42.680269 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6334\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:42.680385 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6511\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:42.681036 140432338822912 basic_session_run_hooks.py:260] loss = 0.25579897, step = 1700 (7.915 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:42.681234 140121141290752 basic_session_run_hooks.py:260] loss = 0.27559584, step = 1700 (7.904 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:42.701520 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.618\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:42.702365 140389551736576 basic_session_run_hooks.py:260] loss = 0.27824426, step = 1700 (7.925 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:50.517081 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7605\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:50.517071 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7604\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:50.517656 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7941\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:50.517822 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.754\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:50.518034 140432338822912 basic_session_run_hooks.py:260] loss = 0.25023198, step = 1800 (7.837 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:50.518085 140121141290752 basic_session_run_hooks.py:260] loss = 0.25249553, step = 1800 (7.837 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:50.518454 140389551736576 basic_session_run_hooks.py:260] loss = 0.2525137, step = 1800 (7.816 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:50.518951 140014048130816 basic_session_run_hooks.py:260] loss = 0.25008306, step = 1800 (7.841 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:58.485587 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5503\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:58.485582 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5494\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:58.486494 140389551736576 basic_session_run_hooks.py:260] loss = 0.26167628, step = 1900 (7.968 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:58.486603 140121141290752 basic_session_run_hooks.py:260] loss = 0.2617768, step = 1900 (7.969 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:58.488880 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5441\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:58.489821 140432338822912 basic_session_run_hooks.py:260] loss = 0.25612813, step = 1900 (7.972 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:58.490843 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5423\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:58.491747 140014048130816 basic_session_run_hooks.py:260] loss = 0.25909185, step = 1900 (7.973 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:06.419432 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6095\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:06.420328 140432338822912 basic_session_run_hooks.py:260] loss = 0.21738839, step = 2000 (7.931 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:06.423617 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5976\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:06.424773 140389551736576 basic_session_run_hooks.py:260] loss = 0.22015144, step = 2000 (7.938 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:06.433726 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5815\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:06.434668 140121141290752 basic_session_run_hooks.py:260] loss = 0.2240405, step = 2000 (7.948 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:06.446693 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5694\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:06.447489 140014048130816 basic_session_run_hooks.py:260] loss = 0.21728197, step = 2000 (7.956 sec)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,2]<stderr>:I0222 16:29:14.463954 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.4373\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:14.464845 140389551736576 basic_session_run_hooks.py:260] loss = 0.22476599, step = 2100 (8.040 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:14.478156 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.451\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:14.478946 140014048130816 basic_session_run_hooks.py:260] loss = 0.21923453, step = 2100 (8.031 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:14.490466 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.3899\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:14.491314 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.4107\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:14.491379 140432338822912 basic_session_run_hooks.py:260] loss = 0.2205246, step = 2100 (8.071 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:14.492099 140121141290752 basic_session_run_hooks.py:260] loss = 0.22831568, step = 2100 (8.057 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:22.333947 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7064\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:22.333905 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.7296\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:22.334296 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7489\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:22.334784 140389551736576 basic_session_run_hooks.py:260] loss = 0.2331152, step = 2200 (7.870 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:22.334983 140014048130816 basic_session_run_hooks.py:260] loss = 0.2341921, step = 2200 (7.856 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:22.335086 140432338822912 basic_session_run_hooks.py:260] loss = 0.23240316, step = 2200 (7.844 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:22.347180 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7294\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:22.348119 140121141290752 basic_session_run_hooks.py:260] loss = 0.23579535, step = 2200 (7.856 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:30.247268 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6368\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:30.248185 140014048130816 basic_session_run_hooks.py:260] loss = 0.2267976, step = 2300 (7.913 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:30.259548 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6385\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:30.260419 140121141290752 basic_session_run_hooks.py:260] loss = 0.22584715, step = 2300 (7.912 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:30.265374 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6081\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:30.265525 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6084\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:30.266226 140389551736576 basic_session_run_hooks.py:260] loss = 0.21841177, step = 2300 (7.931 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:30.266255 140432338822912 basic_session_run_hooks.py:260] loss = 0.21830231, step = 2300 (7.931 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:38.234560 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5484\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:38.235444 140389551736576 basic_session_run_hooks.py:260] loss = 0.21248895, step = 2400 (7.969 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:38.236618 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.536\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:38.237831 140121141290752 basic_session_run_hooks.py:260] loss = 0.21578187, step = 2400 (7.977 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:38.248422 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5268\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:38.248764 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.4976\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:38.249397 140432338822912 basic_session_run_hooks.py:260] loss = 0.21630785, step = 2400 (7.983 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:38.249531 140014048130816 basic_session_run_hooks.py:260] loss = 0.2149369, step = 2400 (8.001 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:46.078849 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7482\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:46.078970 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7705\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:46.079243 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7507\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:46.079511 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.7702\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:46.079779 140389551736576 basic_session_run_hooks.py:260] loss = 0.22218744, step = 2500 (7.844 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:46.079864 140432338822912 basic_session_run_hooks.py:260] loss = 0.22279227, step = 2500 (7.830 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:46.080060 140121141290752 basic_session_run_hooks.py:260] loss = 0.23945957, step = 2500 (7.842 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:46.080363 140014048130816 basic_session_run_hooks.py:260] loss = 0.23539701, step = 2500 (7.831 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:53.943566 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7152\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:53.943595 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7149\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:53.944433 140389551736576 basic_session_run_hooks.py:260] loss = 0.22735332, step = 2600 (7.865 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:53.944523 140432338822912 basic_session_run_hooks.py:260] loss = 0.22843558, step = 2600 (7.865 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:53.944438 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7143\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:53.945325 140121141290752 basic_session_run_hooks.py:260] loss = 0.24275735, step = 2600 (7.865 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:53.957380 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6938\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:53.958284 140014048130816 basic_session_run_hooks.py:260] loss = 0.22154479, step = 2600 (7.878 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:01.989358 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.4289\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:01.989587 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.4298\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:01.990341 140389551736576 basic_session_run_hooks.py:260] loss = 0.20647547, step = 2700 (8.046 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:01.990428 140121141290752 basic_session_run_hooks.py:260] loss = 0.20616996, step = 2700 (8.045 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:02.001820 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.4096\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:02.002775 140432338822912 basic_session_run_hooks.py:260] loss = 0.20826513, step = 2700 (8.058 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:02.004093 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.4274\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:02.004963 140014048130816 basic_session_run_hooks.py:260] loss = 0.21309108, step = 2700 (8.047 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:09.999443 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5073\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:09.999842 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.484\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:10.000289 140014048130816 basic_session_run_hooks.py:260] loss = 0.22376308, step = 2800 (7.995 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:10.000654 140121141290752 basic_session_run_hooks.py:260] loss = 0.21500465, step = 2800 (8.010 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:10.002755 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.4791\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:10.003064 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.4981\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:10.003562 140389551736576 basic_session_run_hooks.py:260] loss = 0.2094556, step = 2800 (8.013 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:10.004144 140432338822912 basic_session_run_hooks.py:260] loss = 0.21463814, step = 2800 (8.001 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:17.906215 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6474\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:17.906389 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6478\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:17.907118 140014048130816 basic_session_run_hooks.py:260] loss = 0.22014639, step = 2900 (7.907 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:17.907205 140121141290752 basic_session_run_hooks.py:260] loss = 0.21580124, step = 2900 (7.907 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:17.919161 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6324\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:17.920032 140432338822912 basic_session_run_hooks.py:260] loss = 0.22011498, step = 2900 (7.916 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:17.920257 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6302\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:17.921112 140389551736576 basic_session_run_hooks.py:260] loss = 0.21550009, step = 2900 (7.918 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:25.755079 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.7407\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:25.755975 140014048130816 basic_session_run_hooks.py:260] loss = 0.23720464, step = 3000 (7.849 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:25.768089 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7424\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:25.769042 140389551736576 basic_session_run_hooks.py:260] loss = 0.22443047, step = 3000 (7.848 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:25.774887 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7295\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:25.775719 140432338822912 basic_session_run_hooks.py:260] loss = 0.22804257, step = 3000 (7.856 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:25.776045 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.707\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:25.776874 140121141290752 basic_session_run_hooks.py:260] loss = 0.23091418, step = 3000 (7.870 sec)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,2]<stderr>:I0222 16:30:33.686388 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.629\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:33.686393 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6416\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:33.687398 140389551736576 basic_session_run_hooks.py:260] loss = 0.22957885, step = 3100 (7.918 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:33.687475 140121141290752 basic_session_run_hooks.py:260] loss = 0.222332, step = 3100 (7.911 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:33.713181 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5658\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:33.713722 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5963\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:33.714257 140014048130816 basic_session_run_hooks.py:260] loss = 0.21288922, step = 3100 (7.958 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:33.714750 140432338822912 basic_session_run_hooks.py:260] loss = 0.22213861, step = 3100 (7.939 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:41.663120 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5365\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:41.663197 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5364\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:41.664040 140389551736576 basic_session_run_hooks.py:260] loss = 0.21050668, step = 3200 (7.977 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:41.664030 140121141290752 basic_session_run_hooks.py:260] loss = 0.20573977, step = 3200 (7.977 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:41.688529 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5396\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:41.689413 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5372\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:41.689501 140432338822912 basic_session_run_hooks.py:260] loss = 0.20198575, step = 3200 (7.975 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:41.690325 140014048130816 basic_session_run_hooks.py:260] loss = 0.21114188, step = 3200 (7.976 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:49.507940 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7474\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:49.507906 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7887\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:49.508650 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7461\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:49.508801 140121141290752 basic_session_run_hooks.py:260] loss = 0.21095279, step = 3300 (7.845 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:49.508906 140432338822912 basic_session_run_hooks.py:260] loss = 0.20863265, step = 3300 (7.819 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:49.509542 140389551736576 basic_session_run_hooks.py:260] loss = 0.20877132, step = 3300 (7.846 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:49.521320 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.7683\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:49.522168 140014048130816 basic_session_run_hooks.py:260] loss = 0.20490462, step = 3300 (7.832 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:57.415727 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6458\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:57.415974 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6465\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:57.416671 140121141290752 basic_session_run_hooks.py:260] loss = 0.20182455, step = 3400 (7.908 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:57.416742 140389551736576 basic_session_run_hooks.py:260] loss = 0.19900677, step = 3400 (7.907 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:57.439760 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6288\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:57.439791 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6073\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:57.440632 140014048130816 basic_session_run_hooks.py:260] loss = 0.21815133, step = 3400 (7.918 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:57.440652 140432338822912 basic_session_run_hooks.py:260] loss = 0.2030763, step = 3400 (7.932 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:05.349668 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6045\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:05.350318 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6414\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:05.350596 140389551736576 basic_session_run_hooks.py:260] loss = 0.22839507, step = 3500 (7.934 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:05.351124 140432338822912 basic_session_run_hooks.py:260] loss = 0.20341173, step = 3500 (7.910 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:05.376003 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5624\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:05.376741 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5992\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:05.376867 140121141290752 basic_session_run_hooks.py:260] loss = 0.22186413, step = 3500 (7.960 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:05.377598 140014048130816 basic_session_run_hooks.py:260] loss = 0.2054109, step = 3500 (7.937 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:13.419127 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.4341\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:13.420000 140014048130816 basic_session_run_hooks.py:260] loss = 0.19874346, step = 3600 (8.042 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:13.421139 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.3893\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:13.422073 140389551736576 basic_session_run_hooks.py:260] loss = 0.18820332, step = 3600 (8.071 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:13.442761 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.3572\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:13.442799 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.3965\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:13.443638 140121141290752 basic_session_run_hooks.py:260] loss = 0.19241157, step = 3600 (8.067 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:13.443683 140432338822912 basic_session_run_hooks.py:260] loss = 0.18485051, step = 3600 (8.093 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:21.341730 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6254\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:21.341733 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6599\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:21.341809 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6598\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:21.341903 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6218\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:21.342618 140121141290752 basic_session_run_hooks.py:260] loss = 0.1914975, step = 3700 (7.899 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:21.342760 140014048130816 basic_session_run_hooks.py:260] loss = 0.20992789, step = 3700 (7.923 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:21.342750 140389551736576 basic_session_run_hooks.py:260] loss = 0.1922314, step = 3700 (7.921 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:21.342806 140432338822912 basic_session_run_hooks.py:260] loss = 0.1966992, step = 3700 (7.899 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:29.222248 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6898\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:29.223151 140014048130816 basic_session_run_hooks.py:260] loss = 0.19282454, step = 3800 (7.880 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:29.236503 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6665\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:29.237460 140389551736576 basic_session_run_hooks.py:260] loss = 0.19934087, step = 3800 (7.895 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:29.248705 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6471\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:29.249530 140432338822912 basic_session_run_hooks.py:260] loss = 0.20259528, step = 3800 (7.907 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:29.249800 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6453\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:29.250602 140121141290752 basic_session_run_hooks.py:260] loss = 0.19565377, step = 3800 (7.908 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:37.062630 140389551736576 basic_session_run_hooks.py:606] Saving checkpoints for 3900 into /tmp/tmprf6zrzsz/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.062736 140014048130816 basic_session_run_hooks.py:606] Saving checkpoints for 3900 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:37.062973 140121141290752 basic_session_run_hooks.py:606] Saving checkpoints for 3900 into /tmp/tmp2i5sxaku/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:37.072022 140432338822912 basic_session_run_hooks.py:606] Saving checkpoints for 3900 into /tmp/tmprvma3v0m/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:37.216102 140389551736576 estimator.py:368] Loss for final step: 0.20286798.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.219326 140014048130816 estimator.py:368] Loss for final step: 0.2040714.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:37.224050 140121141290752 estimator.py:368] Loss for final step: 0.19620277.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:37.225245 140432338822912 estimator.py:368] Loss for final step: 0.19593662.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:-------enter into pipe mode branch!------------\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.260337 140014048130816 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.536584 140014048130816 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.560601 140014048130816 evaluation.py:255] Starting evaluation at 2021-02-22T16:31:37Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.673575 140014048130816 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:31:37.681197 140014048130816 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1282: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use standard file APIs to check for files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.682335 140014048130816 saver.py:1286] Restoring parameters from /opt/ml/model/model.ckpt-3900\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.768208 140014048130816 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.787607 140014048130816 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 16:31:37.847938: W tensorflow/core/framework/dataset.cc:404] Input of PipeModeDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.181355 140014048130816 evaluation.py:275] Finished evaluation at 2021-02-22-16:31:39\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.181580 140014048130816 estimator.py:2039] Saving dict for global step 3900: auc = 0.67065716, global_step = 3900, loss = 1.2234036\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.242358 140014048130816 estimator.py:2099] Saving 'checkpoint_path' summary for global step 3900: /opt/ml/model/model.ckpt-3900\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:31:39.244538 140014048130816 deprecation.py:323] From DeepFM-hvd-tfrecord-vectorized-map.py:435: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:This function has been renamed, use `export_saved_model` instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.252199 140014048130816 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.380671 140014048130816 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:31:39.380896 140014048130816 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.381220 140014048130816 export_utils.py:170] Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.381325 140014048130816 export_utils.py:170] Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.381412 140014048130816 export_utils.py:170] Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.381481 140014048130816 export_utils.py:170] Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.381554 140014048130816 export_utils.py:170] Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.421092 140014048130816 saver.py:1286] Restoring parameters from /opt/ml/model/model.ckpt-3900\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.458505 140014048130816 builder_impl.py:661] Assets added to graph.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.458677 140014048130816 builder_impl.py:456] No assets to write.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.523095 140014048130816 builder_impl.py:421] SavedModel written to: /opt/ml/model/temp-b'1614011499'/saved_model.pb\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-02-22 16:31:42 Uploading - Uploading generated training model\n",
      "2021-02-22 16:31:58 Completed - Training job completed\n",
      "Training seconds: 411\n",
      "Billable seconds: 123\n",
      "Managed Spot Training savings: 70.1%\n"
     ]
    }
   ],
   "source": [
    "#下面这个测试pipe mode\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "'''\n",
    "在Pipe mode下需要设置多个训练channel，训练channel的数量需要与woker_per_host强一致。\n",
    "如： inputs = {'training':train_input, 'training-2':train_input, 'training-3':train_input, 'evaluation': validate_s3}\n",
    "\n",
    "训练数据集路径分两种，一种是各个channel用一个训练数据集路径，一种是每个channel有独自的训练数据集路径（每个channel下面数据集样本数量需要保持一致））。\n",
    "用户可以根据实际情况决定在准备数据集的时候采用哪种方式，这里我们以 enable_data_multi_path 这个参数表示是否每个channel有独自的数据集路径\n",
    "'''\n",
    "\n",
    "train_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/training/'\n",
    "validate_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/val/'\n",
    "\n",
    "if enable_data_multi_path:    #假如有4个不同的channel\n",
    "\n",
    "    train_s3_uri_1 = ''\n",
    "    train_s3_uri_2 = ''\n",
    "    train_s3_uri_3 = ''\n",
    "    train_s3_uri_4 = ''\n",
    "    \n",
    "    if enable_s3_shard:\n",
    "        train_input_1 = TrainingInput(train_s3_uri_1, distribution='ShardedByS3Key')\n",
    "        train_input_2 = TrainingInput(train_s3_uri_2, distribution='ShardedByS3Key')\n",
    "        train_input_3 = TrainingInput(train_s3_uri_3, distribution='ShardedByS3Key')\n",
    "        train_input_4 = TrainingInput(train_s3_uri_4, distribution='ShardedByS3Key')\n",
    "    else :\n",
    "        train_input_1 = TrainingInput(train_s3_uri_1)\n",
    "        train_input_2 = TrainingInput(train_s3_uri_2)\n",
    "        train_input_3 = TrainingInput(train_s3_uri_3)\n",
    "        train_input_4 = TrainingInput(train_s3_uri_4)\n",
    "        \n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "    \n",
    "    inputs = {'{}'.format(training_channel_name) : train_input_1,\n",
    "              '{}-1'.format(training_channel_name) : train_input_2,\n",
    "              '{}-2'.format(training_channel_name) : train_input_3,\n",
    "              '{}-3'.format(training_channel_name) : train_input_4, \n",
    "              evaluation_channel_name : val_input}\n",
    "\n",
    "else : #共用一个训练数据集路径 train_s3_uri\n",
    "    \n",
    "    if enable_s3_shard:\n",
    "        train_input = TrainingInput(train_s3_uri, distribution='ShardedByS3Key')\n",
    "    else :\n",
    "        train_input = TrainingInput(train_s3_uri)\n",
    "        \n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "    \n",
    "    inputs = {'{}'.format(training_channel_name) : train_input,\n",
    "              '{}-1'.format(training_channel_name) : train_input,\n",
    "              '{}-2'.format(training_channel_name) : train_input,\n",
    "              '{}-3'.format(training_channel_name) : train_input, \n",
    "              evaluation_channel_name : val_input}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
