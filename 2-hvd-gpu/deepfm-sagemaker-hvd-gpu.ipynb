{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFM Tensorflow Horovod on SageMaker Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this sample, we will demo how to run a deepfm sample code in tensorflow horovod on sagemaker\n",
    "\n",
    "Notice:\n",
    "\n",
    "1. Dataset format is TFRecord\n",
    "\n",
    "2. This model training we will use **GPU** instances\n",
    "\n",
    "3. Using [SageMaker Python SDK 2.x](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.25.1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面用多个spot实例进行parameter server方式的分布式训练。\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "dt_now = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "bucket = 'sagemaker-us-west-2-169088282855'\n",
    "checkpoint_s3_uri = 's3://{}/deepfm-checkpoint/{}'.format(bucket, dt_now) #Change to your own path if you want to save ckpt during training\n",
    "checkpoint_dir = '/opt/ml/deepfm/checkpoints'\n",
    "model_dir = '/opt/ml/model'\n",
    "output_path= 's3://{}/deepfm-2021'.format(bucket)\n",
    "\n",
    "training_channel_name = 'training'\n",
    "evaluation_channel_name = 'evaluation'\n",
    "\n",
    "train_instance_type = 'ml.p3.8xlarge'\n",
    "hvd_processes_per_host = 4\n",
    "train_instance_count= 1\n",
    "\n",
    "train_use_spot_instances = True\n",
    "enable_s3_shard = True\n",
    "enable_data_multi_path = True\n",
    "\n",
    "#enable pipe mode\n",
    "pipe_mode = 0\n",
    "\n",
    "train_max_run=36000*2\n",
    "train_max_wait = 72000 if train_use_spot_instances else None\n",
    "\n",
    "distributions = {'mpi': {\n",
    "                    'enabled': True,\n",
    "                    'processes_per_host': hvd_processes_per_host,\n",
    "                    'custom_mpi_options': '-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none'\n",
    "                        }\n",
    "                }\n",
    "\n",
    "deep_layer = '128,64,32'\n",
    "\n",
    "batch_size = 1024\n",
    "feature_size = 117581\n",
    "\n",
    "base_job_name='tf-scriptmode-deepfm'\n",
    "\n",
    "hyperparameters = {'servable_model_dir': '/opt/ml/model', 'checkpoint_dir':checkpoint_dir,\n",
    "                   'training_data_dir': '/opt/ml/input/data/training/', 'val_data_dir': '/opt/ml/input/data/evaluation/', 'log_steps': 10, 'num_epochs': 10, \n",
    "                   'field_size': 39, 'feature_size': feature_size, 'deep_layers': deep_layer,\n",
    "                   'perform_shuffle': 0, 'batch_size': batch_size, 'pipe_mode': pipe_mode, 'enable_s3_shard': enable_s3_shard,\n",
    "                   'training_channel_name': training_channel_name, 'evaluation_channel_name': evaluation_channel_name,\n",
    "                   'worker_per_host': hvd_processes_per_host, 'enable_data_multi_path': enable_data_multi_path\n",
    "                  }\n",
    "\n",
    "estimator = TensorFlow(\n",
    "                       #source_dir='./',\n",
    "                       entry_point='DeepFM-hvd-tfrecord-vectorized-map.py',\n",
    "                       model_dir=False,\n",
    "                       #checkpoint_s3_uri = checkpoint_s3_uri,\n",
    "                       #checkpoint_local_path = checkpoint_local_path,\n",
    "                       output_path= output_path,\n",
    "                       instance_type=train_instance_type,\n",
    "                       instance_count=train_instance_count,\n",
    "                       #volume_size = 500,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       base_job_name=base_job_name,\n",
    "                       framework_version='1.15.2',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True,\n",
    "                       #input_mode='Pipe',\n",
    "                       distribution=distributions,\n",
    "                       use_spot_instances=train_use_spot_instances,\n",
    "                       max_wait=train_max_wait,\n",
    "                       max_run=train_max_run,\n",
    "                       debugger_hook_config =False,\n",
    "                       disable_profiler=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-23 07:51:26 Starting - Starting the training job...\n",
      "2021-02-23 07:51:28 Starting - Launching requested ML instances......\n",
      "2021-02-23 07:52:38 Starting - Preparing the instances for training............\n",
      "2021-02-23 07:54:55 Downloading - Downloading input data\n",
      "2021-02-23 07:54:55 Training - Downloading the training image...\n",
      "2021-02-23 07:55:17 Training - Training image download completed. Training in progress..\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-02-23 07:55:22,065 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-02-23 07:55:22,508 sagemaker-containers INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2021-02-23 07:55:22,508 sagemaker-containers INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2021-02-23 07:55:22,514 sagemaker-containers INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2021-02-23 07:55:22,514 sagemaker-containers INFO     Env Hosts: ['algo-1'] Hosts: ['algo-1:4'] process_per_hosts: 4 num_processes: 4\u001b[0m\n",
      "\u001b[34m2021-02-23 07:55:22,516 sagemaker-containers INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2021-02-23 07:55:22,561 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_mpi_num_of_processes_per_host\": 4,\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none\",\n",
      "        \"sagemaker_mpi_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"evaluation\": \"/opt/ml/input/data/evaluation\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"val_data_dir\": \"/opt/ml/input/data/evaluation/\",\n",
      "        \"field_size\": 39,\n",
      "        \"worker_per_host\": 4,\n",
      "        \"pipe_mode\": 0,\n",
      "        \"servable_model_dir\": \"/opt/ml/model\",\n",
      "        \"enable_data_multi_path\": true,\n",
      "        \"batch_size\": 1024,\n",
      "        \"log_steps\": 10,\n",
      "        \"deep_layers\": \"128,64,32\",\n",
      "        \"checkpoint_dir\": \"/opt/ml/deepfm/checkpoints\",\n",
      "        \"training_channel_name\": \"training\",\n",
      "        \"training_data_dir\": \"/opt/ml/input/data/training/\",\n",
      "        \"perform_shuffle\": 0,\n",
      "        \"evaluation_channel_name\": \"evaluation\",\n",
      "        \"feature_size\": 117581,\n",
      "        \"enable_s3_shard\": true,\n",
      "        \"num_epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"evaluation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"ShardedByS3Key\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tf-scriptmode-deepfm-2021-02-23-07-51-26-411\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-23-07-51-26-411/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"DeepFM-hvd-tfrecord-vectorized-map\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"DeepFM-hvd-tfrecord-vectorized-map.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":1024,\"checkpoint_dir\":\"/opt/ml/deepfm/checkpoints\",\"deep_layers\":\"128,64,32\",\"enable_data_multi_path\":true,\"enable_s3_shard\":true,\"evaluation_channel_name\":\"evaluation\",\"feature_size\":117581,\"field_size\":39,\"log_steps\":10,\"num_epochs\":10,\"perform_shuffle\":0,\"pipe_mode\":0,\"servable_model_dir\":\"/opt/ml/model\",\"training_channel_name\":\"training\",\"training_data_dir\":\"/opt/ml/input/data/training/\",\"val_data_dir\":\"/opt/ml/input/data/evaluation/\",\"worker_per_host\":4}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=DeepFM-hvd-tfrecord-vectorized-map.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_mpi_custom_mpi_options\":\"-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":4}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"evaluation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"ShardedByS3Key\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"evaluation\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=DeepFM-hvd-tfrecord-vectorized-map\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-23-07-51-26-411/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":4},\"channel_input_dirs\":{\"evaluation\":\"/opt/ml/input/data/evaluation\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":1024,\"checkpoint_dir\":\"/opt/ml/deepfm/checkpoints\",\"deep_layers\":\"128,64,32\",\"enable_data_multi_path\":true,\"enable_s3_shard\":true,\"evaluation_channel_name\":\"evaluation\",\"feature_size\":117581,\"field_size\":39,\"log_steps\":10,\"num_epochs\":10,\"perform_shuffle\":0,\"pipe_mode\":0,\"servable_model_dir\":\"/opt/ml/model\",\"training_channel_name\":\"training\",\"training_data_dir\":\"/opt/ml/input/data/training/\",\"val_data_dir\":\"/opt/ml/input/data/evaluation/\",\"worker_per_host\":4},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"evaluation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"ShardedByS3Key\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-scriptmode-deepfm-2021-02-23-07-51-26-411\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-23-07-51-26-411/source/sourcedir.tar.gz\",\"module_name\":\"DeepFM-hvd-tfrecord-vectorized-map\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"DeepFM-hvd-tfrecord-vectorized-map.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"1024\",\"--checkpoint_dir\",\"/opt/ml/deepfm/checkpoints\",\"--deep_layers\",\"128,64,32\",\"--enable_data_multi_path\",\"True\",\"--enable_s3_shard\",\"True\",\"--evaluation_channel_name\",\"evaluation\",\"--feature_size\",\"117581\",\"--field_size\",\"39\",\"--log_steps\",\"10\",\"--num_epochs\",\"10\",\"--perform_shuffle\",\"0\",\"--pipe_mode\",\"0\",\"--servable_model_dir\",\"/opt/ml/model\",\"--training_channel_name\",\"training\",\"--training_data_dir\",\"/opt/ml/input/data/training/\",\"--val_data_dir\",\"/opt/ml/input/data/evaluation/\",\"--worker_per_host\",\"4\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_EVALUATION=/opt/ml/input/data/evaluation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_VAL_DATA_DIR=/opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34mSM_HP_FIELD_SIZE=39\u001b[0m\n",
      "\u001b[34mSM_HP_WORKER_PER_HOST=4\u001b[0m\n",
      "\u001b[34mSM_HP_PIPE_MODE=0\u001b[0m\n",
      "\u001b[34mSM_HP_SERVABLE_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_ENABLE_DATA_MULTI_PATH=true\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=1024\u001b[0m\n",
      "\u001b[34mSM_HP_LOG_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_DEEP_LAYERS=128,64,32\u001b[0m\n",
      "\u001b[34mSM_HP_CHECKPOINT_DIR=/opt/ml/deepfm/checkpoints\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_CHANNEL_NAME=training\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_DATA_DIR=/opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34mSM_HP_PERFORM_SHUFFLE=0\u001b[0m\n",
      "\u001b[34mSM_HP_EVALUATION_CHANNEL_NAME=evaluation\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURE_SIZE=117581\u001b[0m\n",
      "\u001b[34mSM_HP_ENABLE_S3_SHARD=true\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:4 -np 4 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to socket -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/usr/local/lib/python3.6/dist-packages/gethostname.cpython-36m-x86_64-linux-gnu.so -verbose -x OMPI_MCA_btl_vader_single_copy_mechanism=none -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_EVALUATION -x SM_CHANNEL_TRAINING -x SM_HP_VAL_DATA_DIR -x SM_HP_FIELD_SIZE -x SM_HP_WORKER_PER_HOST -x SM_HP_PIPE_MODE -x SM_HP_SERVABLE_MODEL_DIR -x SM_HP_ENABLE_DATA_MULTI_PATH -x SM_HP_BATCH_SIZE -x SM_HP_LOG_STEPS -x SM_HP_DEEP_LAYERS -x SM_HP_CHECKPOINT_DIR -x SM_HP_TRAINING_CHANNEL_NAME -x SM_HP_TRAINING_DATA_DIR -x SM_HP_PERFORM_SHUFFLE -x SM_HP_EVALUATION_CHANNEL_NAME -x SM_HP_FEATURE_SIZE -x SM_HP_ENABLE_S3_SHARD -x SM_HP_NUM_EPOCHS -x PYTHONPATH /usr/bin/python3 -m mpi4py DeepFM-hvd-tfrecord-vectorized-map.py --batch_size 1024 --checkpoint_dir /opt/ml/deepfm/checkpoints --deep_layers 128,64,32 --enable_data_multi_path True --enable_s3_shard True --evaluation_channel_name evaluation --feature_size 117581 --field_size 39 --log_steps 10 --num_epochs 10 --perform_shuffle 0 --pipe_mode 0 --servable_model_dir /opt/ml/model --training_channel_name training --training_data_dir /opt/ml/input/data/training/ --val_data_dir /opt/ml/input/data/evaluation/ --worker_per_host 4\n",
      "\n",
      "\n",
      " Data for JOB [55252,1] offset 0 Total slots allocated 4\n",
      "\n",
      " ========================   JOB MAP   ========================\n",
      "\n",
      " Data for node: ip-10-0-237-137#011Num slots: 4#011Max slots: 0#011Num procs: 4\n",
      " #011Process OMPI jobid: [55252,1] App: 0 Process rank: 0 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [55252,1] App: 0 Process rank: 1 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [55252,1] App: 0 Process rank: 2 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [55252,1] App: 0 Process rank: 3 Bound: UNBOUND\n",
      "\n",
      " =============================================================\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mWARNING: Open MPI tried to bind a process but failed.  This is a\u001b[0m\n",
      "\u001b[34mwarning only; your job will continue, though performance may\u001b[0m\n",
      "\u001b[34mbe degraded.\n",
      "\n",
      "  Local host:        ip-10-0-237-137\n",
      "  Application name:  /usr/bin/python3\n",
      "  Error message:     failed to bind memory\n",
      "  Location:          rtc_hwloc.c:447\n",
      "\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:434: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:434: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:434: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:434: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:434: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:435: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:434: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:435: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:434: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:434: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:435: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:435: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--checkpoint_dir', '/opt/ml/deepfm/checkpoints', '--deep_layers', '128,64,32', '--enable_data_multi_path', 'True', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--checkpoint_dir', '/opt/ml/deepfm/checkpoints', '--deep_layers', '128,64,32', '--enable_data_multi_path', 'True', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--checkpoint_dir', '/opt/ml/deepfm/checkpoints', '--deep_layers', '128,64,32', '--enable_data_multi_path', 'True', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--checkpoint_dir', '/opt/ml/deepfm/checkpoints', '--deep_layers', '128,64,32', '--enable_data_multi_path', 'True', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:checkpoint_dir  /opt/ml/deepfm/checkpoints\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:checkpoint_dir  /opt/ml/deepfm/checkpoints\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:checkpoint_dir  /opt/ml/deepfm/checkpoints\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:checkpoint_dir  /opt/ml/deepfm/checkpoints\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:tr_files: ['/opt/ml/input/data/training/data-2/train.tfrecords', '/opt/ml/input/data/training/data-3/train.tfrecords', '/opt/ml/input/data/training/data-4/train.tfrecords', '/opt/ml/input/data/training/data-1/train.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:va_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:te_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:tr_files: ['/opt/ml/input/data/training/data-1/train.tfrecords', '/opt/ml/input/data/training/data-3/train.tfrecords', '/opt/ml/input/data/training/data-2/train.tfrecords', '/opt/ml/input/data/training/data-4/train.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:va_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:te_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:tr_files: ['/opt/ml/input/data/training/data-3/train.tfrecords', '/opt/ml/input/data/training/data-2/train.tfrecords', '/opt/ml/input/data/training/data-1/train.tfrecords', '/opt/ml/input/data/training/data-4/train.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:va_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:te_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:355: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:355: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:355: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.293912 139772761040704 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:355: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.293910 140482554521408 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:355: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.293912 139660100417344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:355: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:tr_files: ['/opt/ml/input/data/training/data-2/train.tfrecords', '/opt/ml/input/data/training/data-1/train.tfrecords', '/opt/ml/input/data/training/data-3/train.tfrecords', '/opt/ml/input/data/training/data-4/train.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:va_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:te_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:current horovod rank is  1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:current horovod rank is  3\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:current horovod rank is  2\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:355: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.294270 139872637613888 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:355: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:current horovod rank is  0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpp2thczv5\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp4nc129__\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.294770 139660100417344 estimator.py:1821] Using temporary folder as model directory: /tmp/tmpp2thczv5\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.294801 140482554521408 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp4nc129__\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp8wl08_sc\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.294858 139772761040704 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp8wl08_sc\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpp2thczv5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  visible_device_list: \"1\"\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0498e5bcc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp4nc129__', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  visible_device_list: \"3\"\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc416fb6cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:26.295509 139660100417344 estimator.py:212] Using config: {'_model_dir': '/tmp/tmpp2thczv5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  visible_device_list: \"1\"\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0498e5bcc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:26.295517 140482554521408 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp4nc129__', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  visible_device_list: \"3\"\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:channel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:last channel name training\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:channel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc416fb6cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp8wl08_sc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  visible_device_list: \"2\"\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1ed42d4cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:26.295577 139772761040704 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp8wl08_sc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  visible_device_list: \"2\"\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1ed42d4cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Using config: {'_model_dir': '/opt/ml/deepfm/checkpoints', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:last channel name training\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:channel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:last channel name training\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:channel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:last channel name training\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  visible_device_list: \"0\"\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f35ff5e3a58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:26.295181 139872637613888 estimator.py:212] Using config: {'_model_dir': '/opt/ml/deepfm/checkpoints', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  visible_device_list: \"0\"\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f35ff5e3a58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.408804 139872637613888 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.408867 139772761040704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.408910 140482554521408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.408982 139660100417344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.484544 139872637613888 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.484600 140482554521408 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.484635 139772761040704 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.484915 139872637613888 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.484999 139772761040704 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.485010 140482554521408 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.485104 139660100417344 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.485467 139660100417344 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:26.583553 139772761040704 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:26.583667 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.583778 139772761040704 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.583897 139872637613888 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:26.584195 139660100417344 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:26.584239 140482554521408 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.584443 139660100417344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.584494 140482554521408 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.603177 139772761040704 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.603518 139872637613888 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.604792 139660100417344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.605023 140482554521408 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.618508 139772761040704 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.618671 139872637613888 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.619888 139772761040704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.620070 139872637613888 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.620477 139660100417344 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.620853 140482554521408 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.622114 139660100417344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.622274 140482554521408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.636290 139772761040704 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.636720 139872637613888 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.639383 139660100417344 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.639608 140482554521408 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.715732 139772761040704 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.716796 139872637613888 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.718181 139772761040704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.719268 139872637613888 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.721586 139660100417344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.722925 140482554521408 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.724223 139660100417344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.725551 140482554521408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.727589 139772761040704 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.728924 139872637613888 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.734251 139660100417344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.735550 140482554521408 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.793200 139772761040704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.795620 139872637613888 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.802569 139660100417344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.804853 140482554521408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.827755 139772761040704 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:26.827983 139772761040704 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.830832 139872637613888 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:26.831058 139872637613888 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.838858 139660100417344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:26.839099 139660100417344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.841486 140482554521408 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:26.841717 140482554521408 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:27.211943 139772761040704 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:27.213341 139772761040704 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:27.214250 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:27.215633 139872637613888 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:27.217728 139660100417344 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:27.219197 139660100417344 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:27.225675 140482554521408 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:27.227105 140482554521408 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:27.496693 139772761040704 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:27.498517 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:27.510790 139660100417344 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:27.520872 140482554521408 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[ip-10-0-237-137.us-west-2.compute.internal:00084] 3 more processes have sent help message help-orte-odls-default.txt / memory not bound\u001b[0m\n",
      "\u001b[34m[ip-10-0-237-137.us-west-2.compute.internal:00084] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:30.272632 139660100417344 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:30.272632 140482554521408 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:30.295113 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:30.296947 139660100417344 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:30.296951 140482554521408 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:30.318898 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:30.327057 139772761040704 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:30.350463 139772761040704 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:30.791435 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:30.791868 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:30.814082 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:30.826001 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.237.137<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL version 2.4.7+cuda10.0\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.237.137<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.237.137<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.237.137<0>\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Channel 00 :    0   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Channel 01 :    0   2   1   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Channel 02 :    0   3   1   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Channel 03 :    0   3   2   1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Channel 04 :    0   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Channel 05 :    0   2   1   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Channel 06 :    0   3   1   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Channel 07 :    0   3   2   1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] NCCL INFO Ring 00 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Ring 00 : 0[0] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] NCCL INFO Ring 00 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 00 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] NCCL INFO Ring 01 : 1[1] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Ring 01 : 0[0] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] NCCL INFO Ring 01 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 01 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Ring 02 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] NCCL INFO Ring 02 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] NCCL INFO Ring 02 : 3[3] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 02 : 2[2] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] NCCL INFO Ring 03 : 1[1] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Ring 03 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 03 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] NCCL INFO Ring 03 : 3[3] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] NCCL INFO Ring 04 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Ring 04 : 0[0] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 04 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] NCCL INFO Ring 04 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] NCCL INFO Ring 05 : 1[1] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Ring 05 : 0[0] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 05 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] NCCL INFO Ring 05 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] NCCL INFO Ring 06 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Ring 06 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 06 : 2[2] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] NCCL INFO Ring 06 : 3[3] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Ring 07 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] NCCL INFO Ring 07 : 1[1] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO Ring 07 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] NCCL INFO Ring 07 : 3[3] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO comm 0x7f35c871f340 rank 0 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:90:372 [1] NCCL INFO comm 0x7f044c70dc00 rank 1 nranks 4 cudaDev 1 nvmlDev 1 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:91:370 [2] NCCL INFO comm 0x7f1e8470dcf0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:92:369 [3] NCCL INFO comm 0x7fc3c870d770 rank 3 nranks 4 cudaDev 3 nvmlDev 3 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:89:371 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.6961214, step = 0\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.69706774, step = 0\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.6967601, step = 0\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.69665647, step = 0\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:32.132019 139872637613888 basic_session_run_hooks.py:262] loss = 0.6961214, step = 0\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:32.132063 139660100417344 basic_session_run_hooks.py:262] loss = 0.69665647, step = 0\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:32.132073 139772761040704 basic_session_run_hooks.py:262] loss = 0.69706774, step = 0\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:32.132070 140482554521408 basic_session_run_hooks.py:262] loss = 0.6967601, step = 0\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:33.967155 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:33.967210 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:33.967303 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:33.967314 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.3771698.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:34.103313 139872637613888 estimator.py:371] Loss for final step: 0.3771698.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.40950757.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.38869584.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:34.105749 140482554521408 estimator.py:371] Loss for final step: 0.40950757.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:34.105984 139772761040704 estimator.py:371] Loss for final step: 0.38869584.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.3996159.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:34.109592 139660100417344 estimator.py:371] Loss for final step: 0.3996159.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:34.146960 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:34.154191 139772761040704 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:34.156303 140482554521408 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:34.160184 139660100417344 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:34.370680 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-23T07:55:34Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:34.390600 139872637613888 evaluation.py:255] Starting evaluation at 2021-02-23T07:55:34Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:34.484212 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:34.492209 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:34.570940 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:34.589722 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:34.749670 139772761040704 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:34.751027 139772761040704 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:34.783824 140482554521408 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:34.784728 139660100417344 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:34.785248 140482554521408 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:34.786159 139660100417344 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-23-07:55:34\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:34.839709 139872637613888 evaluation.py:275] Finished evaluation at 2021-02-23-07:55:34\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 97: auc = 0.74621934, global_step = 97, loss = 0.57216275\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:34.839939 139872637613888 estimator.py:2049] Saving dict for global step 97: auc = 0.74621934, global_step = 97, loss = 0.57216275\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 97: /opt/ml/deepfm/checkpoints/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:34.895148 139872637613888 estimator.py:2109] Saving 'checkpoint_path' summary for global step 97: /opt/ml/deepfm/checkpoints/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:34.937442 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:35.032538 139772761040704 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:35.041100 139772761040704 saver.py:1290] Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:35.078784 139660100417344 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:35.080997 140482554521408 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:35.092063 139660100417344 saver.py:1290] Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp4nc129__/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:35.094335 140482554521408 saver.py:1290] Restoring parameters from /tmp/tmp4nc129__/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:35.156735 139772761040704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:35.214235 139660100417344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:35.214591 140482554521408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:35.226415 139772761040704 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:35.250743 139772761040704 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:35.284797 139660100417344 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:35.288931 140482554521408 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:35.310472 139660100417344 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:35.315123 140482554521408 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:35.667959 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:35.669392 139872637613888 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:35.738821 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:35.812602 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:35.819443 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:35.871189 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:35.880897 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:36.036865 139872637613888 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1075: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use standard file utilities to get mtimes.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:36.106181 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:36.130041 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 97 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:36.623085 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 97 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.40139565, step = 97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.41555446, step = 97\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:37.247804 139772761040704 basic_session_run_hooks.py:262] loss = 0.40139565, step = 97\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:37.247810 139872637613888 basic_session_run_hooks.py:262] loss = 0.41555446, step = 97\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.37394145, step = 97\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.39425516, step = 97\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:37.247971 140482554521408 basic_session_run_hooks.py:262] loss = 0.37394145, step = 97\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:37.247963 139660100417344 basic_session_run_hooks.py:262] loss = 0.39425516, step = 97\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:39.442414 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:39.442529 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:39.442495 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:39.451162 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.32146788.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:39.578643 140482554521408 estimator.py:371] Loss for final step: 0.32146788.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.32547468.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:39.582290 139872637613888 estimator.py:371] Loss for final step: 0.32547468.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.32640746.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:39.585247 139772761040704 estimator.py:371] Loss for final step: 0.32640746.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.31775495.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:39.589309 139660100417344 estimator.py:371] Loss for final step: 0.31775495.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:39.617452 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:39.624398 140482554521408 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:39.629009 139660100417344 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:39.633696 139772761040704 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:39.839258 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-23T07:55:39Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:39.859179 139872637613888 evaluation.py:255] Starting evaluation at 2021-02-23T07:55:39Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:39.952894 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:39.960865 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:40.038097 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:40.057236 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:40.216955 140482554521408 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:40.218304 140482554521408 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:40.231431 139660100417344 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:40.232800 139660100417344 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:40.259608 139772761040704 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:40.261089 139772761040704 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-23-07:55:40\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:40.305179 139872637613888 evaluation.py:275] Finished evaluation at 2021-02-23-07:55:40\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 194: auc = 0.71062547, global_step = 194, loss = 0.8306608\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:40.305398 139872637613888 estimator.py:2049] Saving dict for global step 194: auc = 0.71062547, global_step = 194, loss = 0.8306608\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 194: /opt/ml/deepfm/checkpoints/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:40.305810 139872637613888 estimator.py:2109] Saving 'checkpoint_path' summary for global step 194: /opt/ml/deepfm/checkpoints/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:40.346740 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:40.404648 140482554521408 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp4nc129__/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:40.413058 140482554521408 saver.py:1290] Restoring parameters from /tmp/tmp4nc129__/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:40.422660 139660100417344 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:40.430958 139660100417344 saver.py:1290] Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:40.457810 139772761040704 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:40.466400 139772761040704 saver.py:1290] Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:40.597558 140482554521408 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:40.620043 139660100417344 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:40.621054 140482554521408 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:40.644520 139660100417344 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:40.658498 139772761040704 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:40.683245 139772761040704 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:40.977682 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:40.979083 139872637613888 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:41.106255 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:41.140600 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:41.185758 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:41.193750 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:41.197023 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:41.417039 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:41.441553 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 194 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:41.945235 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 194 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.3084144, step = 194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.3372518, step = 194\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.31876832, step = 194\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.32757768, step = 194\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:42.538779 139872637613888 basic_session_run_hooks.py:262] loss = 0.3372518, step = 194\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:42.538798 139660100417344 basic_session_run_hooks.py:262] loss = 0.31876832, step = 194\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:42.538823 139772761040704 basic_session_run_hooks.py:262] loss = 0.32757768, step = 194\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:42.538767 140482554521408 basic_session_run_hooks.py:262] loss = 0.3084144, step = 194\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:44.708660 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:44.708693 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:44.708797 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:44.713233 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.3010917.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:44.846970 139772761040704 estimator.py:371] Loss for final step: 0.3010917.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.29018253.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:44.851409 139872637613888 estimator.py:371] Loss for final step: 0.29018253.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.27073085.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:44.852065 139660100417344 estimator.py:371] Loss for final step: 0.27073085.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.30917883.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:44.855019 140482554521408 estimator.py:371] Loss for final step: 0.30917883.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:44.886751 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:44.887171 139772761040704 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:44.892100 139660100417344 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:44.896732 140482554521408 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:45.109333 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-23T07:55:45Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:45.129191 139872637613888 evaluation.py:255] Starting evaluation at 2021-02-23T07:55:45Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:45.222322 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:45.230252 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:45.307074 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:45.326411 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:45.482479 139772761040704 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:45.483963 139772761040704 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:45.486425 139660100417344 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:45.487767 139660100417344 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:45.518718 140482554521408 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:45.520132 140482554521408 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-23-07:55:45\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:45.573313 139872637613888 evaluation.py:275] Finished evaluation at 2021-02-23-07:55:45\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 291: auc = 0.69633627, global_step = 291, loss = 0.93481404\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:45.573530 139872637613888 estimator.py:2049] Saving dict for global step 291: auc = 0.69633627, global_step = 291, loss = 0.93481404\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 291: /opt/ml/deepfm/checkpoints/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:45.573912 139872637613888 estimator.py:2109] Saving 'checkpoint_path' summary for global step 291: /opt/ml/deepfm/checkpoints/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:45.614996 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:45.673244 139772761040704 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:45.676656 139660100417344 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:45.684955 139772761040704 saver.py:1290] Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:45.688264 139660100417344 saver.py:1290] Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:45.717610 140482554521408 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp4nc129__/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:45.726048 140482554521408 saver.py:1290] Restoring parameters from /tmp/tmp4nc129__/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:45.869527 139772761040704 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:45.871021 139660100417344 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:45.894231 139772761040704 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:45.894598 139660100417344 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:45.917831 140482554521408 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:45.941477 140482554521408 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:46.250859 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:46.252264 139872637613888 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:46.387422 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:46.390698 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:46.424084 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:46.450929 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:46.459589 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:46.654481 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:46.678364 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 291 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:47.168221 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 291 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.27706176, step = 291\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:47.752203 140482554521408 basic_session_run_hooks.py:262] loss = 0.27706176, step = 291\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.27718922, step = 291\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:47.752330 139660100417344 basic_session_run_hooks.py:262] loss = 0.27718922, step = 291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.30087847, step = 291\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.29217148, step = 291\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:47.752429 139872637613888 basic_session_run_hooks.py:262] loss = 0.30087847, step = 291\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:47.752435 139772761040704 basic_session_run_hooks.py:262] loss = 0.29217148, step = 291\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:49.906527 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:49.906808 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:49.907268 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:49.913775 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.23612799.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:50.044483 139660100417344 estimator.py:371] Loss for final step: 0.23612799.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.2596001.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:50.047489 139872637613888 estimator.py:371] Loss for final step: 0.2596001.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.27572763.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:50.050431 140482554521408 estimator.py:371] Loss for final step: 0.27572763.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.24490994.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:50.053703 139772761040704 estimator.py:371] Loss for final step: 0.24490994.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:50.081385 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:50.084227 139660100417344 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:50.090005 140482554521408 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:50.094084 139772761040704 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:50.414921 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-23T07:55:50Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:50.433946 139872637613888 evaluation.py:255] Starting evaluation at 2021-02-23T07:55:50Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:50.523196 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:50.531145 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:50.609205 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:50.628531 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:50.681679 139660100417344 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:50.683058 139660100417344 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:50.689279 140482554521408 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:50.690662 140482554521408 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:50.713543 139772761040704 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:50.714941 139772761040704 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:50.871204 139660100417344 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-23-07:55:50\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:50.873788 139872637613888 evaluation.py:275] Finished evaluation at 2021-02-23-07:55:50\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 388: auc = 0.69591206, global_step = 388, loss = 1.2021091\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:50.874003 139872637613888 estimator.py:2049] Saving dict for global step 388: auc = 0.69591206, global_step = 388, loss = 1.2021091\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 388: /opt/ml/deepfm/checkpoints/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:50.874377 139872637613888 estimator.py:2109] Saving 'checkpoint_path' summary for global step 388: /opt/ml/deepfm/checkpoints/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:50.879563 139660100417344 saver.py:1290] Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:50.880691 140482554521408 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp4nc129__/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:50.889284 140482554521408 saver.py:1290] Restoring parameters from /tmp/tmp4nc129__/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:50.909175 139772761040704 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:50.913939 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:50.918268 139772761040704 saver.py:1290] Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:51.064275 139660100417344 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:51.075679 140482554521408 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:51.087888 139660100417344 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:51.099600 140482554521408 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:51.107912 139772761040704 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:51.131920 139772761040704 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:51.522399 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:51.523766 139872637613888 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:51.585677 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:51.599996 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:51.622868 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:51.715600 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:51.724630 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:51.920036 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:51.949699 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 388 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:52.452189 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 388 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.25594303, step = 388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.2739572, step = 388\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.2532418, step = 388\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.25774294, step = 388\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:53.089187 139872637613888 basic_session_run_hooks.py:262] loss = 0.2739572, step = 388\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:53.089188 139660100417344 basic_session_run_hooks.py:262] loss = 0.25594303, step = 388\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:53.089219 140482554521408 basic_session_run_hooks.py:262] loss = 0.25774294, step = 388\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:53.089221 139772761040704 basic_session_run_hooks.py:262] loss = 0.2532418, step = 388\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:55.248675 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:55.248750 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:55.248817 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:55.254686 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:55:55.310381 139872637613888 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:55:55.311961 139772761040704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:55:55.313860 139660100417344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:55:55.318165 140482554521408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.24072066.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:55.399008 139872637613888 estimator.py:371] Loss for final step: 0.24072066.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.2615735.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:55.399170 139772761040704 estimator.py:371] Loss for final step: 0.2615735.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.24976407.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:55.404095 139660100417344 estimator.py:371] Loss for final step: 0.24976407.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.2536757.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:55.406284 140482554521408 estimator.py:371] Loss for final step: 0.2536757.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:55.433175 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:55.439004 139772761040704 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:55.444932 139660100417344 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:55.447408 140482554521408 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:55.644858 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-23T07:55:55Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:55.663635 139872637613888 evaluation.py:255] Starting evaluation at 2021-02-23T07:55:55Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:55.753809 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:55.761871 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:55.840737 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:55.859196 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-23-07:55:56\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:56.101554 139872637613888 evaluation.py:275] Finished evaluation at 2021-02-23-07:55:56\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 485: auc = 0.69407916, global_step = 485, loss = 1.3145335\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:56.101784 139872637613888 estimator.py:2049] Saving dict for global step 485: auc = 0.69407916, global_step = 485, loss = 1.3145335\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 485: /opt/ml/deepfm/checkpoints/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:56.102227 139872637613888 estimator.py:2109] Saving 'checkpoint_path' summary for global step 485: /opt/ml/deepfm/checkpoints/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:56.143141 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:56.173026 139772761040704 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:56.174377 139772761040704 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:56.199432 139660100417344 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:56.200861 139660100417344 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:56.214099 140482554521408 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:56.215568 140482554521408 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:56.360811 139772761040704 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:56.369210 139772761040704 saver.py:1290] Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:56.395246 139660100417344 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:56.403801 139660100417344 saver.py:1290] Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:56.414021 140482554521408 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp4nc129__/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:56.422717 140482554521408 saver.py:1290] Restoring parameters from /tmp/tmp4nc129__/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:56.560947 139772761040704 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:56.585715 139772761040704 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:56.603579 139660100417344 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:56.619794 140482554521408 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:56.628928 139660100417344 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:56.643955 140482554521408 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:56.779100 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:56.780558 139872637613888 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:56.978478 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:56.986998 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-485\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:57.077170 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:57.140302 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:57.144892 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:57.181848 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:57.211817 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 485 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:57.734726 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 485 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.25613463, step = 485\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.23100026, step = 485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.2447066, step = 485\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:55:58.322156 139660100417344 basic_session_run_hooks.py:262] loss = 0.25613463, step = 485\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:55:58.322235 139872637613888 basic_session_run_hooks.py:262] loss = 0.2447066, step = 485\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:55:58.322249 139772761040704 basic_session_run_hooks.py:262] loss = 0.23100026, step = 485\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.24111325, step = 485\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:55:58.322386 140482554521408 basic_session_run_hooks.py:262] loss = 0.24111325, step = 485\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:00.466273 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:00.466342 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:00.466411 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:00.475029 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.2201621.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:00.617245 139772761040704 estimator.py:371] Loss for final step: 0.2201621.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.22234422.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:00.619776 139872637613888 estimator.py:371] Loss for final step: 0.22234422.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.21526757.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:00.624429 139660100417344 estimator.py:371] Loss for final step: 0.21526757.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.2287496.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:00.627467 140482554521408 estimator.py:371] Loss for final step: 0.2287496.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:00.655833 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:00.657624 139772761040704 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:00.663779 139660100417344 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:00.667234 140482554521408 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:00.878780 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-23T07:56:00Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:00.898764 139872637613888 evaluation.py:255] Starting evaluation at 2021-02-23T07:56:00Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:00.992112 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:01.000258 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:01.079288 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:01.098973 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:01.252211 139772761040704 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:01.253614 139772761040704 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:01.254918 139660100417344 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:01.256273 139660100417344 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:01.267620 140482554521408 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:01.269060 140482554521408 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-23-07:56:01\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:01.347763 139872637613888 evaluation.py:275] Finished evaluation at 2021-02-23-07:56:01\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 582: auc = 0.68121785, global_step = 582, loss = 1.4653285\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:01.347995 139872637613888 estimator.py:2049] Saving dict for global step 582: auc = 0.68121785, global_step = 582, loss = 1.4653285\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 582: /opt/ml/deepfm/checkpoints/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:01.348390 139872637613888 estimator.py:2109] Saving 'checkpoint_path' summary for global step 582: /opt/ml/deepfm/checkpoints/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:01.389249 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:01.440034 139772761040704 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:01.443145 139660100417344 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:01.451845 139772761040704 saver.py:1290] Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:01.455374 139660100417344 saver.py:1290] Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:01.457345 140482554521408 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp4nc129__/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:01.465750 140482554521408 saver.py:1290] Restoring parameters from /tmp/tmp4nc129__/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:01.641096 139772761040704 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:01.664781 139772761040704 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:01.669830 139660100417344 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:01.685353 140482554521408 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:01.696858 139660100417344 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:01.710649 140482554521408 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:02.026432 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:02.027867 139872637613888 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:02.171720 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:02.209852 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:02.226876 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:02.368576 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:02.377265 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:02.581332 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:02.607161 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 582 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:03.118103 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 582 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.2206778, step = 582\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.21704105, step = 582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.22506294, step = 582\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.21669537, step = 582\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:03.751713 139660100417344 basic_session_run_hooks.py:262] loss = 0.2206778, step = 582\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:03.751752 139872637613888 basic_session_run_hooks.py:262] loss = 0.22506294, step = 582\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:03.751781 140482554521408 basic_session_run_hooks.py:262] loss = 0.21669537, step = 582\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:03.751716 139772761040704 basic_session_run_hooks.py:262] loss = 0.21704105, step = 582\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:05.956721 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:05.958564 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:05.963402 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:05.965289 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.21841022.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:06.107990 139772761040704 estimator.py:371] Loss for final step: 0.21841022.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.22071698.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:06.112742 139872637613888 estimator.py:371] Loss for final step: 0.22071698.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.215841.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:06.116912 140482554521408 estimator.py:371] Loss for final step: 0.215841.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.20352349.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:06.117800 139660100417344 estimator.py:371] Loss for final step: 0.20352349.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:06.147930 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:06.150646 139772761040704 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:06.158355 140482554521408 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:06.165377 139660100417344 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:06.365454 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-23T07:56:06Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:06.384792 139872637613888 evaluation.py:255] Starting evaluation at 2021-02-23T07:56:06Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:06.475391 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:06.483505 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:06.562581 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:06.583600 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:06.750527 139772761040704 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:06.751931 139772761040704 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:06.764694 140482554521408 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:06.766105 140482554521408 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:06.794451 139660100417344 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:06.795843 139660100417344 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-23-07:56:06\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:06.836991 139872637613888 evaluation.py:275] Finished evaluation at 2021-02-23-07:56:06\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 679: auc = 0.68171316, global_step = 679, loss = 1.6176991\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:06.837211 139872637613888 estimator.py:2049] Saving dict for global step 679: auc = 0.68171316, global_step = 679, loss = 1.6176991\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 679: /opt/ml/deepfm/checkpoints/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:06.837606 139872637613888 estimator.py:2109] Saving 'checkpoint_path' summary for global step 679: /opt/ml/deepfm/checkpoints/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:06.877550 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:06.941073 139772761040704 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:06.949872 139772761040704 saver.py:1290] Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:06.957658 140482554521408 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp4nc129__/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:06.966123 140482554521408 saver.py:1290] Restoring parameters from /tmp/tmp4nc129__/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:06.995395 139660100417344 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:07.003913 139660100417344 saver.py:1290] Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:07.143362 139772761040704 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:07.160090 140482554521408 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:07.167578 139772761040704 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:07.184939 140482554521408 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:07.200185 139660100417344 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:07.224783 139660100417344 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:07.513460 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:07.514881 139872637613888 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:07.657917 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:07.679178 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:07.713804 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:07.722766 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-679\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:07.739913 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:07.934015 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:07.959670 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 679 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:08.473714 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 679 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.21069849, step = 679\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.2134513, step = 679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.23494345, step = 679\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:09.105135 140482554521408 basic_session_run_hooks.py:262] loss = 0.2134513, step = 679\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.22542523, step = 679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:09.105123 139872637613888 basic_session_run_hooks.py:262] loss = 0.23494345, step = 679\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:09.105195 139772761040704 basic_session_run_hooks.py:262] loss = 0.22542523, step = 679\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:09.105112 139660100417344 basic_session_run_hooks.py:262] loss = 0.21069849, step = 679\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:11.263142 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:11.264687 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:11.268318 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:11.272958 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.20298898.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:11.404798 139772761040704 estimator.py:371] Loss for final step: 0.20298898.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.19453117.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:11.405020 139872637613888 estimator.py:371] Loss for final step: 0.19453117.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.20707038.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:11.418319 140482554521408 estimator.py:371] Loss for final step: 0.20707038.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.1883458.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:11.420772 139660100417344 estimator.py:371] Loss for final step: 0.1883458.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:11.439599 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:11.453172 139772761040704 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:11.459716 139660100417344 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:11.467923 140482554521408 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:11.653922 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-23T07:56:11Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:11.673053 139872637613888 evaluation.py:255] Starting evaluation at 2021-02-23T07:56:11Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:11.762278 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:11.770193 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:11.845054 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:11.863810 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:12.053726 139660100417344 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:12.055070 139660100417344 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:12.076765 139772761040704 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:12.078196 139772761040704 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:12.103602 140482554521408 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:12.105060 140482554521408 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-23-07:56:12\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:12.107414 139872637613888 evaluation.py:275] Finished evaluation at 2021-02-23-07:56:12\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 776: auc = 0.6816339, global_step = 776, loss = 1.7191894\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:12.107636 139872637613888 estimator.py:2049] Saving dict for global step 776: auc = 0.6816339, global_step = 776, loss = 1.7191894\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 776: /opt/ml/deepfm/checkpoints/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:12.108042 139872637613888 estimator.py:2109] Saving 'checkpoint_path' summary for global step 776: /opt/ml/deepfm/checkpoints/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:12.150798 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:12.389128 139660100417344 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:12.397639 139660100417344 saver.py:1290] Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:12.418785 139772761040704 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:12.427945 139772761040704 saver.py:1290] Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:12.444768 140482554521408 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp4nc129__/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:12.453385 140482554521408 saver.py:1290] Restoring parameters from /tmp/tmp4nc129__/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:12.592667 139660100417344 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:12.617484 139660100417344 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:12.629791 139772761040704 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:12.656587 139772761040704 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:12.656813 140482554521408 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:12.682378 140482554521408 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:12.784413 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:12.785897 139872637613888 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:12.982880 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:12.991377 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-776\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:13.115998 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:13.164345 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:13.182229 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:13.193036 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:13.207639 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 776 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:13.764040 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 776 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.18508923, step = 776\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.20114756, step = 776\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.20721738, step = 776\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.2149204, step = 776\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:14.360337 139772761040704 basic_session_run_hooks.py:262] loss = 0.20114756, step = 776\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:14.360330 140482554521408 basic_session_run_hooks.py:262] loss = 0.18508923, step = 776\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:14.360383 139872637613888 basic_session_run_hooks.py:262] loss = 0.2149204, step = 776\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:14.360324 139660100417344 basic_session_run_hooks.py:262] loss = 0.20721738, step = 776\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-02-23 07:56:24 Uploading - Uploading generated training model\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:16.498607 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:16.498697 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:16.504280 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:16.504509 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.1962421.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:16.646716 139872637613888 estimator.py:371] Loss for final step: 0.1962421.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.18906158.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:16.653799 139660100417344 estimator.py:371] Loss for final step: 0.18906158.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.20302951.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:16.656737 140482554521408 estimator.py:371] Loss for final step: 0.20302951.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.20699692.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:16.657100 139772761040704 estimator.py:371] Loss for final step: 0.20699692.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:16.681405 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:16.695420 139660100417344 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:16.696961 140482554521408 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:16.699157 139772761040704 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:16.895724 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-23T07:56:16Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:16.914904 139872637613888 evaluation.py:255] Starting evaluation at 2021-02-23T07:56:16Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:17.004799 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:17.012706 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:17.088448 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:17.107657 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:17.293101 140482554521408 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:17.294444 140482554521408 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:17.304675 139660100417344 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:17.306126 139660100417344 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:17.330389 139772761040704 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:17.331824 139772761040704 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-23-07:56:17\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:17.346161 139872637613888 evaluation.py:275] Finished evaluation at 2021-02-23-07:56:17\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 873: auc = 0.6833758, global_step = 873, loss = 1.6758975\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:17.346369 139872637613888 estimator.py:2049] Saving dict for global step 873: auc = 0.6833758, global_step = 873, loss = 1.6758975\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 873: /opt/ml/deepfm/checkpoints/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:17.346757 139872637613888 estimator.py:2109] Saving 'checkpoint_path' summary for global step 873: /opt/ml/deepfm/checkpoints/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:17.386772 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:17.482912 140482554521408 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp4nc129__/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:17.491738 140482554521408 saver.py:1290] Restoring parameters from /tmp/tmp4nc129__/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:17.497096 139660100417344 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:17.505705 139660100417344 saver.py:1290] Restoring parameters from /tmp/tmpp2thczv5/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:17.529664 139772761040704 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:17.539194 139772761040704 saver.py:1290] Restoring parameters from /tmp/tmp8wl08_sc/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:17.683413 140482554521408 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:17.700359 139660100417344 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:17.707567 140482554521408 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:17.724979 139660100417344 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:17.736062 139772761040704 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:17.760675 139772761040704 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:18.144742 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:18.146165 139872637613888 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:18.199059 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:18.225544 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:18.262297 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:18.341567 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:18.351035 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:18.550428 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:18.575301 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 873 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:19.071186 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 873 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:loss = 0.19614401, step = 873\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:loss = 0.19121426, step = 873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:loss = 0.19003062, step = 873\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:19.682751 140482554521408 basic_session_run_hooks.py:262] loss = 0.19614401, step = 873\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:loss = 0.20687523, step = 873\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:19.682849 139872637613888 basic_session_run_hooks.py:262] loss = 0.19003062, step = 873\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:19.682869 139660100417344 basic_session_run_hooks.py:262] loss = 0.20687523, step = 873\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:19.682839 139772761040704 basic_session_run_hooks.py:262] loss = 0.19121426, step = 873\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 970 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:21.821298 139772761040704 basic_session_run_hooks.py:606] Saving checkpoints for 970 into /tmp/tmp8wl08_sc/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 970 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:21.821535 139872637613888 basic_session_run_hooks.py:606] Saving checkpoints for 970 into /opt/ml/deepfm/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 970 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:21.823432 139660100417344 basic_session_run_hooks.py:606] Saving checkpoints for 970 into /tmp/tmpp2thczv5/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 970 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:21.827952 140482554521408 basic_session_run_hooks.py:606] Saving checkpoints for 970 into /tmp/tmp4nc129__/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Loss for final step: 0.18205947.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:21.966125 139872637613888 estimator.py:371] Loss for final step: 0.18205947.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Loss for final step: 0.17064242.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0223 07:56:21.977334 139660100417344 estimator.py:371] Loss for final step: 0.17064242.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:423: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0223 07:56:21.977652 139660100417344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:423: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.000505 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Loss for final step: 0.19744825.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0223 07:56:22.016244 139772761040704 estimator.py:371] Loss for final step: 0.19744825.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:423: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0223 07:56:22.016575 139772761040704 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:423: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Loss for final step: 0.2042976.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0223 07:56:22.018856 140482554521408 estimator.py:371] Loss for final step: 0.2042976.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:423: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0223 07:56:22.019172 140482554521408 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:423: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.220871 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Starting evaluation at 2021-02-23T07:56:22Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.240630 139872637613888 evaluation.py:255] Starting evaluation at 2021-02-23T07:56:22Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.332097 139872637613888 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-970\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.340279 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-970\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.420250 139872637613888 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.441724 139872637613888 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Finished evaluation at 2021-02-23-07:56:22\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.697555 139872637613888 evaluation.py:275] Finished evaluation at 2021-02-23-07:56:22\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving dict for global step 970: auc = 0.6930612, global_step = 970, loss = 1.9404798\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.697773 139872637613888 estimator.py:2049] Saving dict for global step 970: auc = 0.6930612, global_step = 970, loss = 1.9404798\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving 'checkpoint_path' summary for global step 970: /opt/ml/deepfm/checkpoints/model.ckpt-970\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.698177 139872637613888 estimator.py:2109] Saving 'checkpoint_path' summary for global step 970: /opt/ml/deepfm/checkpoints/model.ckpt-970\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:423: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:56:22.698732 139872637613888 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:423: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:431: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:This function has been renamed, use `export_saved_model` instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:56:22.700407 139872637613888 deprecation.py:323] From DeepFM-hvd-tfrecord-vectorized-map.py:431: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:This function has been renamed, use `export_saved_model` instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.707588 139872637613888 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.811759 139872637613888 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0223 07:56:22.812023 139872637613888 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.812441 139872637613888 export_utils.py:170] Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.812557 139872637613888 export_utils.py:170] Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.812661 139872637613888 export_utils.py:170] Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.812799 139872637613888 export_utils.py:170] Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.812944 139872637613888 export_utils.py:170] Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-970\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.915647 139872637613888 saver.py:1290] Restoring parameters from /opt/ml/deepfm/checkpoints/model.ckpt-970\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets added to graph.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.951786 139872637613888 builder_impl.py:665] Assets added to graph.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:22.951956 139872637613888 builder_impl.py:460] No assets to write.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:SavedModel written to: /opt/ml/model/temp-1614066982/saved_model.pb\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0223 07:56:23.010857 139872637613888 builder_impl.py:425] SavedModel written to: /opt/ml/model/temp-1614066982/saved_model.pb\u001b[0m\n",
      "\u001b[34m2021-02-23 07:56:23,588 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-02-23 07:56:30 Completed - Training job completed\n",
      "Training seconds: 117\n",
      "Billable seconds: 35\n",
      "Managed Spot Training savings: 70.1%\n"
     ]
    }
   ],
   "source": [
    "#下面这个测试file mode\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/training/'\n",
    "validate_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/val/'\n",
    "\n",
    "if enable_s3_shard:\n",
    "    train_input = TrainingInput(train_s3_uri, distribution='ShardedByS3Key')\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "else :\n",
    "    train_input = TrainingInput(train_s3_uri)\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "\n",
    "inputs = {training_channel_name : train_input, evaluation_channel_name : val_input}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipe mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面用多个spot实例进行parameter server方式的分布式训练。\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "dt_now = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "bucket = 'sagemaker-us-west-2-169088282855'\n",
    "checkpoint_s3_uri = 's3://{}/deepfm-checkpoint/{}'.format(bucket, dt_now) #Change to your own path if you want to save ckpt during training\n",
    "checkpoint_dir = '/opt/ml/deepfm/checkpoints'\n",
    "model_dir = '/opt/ml/model'\n",
    "output_path= 's3://{}/deepfm-2021'.format(bucket)\n",
    "\n",
    "training_channel_name = 'training'\n",
    "evaluation_channel_name = 'evaluation'\n",
    "\n",
    "train_instance_type = 'ml.p3.8xlarge'\n",
    "hvd_processes_per_host = 4\n",
    "train_instance_count= 1\n",
    "\n",
    "train_use_spot_instances = True\n",
    "enable_s3_shard = True\n",
    "enable_data_multi_path = False\n",
    "\n",
    "#enable pipe mode\n",
    "pipe_mode = 1\n",
    "\n",
    "train_max_run=36000*2\n",
    "train_max_wait = 72000 if train_use_spot_instances else None\n",
    "\n",
    "distributions = {'mpi': {\n",
    "                    'enabled': True,\n",
    "                    'processes_per_host': hvd_processes_per_host,\n",
    "                    'custom_mpi_options': '-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none'\n",
    "                        }\n",
    "                }\n",
    "\n",
    "deep_layer = '128,64,32'\n",
    "\n",
    "batch_size = 1024\n",
    "feature_size = 117581\n",
    "\n",
    "base_job_name='tf-scriptmode-deepfm'\n",
    "\n",
    "hyperparameters = {'servable_model_dir': '/opt/ml/model', 'checkpoint_dir':checkpoint_dir,\n",
    "                   'training_data_dir': '/opt/ml/input/data/training/', 'val_data_dir': '/opt/ml/input/data/evaluation/', 'log_steps': 10, 'num_epochs': 10, \n",
    "                   'field_size': 39, 'feature_size': feature_size, 'deep_layers': deep_layer,\n",
    "                   'perform_shuffle': 0, 'batch_size': batch_size, 'pipe_mode': pipe_mode, 'enable_s3_shard': enable_s3_shard,\n",
    "                   'training_channel_name': training_channel_name, 'evaluation_channel_name': evaluation_channel_name,\n",
    "                   'worker_per_host': hvd_processes_per_host, 'enable_data_multi_path': enable_data_multi_path\n",
    "                  }\n",
    "\n",
    "estimator = TensorFlow(\n",
    "                       #source_dir='./',\n",
    "                       entry_point='DeepFM-hvd-tfrecord-vectorized-map.py',\n",
    "                       model_dir=False,\n",
    "                       #checkpoint_s3_uri = checkpoint_s3_uri,\n",
    "                       #checkpoint_local_path = checkpoint_local_path,\n",
    "                       output_path= output_path,\n",
    "                       instance_type=train_instance_type,\n",
    "                       instance_count=train_instance_count,\n",
    "                       #volume_size = 500,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       base_job_name=base_job_name,\n",
    "                       framework_version='1.14',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True,\n",
    "                       input_mode='Pipe',\n",
    "                       distribution=distributions,\n",
    "                       use_spot_instances=train_use_spot_instances,\n",
    "                       max_wait=train_max_wait,\n",
    "                       max_run=train_max_run,\n",
    "                       debugger_hook_config =False,\n",
    "                       disable_profiler=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-22 16:22:47 Starting - Starting the training job...\n",
      "2021-02-22 16:22:50 Starting - Launching requested ML instances.........\n",
      "2021-02-22 16:24:31 Starting - Preparing the instances for training...\n",
      "2021-02-22 16:25:07 Downloading - Downloading input data...\n",
      "2021-02-22 16:25:39 Training - Downloading the training image...\n",
      "2021-02-22 16:26:11 Training - Training image download completed. Training in progress..\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      " Data for JOB [60595,1] offset 0 Total slots allocated 4\n",
      "\n",
      " ========================   JOB MAP   ========================\n",
      "\n",
      " Data for node: ip-10-0-138-82#011Num slots: 4#011Max slots: 0#011Num procs: 4\n",
      " #011Process OMPI jobid: [60595,1] App: 0 Process rank: 0 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [60595,1] App: 0 Process rank: 1 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [60595,1] App: 0 Process rank: 2 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [60595,1] App: 0 Process rank: 3 Bound: UNBOUND\n",
      "\n",
      " =============================================================\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mWARNING: Open MPI tried to bind a process but failed.  This is a\u001b[0m\n",
      "\u001b[34mwarning only; your job will continue, though performance may\u001b[0m\n",
      "\u001b[34mbe degraded.\n",
      "\n",
      "  Local host:        ip-10-0-138-82\n",
      "  Application name:  /usr/local/bin/python3.6\n",
      "  Error message:     failed to bind memory\n",
      "  Location:          rtc_hwloc.c:447\n",
      "\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:18.361292 140014048130816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:18.361295 140121141290752 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:18.361276 140432338822912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:18.361561 140121141290752 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:18.361559 140014048130816 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:18.361575 140432338822912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:18.396287 140389551736576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:107: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:18.396631 140389551736576 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:141: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:19.996749 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:19.996992 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:19.997004 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:19.997122 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:439: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:19.997040 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:19.997065 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:19.997264 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:19.997274 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:19.997294 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:438: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:19.997411 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:439: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:19.997408 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:439: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:19.997412 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:439: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_data_multi_path', 'False', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '1', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_data_multi_path', 'False', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '1', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_data_multi_path', 'False', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '1', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_data_multi_path', 'False', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '1', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/', '--worker_per_host', '4']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:tr_files: \u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:va_files: \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:te_files: \u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:tr_files: \u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:va_files: \u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:te_files: \u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.090069 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:356: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.090591 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:356: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.091612 140389551736576 estimator.py:1811] Using temporary folder as model directory: /tmp/tmprf6zrzsz\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:20.092479 140389551736576 estimator.py:209] Using config: {'_model_dir': '/tmp/tmprf6zrzsz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  visible_device_list: \"2\"\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fae5492b0f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.090213 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:356: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.091440 140121141290752 estimator.py:1811] Using temporary folder as model directory: /tmp/tmp2i5sxaku\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:20.092334 140121141290752 estimator.py:209] Using config: {'_model_dir': '/tmp/tmp2i5sxaku', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  visible_device_list: \"3\"\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6fd6255080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.090919 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:356: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:20.091127 140014048130816 estimator.py:209] Using config: {'_model_dir': '/opt/ml/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  visible_device_list: \"0\"\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f56e6e940b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.091942 140432338822912 estimator.py:1811] Using temporary folder as model directory: /tmp/tmprvma3v0m\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:20.092905 140432338822912 estimator.py:209] Using config: {'_model_dir': '/tmp/tmprvma3v0m', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  visible_device_list: \"1\"\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb84afac0f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:tr_files: \u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:va_files: \u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:te_files: \u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:current horovod rank is  2\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:tr_files: \u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:va_files: \u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:te_files: \u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:current horovod rank is  1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:current horovod rank is  0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:channel name ['evaluation', 'training', 'training-1', 'training-2', 'training-3']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:last channel name training-3\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:current horovod rank is  3\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:channel name ['evaluation', 'training', 'training-1', 'training-2', 'training-3']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:last channel name training-3\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:channel name ['evaluation', 'training', 'training-1', 'training-2', 'training-3']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:last channel name training-3\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:channel name ['evaluation', 'training', 'training-1', 'training-2', 'training-3']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:last channel name training-3\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.100745 140389551736576 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.100884 140432338822912 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.100951 140121141290752 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.101020 140014048130816 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:-------enter into pipe mode branch!------------\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:-------enter into pipe mode branch!------------\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:-------enter into pipe mode branch!------------\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:-------enter into pipe mode branch!------------\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.125456 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:79: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.125614 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:79: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.125602 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:79: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.125629 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:81: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.125696 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:79: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.125771 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:81: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.125796 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:81: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.125869 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:81: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:20.159722 140014048130816 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.159947 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:20.160100 140121141290752 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:20.160261 140432338822912 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.160330 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.160579 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:20.160579 140389551736576 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.160793 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:159: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.164354 140014048130816 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Call initializer instance with the dtype argument instead of passing it to the constructor[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.164913 140121141290752 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Call initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.165301 140432338822912 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Call initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.165369 140389551736576 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Call initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.182970 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:170: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.184206 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:170: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.184588 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:170: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.184691 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:170: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.539232 140014048130816 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:211: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.540126 140121141290752 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:211: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.540920 140432338822912 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:211: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.543314 140389551736576 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:211: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.639772 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:228: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.642248 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:228: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.642913 140014048130816 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.643095 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:228: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.645245 140389551736576 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.646180 140432338822912 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.649877 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:228: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.652972 140121141290752 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.655019 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.656904 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.658213 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.665008 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:243: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.733983 140014048130816 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:809: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.734456 140389551736576 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:809: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.738294 140432338822912 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:809: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.745431 140121141290752 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:809: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.777171 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:254: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.777302 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:254: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:26:20.777377 140014048130816 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:264: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 16:26:20.777507 140389551736576 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:264: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.782551 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:254: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 16:26:20.782762 140432338822912 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:264: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.789524 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:254: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 16:26:20.789731 140121141290752 deprecation_wrapper.py:119] From DeepFM-hvd-tfrecord-vectorized-map.py:264: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[ip-10-0-138-82.us-west-2.compute.internal:00051] 3 more processes have sent help message help-orte-odls-default.txt / memory not bound\u001b[0m\n",
      "\u001b[34m[ip-10-0-138-82.us-west-2.compute.internal:00051] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:21.307508 140432338822912 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:21.307945 140121141290752 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:21.309148 140432338822912 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:21.309573 140121141290752 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:21.317654 140389551736576 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:21.319292 140389551736576 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:21.321895 140014048130816 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:21.323568 140014048130816 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:21.741265 140432338822912 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:21.741542 140121141290752 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:21.758707 140389551736576 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:21.759711 140014048130816 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 16:26:24.836808: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:2021-02-22 16:26:24.846965: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:24.850627 140014048130816 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:24.853578 140432338822912 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:2021-02-22 16:26:24.869854: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:24.872532 140014048130816 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:24.874199 140432338822912 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:24.876677 140389551736576 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:2021-02-22 16:26:24.887848: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:24.894602 140121141290752 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:24.897580 140389551736576 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:24.915534 140121141290752 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:25.460556 140432338822912 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmprvma3v0m/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:25.488250 140014048130816 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:25.500613 140389551736576 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmprf6zrzsz/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:25.523600 140121141290752 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmp2i5sxaku/model.ckpt.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,1]<stderr>:2021-02-22 16:26:25.744873: W tensorflow/core/framework/dataset.cc:404] Input of PipeModeDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:2021-02-22 16:26:25.756013: W tensorflow/core/framework/dataset.cc:404] Input of PipeModeDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 16:26:25.759490: W tensorflow/core/framework/dataset.cc:404] Input of PipeModeDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:2021-02-22 16:26:25.783438: W tensorflow/core/framework/dataset.cc:404] Input of PipeModeDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.138.82<0>\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:NCCL version 2.4.7+cuda10.0\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.138.82<0>\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.138.82<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.138.82<0>\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 00 :    0   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 01 :    0   2   1   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 02 :    0   3   1   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 03 :    0   3   2   1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 04 :    0   1   2   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 05 :    0   2   1   3\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 06 :    0   3   1   2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Channel 07 :    0   3   2   1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 00 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 00 : 0[0] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 00 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 00 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 01 : 1[1] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 01 : 0[0] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 01 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 01 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 02 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 02 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 02 : 2[2] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 02 : 3[3] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 03 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 03 : 1[1] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 03 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 03 : 3[3] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 04 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 04 : 0[0] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 04 : 2[2] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 04 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 05 : 1[1] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 05 : 0[0] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 05 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 05 : 3[3] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 06 : 1[1] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 06 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 06 : 2[2] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 06 : 3[3] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Ring 07 : 0[0] -> 3[3] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO Ring 07 : 1[1] -> 0[0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO Ring 07 : 2[2] -> 1[1] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO Ring 07 : 3[3] -> 2[2] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO comm 0x7f56e0710aa0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:algo-1:57:200 [1] NCCL INFO comm 0x7fb8447028b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:algo-1:58:201 [2] NCCL INFO comm 0x7fae507021b0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:algo-1:59:203 [3] NCCL INFO comm 0x7f6fd0701c30 rank 3 nranks 4 cudaDev 3 nvmlDev 3 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:algo-1:56:202 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:27.305060 140432338822912 basic_session_run_hooks.py:262] loss = 0.69678795, step = 0\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:27.307405 140014048130816 basic_session_run_hooks.py:262] loss = 0.6964474, step = 0\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:27.311202 140389551736576 basic_session_run_hooks.py:262] loss = 0.69663006, step = 0\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:27.311527 140121141290752 basic_session_run_hooks.py:262] loss = 0.6965787, step = 0\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:35.797043 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 11.7751\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:35.797960 140432338822912 basic_session_run_hooks.py:260] loss = 0.5119243, step = 100 (8.493 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:35.808963 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 11.7619\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:35.809897 140014048130816 basic_session_run_hooks.py:260] loss = 0.5075308, step = 100 (8.503 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:35.821233 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 11.7505\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:35.822079 140121141290752 basic_session_run_hooks.py:260] loss = 0.5024146, step = 100 (8.511 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:35.822091 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 11.749\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:35.822960 140389551736576 basic_session_run_hooks.py:260] loss = 0.5087091, step = 100 (8.512 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:43.631709 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7638\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:43.632644 140432338822912 basic_session_run_hooks.py:260] loss = 0.49920604, step = 200 (7.835 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:43.643676 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.7637\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:43.644498 140014048130816 basic_session_run_hooks.py:260] loss = 0.5013862, step = 200 (7.835 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:43.655025 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7652\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:43.655913 140121141290752 basic_session_run_hooks.py:260] loss = 0.4995842, step = 200 (7.834 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:43.656290 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7645\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:43.657090 140389551736576 basic_session_run_hooks.py:260] loss = 0.49970508, step = 200 (7.834 sec)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,2]<stderr>:I0222 16:26:51.539284 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6856\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:51.540243 140389551736576 basic_session_run_hooks.py:260] loss = 0.4352495, step = 300 (7.883 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:51.540313 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6636\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:51.541116 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6806\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:51.541151 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6432\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:51.541295 140014048130816 basic_session_run_hooks.py:260] loss = 0.43264875, step = 300 (7.897 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:51.542168 140121141290752 basic_session_run_hooks.py:260] loss = 0.43114898, step = 300 (7.886 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:51.542221 140432338822912 basic_session_run_hooks.py:260] loss = 0.4257103, step = 300 (7.910 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:59.575684 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.4463\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:26:59.576633 140432338822912 basic_session_run_hooks.py:260] loss = 0.4327226, step = 400 (8.034 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:59.588627 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.425\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:59.588677 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.4261\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:59.588753 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.4232\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:26:59.589495 140121141290752 basic_session_run_hooks.py:260] loss = 0.44197372, step = 400 (8.047 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:26:59.589504 140014048130816 basic_session_run_hooks.py:260] loss = 0.43155897, step = 400 (8.048 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:26:59.589662 140389551736576 basic_session_run_hooks.py:260] loss = 0.44487563, step = 400 (8.049 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:07.639246 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.4216\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:07.639312 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.4013\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:07.640050 140389551736576 basic_session_run_hooks.py:260] loss = 0.38178706, step = 500 (8.050 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:07.640127 140432338822912 basic_session_run_hooks.py:260] loss = 0.3654773, step = 500 (8.063 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:07.661875 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.3866\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:07.662686 140121141290752 basic_session_run_hooks.py:260] loss = 0.39600113, step = 500 (8.073 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:07.662947 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.3849\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:07.663893 140014048130816 basic_session_run_hooks.py:260] loss = 0.36893976, step = 500 (8.074 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:15.552218 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6738\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:15.552396 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6752\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:15.552551 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.637\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:15.553211 140121141290752 basic_session_run_hooks.py:260] loss = 0.3566168, step = 600 (7.891 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:15.553354 140389551736576 basic_session_run_hooks.py:260] loss = 0.34837553, step = 600 (7.913 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:15.553353 140014048130816 basic_session_run_hooks.py:260] loss = 0.35300466, step = 600 (7.889 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:15.554471 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.634\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:15.555454 140432338822912 basic_session_run_hooks.py:260] loss = 0.36142638, step = 600 (7.915 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:23.573162 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.4709\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:23.574174 140432338822912 basic_session_run_hooks.py:260] loss = 0.33269083, step = 700 (8.019 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:23.581357 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.4549\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:23.582233 140014048130816 basic_session_run_hooks.py:260] loss = 0.33478916, step = 700 (8.029 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:23.597620 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.4299\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:23.597778 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.4292\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:23.598392 140389551736576 basic_session_run_hooks.py:260] loss = 0.34054667, step = 700 (8.045 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:23.598531 140121141290752 basic_session_run_hooks.py:260] loss = 0.34801847, step = 700 (8.045 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:31.515629 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6035\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:31.515554 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6299\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:31.515874 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5902\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:31.516441 140014048130816 basic_session_run_hooks.py:260] loss = 0.32547107, step = 800 (7.934 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:31.516622 140121141290752 basic_session_run_hooks.py:260] loss = 0.33292928, step = 800 (7.918 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:31.516751 140432338822912 basic_session_run_hooks.py:260] loss = 0.32196587, step = 800 (7.943 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:31.529746 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.607\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:31.530596 140389551736576 basic_session_run_hooks.py:260] loss = 0.343571, step = 800 (7.932 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:39.296270 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.8523\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:39.296826 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.8515\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:39.297236 140121141290752 basic_session_run_hooks.py:260] loss = 0.32076162, step = 900 (7.781 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:39.297694 140014048130816 basic_session_run_hooks.py:260] loss = 0.32229495, step = 900 (7.781 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:39.321034 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.8349\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:39.321860 140389551736576 basic_session_run_hooks.py:260] loss = 0.32272172, step = 900 (7.791 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:39.321863 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.8106\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:39.322617 140432338822912 basic_session_run_hooks.py:260] loss = 0.32189885, step = 900 (7.806 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:47.206103 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6822\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:47.206102 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6836\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:47.206972 140389551736576 basic_session_run_hooks.py:260] loss = 0.33881783, step = 1000 (7.885 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:47.207065 140432338822912 basic_session_run_hooks.py:260] loss = 0.33682638, step = 1000 (7.884 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:47.210842 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6349\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:47.211686 140121141290752 basic_session_run_hooks.py:260] loss = 0.34686518, step = 1000 (7.914 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:47.212406 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6333\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:47.213577 140014048130816 basic_session_run_hooks.py:260] loss = 0.34639478, step = 1000 (7.916 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:55.186566 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5405\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:55.186655 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5305\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:27:55.187495 140014048130816 basic_session_run_hooks.py:260] loss = 0.3478163, step = 1100 (7.974 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:27:55.187504 140432338822912 basic_session_run_hooks.py:260] loss = 0.34920353, step = 1100 (7.980 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:55.198556 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5192\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:55.198687 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5116\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:27:55.199410 140389551736576 basic_session_run_hooks.py:260] loss = 0.34924465, step = 1100 (7.992 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:27:55.199514 140121141290752 basic_session_run_hooks.py:260] loss = 0.3614805, step = 1100 (7.988 sec)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,2]<stderr>:I0222 16:28:03.062580 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7164\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:03.062526 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6971\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:03.063098 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6959\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:03.063445 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7147\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:03.063532 140389551736576 basic_session_run_hooks.py:260] loss = 0.34033877, step = 1200 (7.864 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:03.063655 140432338822912 basic_session_run_hooks.py:260] loss = 0.33552784, step = 1200 (7.876 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:03.064073 140014048130816 basic_session_run_hooks.py:260] loss = 0.33531767, step = 1200 (7.877 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:03.064216 140121141290752 basic_session_run_hooks.py:260] loss = 0.3347452, step = 1200 (7.865 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:11.045060 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5283\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:11.045262 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5269\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:11.045262 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5271\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:11.045739 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5277\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:11.046025 140432338822912 basic_session_run_hooks.py:260] loss = 0.30754536, step = 1300 (7.982 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:11.046049 140014048130816 basic_session_run_hooks.py:260] loss = 0.31530946, step = 1300 (7.982 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:11.046091 140389551736576 basic_session_run_hooks.py:260] loss = 0.31074572, step = 1300 (7.983 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:11.046573 140121141290752 basic_session_run_hooks.py:260] loss = 0.3242435, step = 1300 (7.982 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:18.908675 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7173\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:18.908877 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7168\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:18.909511 140432338822912 basic_session_run_hooks.py:260] loss = 0.2866537, step = 1400 (7.863 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:18.909737 140389551736576 basic_session_run_hooks.py:260] loss = 0.28406906, step = 1400 (7.864 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:18.922043 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6963\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:18.923029 140121141290752 basic_session_run_hooks.py:260] loss = 0.28637108, step = 1400 (7.876 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:18.936532 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6719\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:18.937456 140014048130816 basic_session_run_hooks.py:260] loss = 0.29061317, step = 1400 (7.891 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:26.825997 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6519\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:26.826431 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6302\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:26.827045 140121141290752 basic_session_run_hooks.py:260] loss = 0.29711172, step = 1500 (7.904 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:26.827585 140389551736576 basic_session_run_hooks.py:260] loss = 0.29231125, step = 1500 (7.918 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:26.853291 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6314\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:26.853686 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5864\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:26.854288 140014048130816 basic_session_run_hooks.py:260] loss = 0.29624107, step = 1500 (7.917 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:26.854575 140432338822912 basic_session_run_hooks.py:260] loss = 0.29949203, step = 1500 (7.945 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:34.764771 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6405\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:34.765227 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6391\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:34.765751 140432338822912 basic_session_run_hooks.py:260] loss = 0.25211748, step = 1600 (7.911 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:34.766136 140014048130816 basic_session_run_hooks.py:260] loss = 0.25739542, step = 1600 (7.912 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:34.775932 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5787\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:34.776347 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5787\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:34.776855 140121141290752 basic_session_run_hooks.py:260] loss = 0.2568985, step = 1600 (7.950 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:34.777178 140389551736576 basic_session_run_hooks.py:260] loss = 0.25540927, step = 1600 (7.950 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:42.677149 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6392\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:42.678130 140014048130816 basic_session_run_hooks.py:260] loss = 0.26949447, step = 1700 (7.912 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:42.680269 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6334\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:42.680385 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6511\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:42.681036 140432338822912 basic_session_run_hooks.py:260] loss = 0.25579897, step = 1700 (7.915 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:42.681234 140121141290752 basic_session_run_hooks.py:260] loss = 0.27559584, step = 1700 (7.904 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:42.701520 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.618\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:42.702365 140389551736576 basic_session_run_hooks.py:260] loss = 0.27824426, step = 1700 (7.925 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:50.517081 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7605\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:50.517071 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7604\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:50.517656 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7941\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:50.517822 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.754\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:50.518034 140432338822912 basic_session_run_hooks.py:260] loss = 0.25023198, step = 1800 (7.837 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:50.518085 140121141290752 basic_session_run_hooks.py:260] loss = 0.25249553, step = 1800 (7.837 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:50.518454 140389551736576 basic_session_run_hooks.py:260] loss = 0.2525137, step = 1800 (7.816 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:50.518951 140014048130816 basic_session_run_hooks.py:260] loss = 0.25008306, step = 1800 (7.841 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:58.485587 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5503\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:58.485582 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5494\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:28:58.486494 140389551736576 basic_session_run_hooks.py:260] loss = 0.26167628, step = 1900 (7.968 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:28:58.486603 140121141290752 basic_session_run_hooks.py:260] loss = 0.2617768, step = 1900 (7.969 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:58.488880 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5441\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:28:58.489821 140432338822912 basic_session_run_hooks.py:260] loss = 0.25612813, step = 1900 (7.972 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:58.490843 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5423\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:28:58.491747 140014048130816 basic_session_run_hooks.py:260] loss = 0.25909185, step = 1900 (7.973 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:06.419432 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6095\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:06.420328 140432338822912 basic_session_run_hooks.py:260] loss = 0.21738839, step = 2000 (7.931 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:06.423617 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5976\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:06.424773 140389551736576 basic_session_run_hooks.py:260] loss = 0.22015144, step = 2000 (7.938 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:06.433726 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5815\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:06.434668 140121141290752 basic_session_run_hooks.py:260] loss = 0.2240405, step = 2000 (7.948 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:06.446693 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5694\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:06.447489 140014048130816 basic_session_run_hooks.py:260] loss = 0.21728197, step = 2000 (7.956 sec)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,2]<stderr>:I0222 16:29:14.463954 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.4373\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:14.464845 140389551736576 basic_session_run_hooks.py:260] loss = 0.22476599, step = 2100 (8.040 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:14.478156 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.451\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:14.478946 140014048130816 basic_session_run_hooks.py:260] loss = 0.21923453, step = 2100 (8.031 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:14.490466 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.3899\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:14.491314 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.4107\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:14.491379 140432338822912 basic_session_run_hooks.py:260] loss = 0.2205246, step = 2100 (8.071 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:14.492099 140121141290752 basic_session_run_hooks.py:260] loss = 0.22831568, step = 2100 (8.057 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:22.333947 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7064\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:22.333905 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.7296\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:22.334296 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7489\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:22.334784 140389551736576 basic_session_run_hooks.py:260] loss = 0.2331152, step = 2200 (7.870 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:22.334983 140014048130816 basic_session_run_hooks.py:260] loss = 0.2341921, step = 2200 (7.856 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:22.335086 140432338822912 basic_session_run_hooks.py:260] loss = 0.23240316, step = 2200 (7.844 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:22.347180 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7294\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:22.348119 140121141290752 basic_session_run_hooks.py:260] loss = 0.23579535, step = 2200 (7.856 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:30.247268 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6368\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:30.248185 140014048130816 basic_session_run_hooks.py:260] loss = 0.2267976, step = 2300 (7.913 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:30.259548 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6385\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:30.260419 140121141290752 basic_session_run_hooks.py:260] loss = 0.22584715, step = 2300 (7.912 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:30.265374 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6081\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:30.265525 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6084\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:30.266226 140389551736576 basic_session_run_hooks.py:260] loss = 0.21841177, step = 2300 (7.931 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:30.266255 140432338822912 basic_session_run_hooks.py:260] loss = 0.21830231, step = 2300 (7.931 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:38.234560 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5484\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:38.235444 140389551736576 basic_session_run_hooks.py:260] loss = 0.21248895, step = 2400 (7.969 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:38.236618 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.536\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:38.237831 140121141290752 basic_session_run_hooks.py:260] loss = 0.21578187, step = 2400 (7.977 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:38.248422 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5268\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:38.248764 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.4976\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:38.249397 140432338822912 basic_session_run_hooks.py:260] loss = 0.21630785, step = 2400 (7.983 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:38.249531 140014048130816 basic_session_run_hooks.py:260] loss = 0.2149369, step = 2400 (8.001 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:46.078849 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7482\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:46.078970 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7705\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:46.079243 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7507\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:46.079511 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.7702\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:46.079779 140389551736576 basic_session_run_hooks.py:260] loss = 0.22218744, step = 2500 (7.844 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:46.079864 140432338822912 basic_session_run_hooks.py:260] loss = 0.22279227, step = 2500 (7.830 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:46.080060 140121141290752 basic_session_run_hooks.py:260] loss = 0.23945957, step = 2500 (7.842 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:46.080363 140014048130816 basic_session_run_hooks.py:260] loss = 0.23539701, step = 2500 (7.831 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:53.943566 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7152\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:53.943595 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7149\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:29:53.944433 140389551736576 basic_session_run_hooks.py:260] loss = 0.22735332, step = 2600 (7.865 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:29:53.944523 140432338822912 basic_session_run_hooks.py:260] loss = 0.22843558, step = 2600 (7.865 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:53.944438 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7143\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:29:53.945325 140121141290752 basic_session_run_hooks.py:260] loss = 0.24275735, step = 2600 (7.865 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:53.957380 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6938\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:29:53.958284 140014048130816 basic_session_run_hooks.py:260] loss = 0.22154479, step = 2600 (7.878 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:01.989358 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.4289\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:01.989587 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.4298\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:01.990341 140389551736576 basic_session_run_hooks.py:260] loss = 0.20647547, step = 2700 (8.046 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:01.990428 140121141290752 basic_session_run_hooks.py:260] loss = 0.20616996, step = 2700 (8.045 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:02.001820 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.4096\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:02.002775 140432338822912 basic_session_run_hooks.py:260] loss = 0.20826513, step = 2700 (8.058 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:02.004093 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.4274\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:02.004963 140014048130816 basic_session_run_hooks.py:260] loss = 0.21309108, step = 2700 (8.047 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:09.999443 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5073\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:09.999842 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.484\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:10.000289 140014048130816 basic_session_run_hooks.py:260] loss = 0.22376308, step = 2800 (7.995 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:10.000654 140121141290752 basic_session_run_hooks.py:260] loss = 0.21500465, step = 2800 (8.010 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:10.002755 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.4791\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:10.003064 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.4981\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:10.003562 140389551736576 basic_session_run_hooks.py:260] loss = 0.2094556, step = 2800 (8.013 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:10.004144 140432338822912 basic_session_run_hooks.py:260] loss = 0.21463814, step = 2800 (8.001 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:17.906215 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6474\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:17.906389 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6478\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:17.907118 140014048130816 basic_session_run_hooks.py:260] loss = 0.22014639, step = 2900 (7.907 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:17.907205 140121141290752 basic_session_run_hooks.py:260] loss = 0.21580124, step = 2900 (7.907 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:17.919161 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6324\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:17.920032 140432338822912 basic_session_run_hooks.py:260] loss = 0.22011498, step = 2900 (7.916 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:17.920257 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6302\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:17.921112 140389551736576 basic_session_run_hooks.py:260] loss = 0.21550009, step = 2900 (7.918 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:25.755079 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.7407\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:25.755975 140014048130816 basic_session_run_hooks.py:260] loss = 0.23720464, step = 3000 (7.849 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:25.768089 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7424\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:25.769042 140389551736576 basic_session_run_hooks.py:260] loss = 0.22443047, step = 3000 (7.848 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:25.774887 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7295\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:25.775719 140432338822912 basic_session_run_hooks.py:260] loss = 0.22804257, step = 3000 (7.856 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:25.776045 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.707\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:25.776874 140121141290752 basic_session_run_hooks.py:260] loss = 0.23091418, step = 3000 (7.870 sec)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,2]<stderr>:I0222 16:30:33.686388 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.629\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:33.686393 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6416\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:33.687398 140389551736576 basic_session_run_hooks.py:260] loss = 0.22957885, step = 3100 (7.918 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:33.687475 140121141290752 basic_session_run_hooks.py:260] loss = 0.222332, step = 3100 (7.911 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:33.713181 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5658\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:33.713722 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5963\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:33.714257 140014048130816 basic_session_run_hooks.py:260] loss = 0.21288922, step = 3100 (7.958 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:33.714750 140432338822912 basic_session_run_hooks.py:260] loss = 0.22213861, step = 3100 (7.939 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:41.663120 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.5365\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:41.663197 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5364\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:41.664040 140389551736576 basic_session_run_hooks.py:260] loss = 0.21050668, step = 3200 (7.977 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:41.664030 140121141290752 basic_session_run_hooks.py:260] loss = 0.20573977, step = 3200 (7.977 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:41.688529 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.5396\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:41.689413 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5372\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:41.689501 140432338822912 basic_session_run_hooks.py:260] loss = 0.20198575, step = 3200 (7.975 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:41.690325 140014048130816 basic_session_run_hooks.py:260] loss = 0.21114188, step = 3200 (7.976 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:49.507940 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.7474\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:49.507906 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.7887\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:49.508650 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.7461\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:49.508801 140121141290752 basic_session_run_hooks.py:260] loss = 0.21095279, step = 3300 (7.845 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:49.508906 140432338822912 basic_session_run_hooks.py:260] loss = 0.20863265, step = 3300 (7.819 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:49.509542 140389551736576 basic_session_run_hooks.py:260] loss = 0.20877132, step = 3300 (7.846 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:49.521320 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.7683\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:49.522168 140014048130816 basic_session_run_hooks.py:260] loss = 0.20490462, step = 3300 (7.832 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:57.415727 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6458\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:57.415974 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6465\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:30:57.416671 140121141290752 basic_session_run_hooks.py:260] loss = 0.20182455, step = 3400 (7.908 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:30:57.416742 140389551736576 basic_session_run_hooks.py:260] loss = 0.19900677, step = 3400 (7.907 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:57.439760 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6288\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:57.439791 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6073\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:30:57.440632 140014048130816 basic_session_run_hooks.py:260] loss = 0.21815133, step = 3400 (7.918 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:30:57.440652 140432338822912 basic_session_run_hooks.py:260] loss = 0.2030763, step = 3400 (7.932 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:05.349668 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6045\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:05.350318 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6414\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:05.350596 140389551736576 basic_session_run_hooks.py:260] loss = 0.22839507, step = 3500 (7.934 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:05.351124 140432338822912 basic_session_run_hooks.py:260] loss = 0.20341173, step = 3500 (7.910 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:05.376003 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.5624\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:05.376741 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.5992\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:05.376867 140121141290752 basic_session_run_hooks.py:260] loss = 0.22186413, step = 3500 (7.960 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:05.377598 140014048130816 basic_session_run_hooks.py:260] loss = 0.2054109, step = 3500 (7.937 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:13.419127 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.4341\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:13.420000 140014048130816 basic_session_run_hooks.py:260] loss = 0.19874346, step = 3600 (8.042 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:13.421139 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.3893\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:13.422073 140389551736576 basic_session_run_hooks.py:260] loss = 0.18820332, step = 3600 (8.071 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:13.442761 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.3572\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:13.442799 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.3965\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:13.443638 140121141290752 basic_session_run_hooks.py:260] loss = 0.19241157, step = 3600 (8.067 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:13.443683 140432338822912 basic_session_run_hooks.py:260] loss = 0.18485051, step = 3600 (8.093 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:21.341730 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6254\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:21.341733 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6599\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:21.341809 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6598\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:21.341903 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6218\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:21.342618 140121141290752 basic_session_run_hooks.py:260] loss = 0.1914975, step = 3700 (7.899 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:21.342760 140014048130816 basic_session_run_hooks.py:260] loss = 0.20992789, step = 3700 (7.923 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:21.342750 140389551736576 basic_session_run_hooks.py:260] loss = 0.1922314, step = 3700 (7.921 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:21.342806 140432338822912 basic_session_run_hooks.py:260] loss = 0.1966992, step = 3700 (7.899 sec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:29.222248 140014048130816 basic_session_run_hooks.py:692] global_step/sec: 12.6898\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:29.223151 140014048130816 basic_session_run_hooks.py:260] loss = 0.19282454, step = 3800 (7.880 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:29.236503 140389551736576 basic_session_run_hooks.py:692] global_step/sec: 12.6665\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:29.237460 140389551736576 basic_session_run_hooks.py:260] loss = 0.19934087, step = 3800 (7.895 sec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:29.248705 140432338822912 basic_session_run_hooks.py:692] global_step/sec: 12.6471\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:29.249530 140432338822912 basic_session_run_hooks.py:260] loss = 0.20259528, step = 3800 (7.907 sec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:29.249800 140121141290752 basic_session_run_hooks.py:692] global_step/sec: 12.6453\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:29.250602 140121141290752 basic_session_run_hooks.py:260] loss = 0.19565377, step = 3800 (7.908 sec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:37.062630 140389551736576 basic_session_run_hooks.py:606] Saving checkpoints for 3900 into /tmp/tmprf6zrzsz/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.062736 140014048130816 basic_session_run_hooks.py:606] Saving checkpoints for 3900 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:37.062973 140121141290752 basic_session_run_hooks.py:606] Saving checkpoints for 3900 into /tmp/tmp2i5sxaku/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:37.072022 140432338822912 basic_session_run_hooks.py:606] Saving checkpoints for 3900 into /tmp/tmprvma3v0m/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 16:31:37.216102 140389551736576 estimator.py:368] Loss for final step: 0.20286798.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.219326 140014048130816 estimator.py:368] Loss for final step: 0.2040714.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 16:31:37.224050 140121141290752 estimator.py:368] Loss for final step: 0.19620277.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 16:31:37.225245 140432338822912 estimator.py:368] Loss for final step: 0.19593662.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:-------enter into pipe mode branch!------------\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.260337 140014048130816 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.536584 140014048130816 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.560601 140014048130816 evaluation.py:255] Starting evaluation at 2021-02-22T16:31:37Z\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.673575 140014048130816 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:31:37.681197 140014048130816 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1282: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use standard file APIs to check for files with this prefix.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.682335 140014048130816 saver.py:1286] Restoring parameters from /opt/ml/model/model.ckpt-3900\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.768208 140014048130816 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:37.787607 140014048130816 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 16:31:37.847938: W tensorflow/core/framework/dataset.cc:404] Input of PipeModeDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.181355 140014048130816 evaluation.py:275] Finished evaluation at 2021-02-22-16:31:39\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.181580 140014048130816 estimator.py:2039] Saving dict for global step 3900: auc = 0.67065716, global_step = 3900, loss = 1.2234036\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.242358 140014048130816 estimator.py:2099] Saving 'checkpoint_path' summary for global step 3900: /opt/ml/model/model.ckpt-3900\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:31:39.244538 140014048130816 deprecation.py:323] From DeepFM-hvd-tfrecord-vectorized-map.py:435: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:This function has been renamed, use `export_saved_model` instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.252199 140014048130816 estimator.py:1145] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.380671 140014048130816 estimator.py:1147] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 16:31:39.380896 140014048130816 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.381220 140014048130816 export_utils.py:170] Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.381325 140014048130816 export_utils.py:170] Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.381412 140014048130816 export_utils.py:170] Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.381481 140014048130816 export_utils.py:170] Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.381554 140014048130816 export_utils.py:170] Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.421092 140014048130816 saver.py:1286] Restoring parameters from /opt/ml/model/model.ckpt-3900\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.458505 140014048130816 builder_impl.py:661] Assets added to graph.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.458677 140014048130816 builder_impl.py:456] No assets to write.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 16:31:39.523095 140014048130816 builder_impl.py:421] SavedModel written to: /opt/ml/model/temp-b'1614011499'/saved_model.pb\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-02-22 16:31:42 Uploading - Uploading generated training model\n",
      "2021-02-22 16:31:58 Completed - Training job completed\n",
      "Training seconds: 411\n",
      "Billable seconds: 123\n",
      "Managed Spot Training savings: 70.1%\n"
     ]
    }
   ],
   "source": [
    "#下面这个测试pipe mode\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "'''\n",
    "在Pipe mode下需要设置多个训练channel，训练channel的数量需要与woker_per_host强一致。\n",
    "如： inputs = {'training':train_input, 'training-2':train_input, 'training-3':train_input, 'evaluation': validate_s3}\n",
    "\n",
    "训练数据集路径分两种，一种是各个channel用一个训练数据集路径，一种是每个channel有独自的训练数据集路径（每个channel下面数据集样本数量需要保持一致））。\n",
    "用户可以根据实际情况决定在准备数据集的时候采用哪种方式，这里我们以 enable_data_multi_path 这个参数表示是否每个channel有独自的数据集路径\n",
    "'''\n",
    "\n",
    "train_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/training/'\n",
    "validate_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/val/'\n",
    "\n",
    "if enable_data_multi_path:    #假如有4个不同的channel\n",
    "\n",
    "    train_s3_uri_1 = ''\n",
    "    train_s3_uri_2 = ''\n",
    "    train_s3_uri_3 = ''\n",
    "    train_s3_uri_4 = ''\n",
    "    \n",
    "    if enable_s3_shard:\n",
    "        train_input_1 = TrainingInput(train_s3_uri_1, distribution='ShardedByS3Key')\n",
    "        train_input_2 = TrainingInput(train_s3_uri_2, distribution='ShardedByS3Key')\n",
    "        train_input_3 = TrainingInput(train_s3_uri_3, distribution='ShardedByS3Key')\n",
    "        train_input_4 = TrainingInput(train_s3_uri_4, distribution='ShardedByS3Key')\n",
    "    else :\n",
    "        train_input_1 = TrainingInput(train_s3_uri_1)\n",
    "        train_input_2 = TrainingInput(train_s3_uri_2)\n",
    "        train_input_3 = TrainingInput(train_s3_uri_3)\n",
    "        train_input_4 = TrainingInput(train_s3_uri_4)\n",
    "        \n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "    \n",
    "    inputs = {'{}'.format(training_channel_name) : train_input_1,\n",
    "              '{}-1'.format(training_channel_name) : train_input_2,\n",
    "              '{}-2'.format(training_channel_name) : train_input_3,\n",
    "              '{}-3'.format(training_channel_name) : train_input_4, \n",
    "              evaluation_channel_name : val_input}\n",
    "\n",
    "else : #共用一个训练数据集路径 train_s3_uri\n",
    "    \n",
    "    if enable_s3_shard:\n",
    "        train_input = TrainingInput(train_s3_uri, distribution='ShardedByS3Key')\n",
    "    else :\n",
    "        train_input = TrainingInput(train_s3_uri)\n",
    "        \n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "    \n",
    "    inputs = {'{}'.format(training_channel_name) : train_input,\n",
    "              '{}-1'.format(training_channel_name) : train_input,\n",
    "              '{}-2'.format(training_channel_name) : train_input,\n",
    "              '{}-3'.format(training_channel_name) : train_input, \n",
    "              evaluation_channel_name : val_input}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
