{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFM Tensorflow Horovod on SageMaker Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this sample, we will demo how to run a deepfm sample code in tensorflow horovod on sagemaker\n",
    "\n",
    "Notice:\n",
    "\n",
    "1. Dataset format is TFRecord\n",
    "\n",
    "2. This model training we will use **GPU** instances\n",
    "\n",
    "3. Using [SageMaker Python SDK 2.x](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.25.1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面用多个spot实例进行parameter server方式的分布式训练。\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "bucket = 'sagemaker-us-west-2-169088282855'\n",
    "checkpoint_s3_uri = 's3://{}/deepfm-checkpoint'.format(bucket) #Change to your own path if you want to save ckpt during training\n",
    "checkpoint_local_path = '/opt/ml/checkpoints'\n",
    "model_dir = '/opt/ml/model'\n",
    "output_path= 's3://{}/deepfm-2021'.format(bucket)\n",
    "\n",
    "training_channel_name = 'training'\n",
    "evaluation_channel_name = 'evaluation'\n",
    "\n",
    "train_instance_type = 'ml.p3.8xlarge'\n",
    "hvd_processes_per_host = 4\n",
    "train_instance_count= 1\n",
    "\n",
    "train_use_spot_instances = True\n",
    "enable_s3_shard = True\n",
    "\n",
    "train_max_run=36000*2\n",
    "train_max_wait = 72000 if train_use_spot_instances else None\n",
    "\n",
    "distributions = {'mpi': {\n",
    "                    'enabled': True,\n",
    "                    'processes_per_host': hvd_processes_per_host,\n",
    "                    'custom_mpi_options': '-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none'\n",
    "                        }\n",
    "                }\n",
    "\n",
    "deep_layer = '128,64,32'\n",
    "\n",
    "batch_size = 1024\n",
    "feature_size = 117581\n",
    "\n",
    "base_job_name='tf-scriptmode-deepfm'\n",
    "\n",
    "hyperparameters = {'servable_model_dir': '/opt/ml/model', 'training_data_dir': '/opt/ml/input/data/training/',\n",
    "                   'val_data_dir': '/opt/ml/input/data/evaluation/', 'log_steps': 10, 'num_epochs': 10, \n",
    "                   'field_size': 39, 'feature_size': feature_size, 'deep_layers': deep_layer,\n",
    "                   'perform_shuffle': 0, 'batch_size': batch_size, 'pipe_mode': 0, 'enable_s3_shard': enable_s3_shard,\n",
    "                   'training_channel_name': training_channel_name, 'evaluation_channel_name': evaluation_channel_name\n",
    "                  }\n",
    "\n",
    "estimator = TensorFlow(\n",
    "                       #source_dir='./',\n",
    "                       entry_point='DeepFM-hvd-tfrecord-vectorized-map.py',\n",
    "                       model_dir=model_dir,\n",
    "                       #checkpoint_s3_uri = checkpoint_s3_uri,\n",
    "                       #checkpoint_local_path = checkpoint_local_path,\n",
    "                       output_path= output_path,\n",
    "                       instance_type=train_instance_type,\n",
    "                       instance_count=train_instance_count,\n",
    "                       #volume_size = 500,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       base_job_name=base_job_name,\n",
    "                       framework_version='1.15.2',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True,\n",
    "                       #input_mode='Pipe',\n",
    "                       distribution=distributions,\n",
    "                       use_spot_instances=train_use_spot_instances,\n",
    "                       max_wait=train_max_wait,\n",
    "                       max_run=train_max_run,\n",
    "                       debugger_hook_config =False,\n",
    "                       disable_profiler=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-22 11:13:18 Starting - Starting the training job...\n",
      "2021-02-22 11:13:20 Starting - Launching requested ML instances......\n",
      "2021-02-22 11:14:31 Starting - Preparing the instances for training......\n",
      "2021-02-22 11:15:42 Downloading - Downloading input data...\n",
      "2021-02-22 11:15:54 Training - Downloading the training image......\n",
      "2021-02-22 11:17:17 Uploading - Uploading generated training model\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-02-22 11:17:06,030 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-02-22 11:17:06,470 sagemaker-containers INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2021-02-22 11:17:06,471 sagemaker-containers INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2021-02-22 11:17:06,478 sagemaker-containers INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2021-02-22 11:17:06,478 sagemaker-containers INFO     Env Hosts: ['algo-1'] Hosts: ['algo-1:4'] process_per_hosts: 4 num_processes: 4\u001b[0m\n",
      "\u001b[34m2021-02-22 11:17:06,480 sagemaker-containers INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2021-02-22 11:17:06,527 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_mpi_num_of_processes_per_host\": 4,\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none\",\n",
      "        \"sagemaker_mpi_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"evaluation\": \"/opt/ml/input/data/evaluation\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 1024,\n",
      "        \"val_data_dir\": \"/opt/ml/input/data/evaluation/\",\n",
      "        \"log_steps\": 10,\n",
      "        \"field_size\": 39,\n",
      "        \"deep_layers\": \"128,64,32\",\n",
      "        \"training_channel_name\": \"training\",\n",
      "        \"training_data_dir\": \"/opt/ml/input/data/training/\",\n",
      "        \"perform_shuffle\": 0,\n",
      "        \"evaluation_channel_name\": \"evaluation\",\n",
      "        \"feature_size\": 117581,\n",
      "        \"pipe_mode\": 0,\n",
      "        \"servable_model_dir\": \"/opt/ml/model\",\n",
      "        \"model_dir\": \"/opt/ml/model\",\n",
      "        \"enable_s3_shard\": true,\n",
      "        \"num_epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"evaluation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"ShardedByS3Key\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tf-scriptmode-deepfm-2021-02-22-11-13-17-852\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-22-11-13-17-852/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"DeepFM-hvd-tfrecord-vectorized-map\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"DeepFM-hvd-tfrecord-vectorized-map.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":1024,\"deep_layers\":\"128,64,32\",\"enable_s3_shard\":true,\"evaluation_channel_name\":\"evaluation\",\"feature_size\":117581,\"field_size\":39,\"log_steps\":10,\"model_dir\":\"/opt/ml/model\",\"num_epochs\":10,\"perform_shuffle\":0,\"pipe_mode\":0,\"servable_model_dir\":\"/opt/ml/model\",\"training_channel_name\":\"training\",\"training_data_dir\":\"/opt/ml/input/data/training/\",\"val_data_dir\":\"/opt/ml/input/data/evaluation/\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=DeepFM-hvd-tfrecord-vectorized-map.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_mpi_custom_mpi_options\":\"-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":4}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"evaluation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"ShardedByS3Key\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"evaluation\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=DeepFM-hvd-tfrecord-vectorized-map\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-22-11-13-17-852/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":4},\"channel_input_dirs\":{\"evaluation\":\"/opt/ml/input/data/evaluation\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":1024,\"deep_layers\":\"128,64,32\",\"enable_s3_shard\":true,\"evaluation_channel_name\":\"evaluation\",\"feature_size\":117581,\"field_size\":39,\"log_steps\":10,\"model_dir\":\"/opt/ml/model\",\"num_epochs\":10,\"perform_shuffle\":0,\"pipe_mode\":0,\"servable_model_dir\":\"/opt/ml/model\",\"training_channel_name\":\"training\",\"training_data_dir\":\"/opt/ml/input/data/training/\",\"val_data_dir\":\"/opt/ml/input/data/evaluation/\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"evaluation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"ShardedByS3Key\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-scriptmode-deepfm-2021-02-22-11-13-17-852\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-169088282855/tf-scriptmode-deepfm-2021-02-22-11-13-17-852/source/sourcedir.tar.gz\",\"module_name\":\"DeepFM-hvd-tfrecord-vectorized-map\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"DeepFM-hvd-tfrecord-vectorized-map.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"1024\",\"--deep_layers\",\"128,64,32\",\"--enable_s3_shard\",\"True\",\"--evaluation_channel_name\",\"evaluation\",\"--feature_size\",\"117581\",\"--field_size\",\"39\",\"--log_steps\",\"10\",\"--model_dir\",\"/opt/ml/model\",\"--num_epochs\",\"10\",\"--perform_shuffle\",\"0\",\"--pipe_mode\",\"0\",\"--servable_model_dir\",\"/opt/ml/model\",\"--training_channel_name\",\"training\",\"--training_data_dir\",\"/opt/ml/input/data/training/\",\"--val_data_dir\",\"/opt/ml/input/data/evaluation/\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_EVALUATION=/opt/ml/input/data/evaluation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=1024\u001b[0m\n",
      "\u001b[34mSM_HP_VAL_DATA_DIR=/opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34mSM_HP_LOG_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_FIELD_SIZE=39\u001b[0m\n",
      "\u001b[34mSM_HP_DEEP_LAYERS=128,64,32\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_CHANNEL_NAME=training\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_DATA_DIR=/opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34mSM_HP_PERFORM_SHUFFLE=0\u001b[0m\n",
      "\u001b[34mSM_HP_EVALUATION_CHANNEL_NAME=evaluation\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURE_SIZE=117581\u001b[0m\n",
      "\u001b[34mSM_HP_PIPE_MODE=0\u001b[0m\n",
      "\u001b[34mSM_HP_SERVABLE_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_ENABLE_S3_SHARD=true\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:4 -np 4 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to socket -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/usr/local/lib/python3.6/dist-packages/gethostname.cpython-36m-x86_64-linux-gnu.so -verbose -x OMPI_MCA_btl_vader_single_copy_mechanism=none -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_EVALUATION -x SM_CHANNEL_TRAINING -x SM_HP_BATCH_SIZE -x SM_HP_VAL_DATA_DIR -x SM_HP_LOG_STEPS -x SM_HP_FIELD_SIZE -x SM_HP_DEEP_LAYERS -x SM_HP_TRAINING_CHANNEL_NAME -x SM_HP_TRAINING_DATA_DIR -x SM_HP_PERFORM_SHUFFLE -x SM_HP_EVALUATION_CHANNEL_NAME -x SM_HP_FEATURE_SIZE -x SM_HP_PIPE_MODE -x SM_HP_SERVABLE_MODEL_DIR -x SM_HP_MODEL_DIR -x SM_HP_ENABLE_S3_SHARD -x SM_HP_NUM_EPOCHS -x PYTHONPATH /usr/bin/python3 -m mpi4py DeepFM-hvd-tfrecord-vectorized-map.py --batch_size 1024 --deep_layers 128,64,32 --enable_s3_shard True --evaluation_channel_name evaluation --feature_size 117581 --field_size 39 --log_steps 10 --model_dir /opt/ml/model --num_epochs 10 --perform_shuffle 0 --pipe_mode 0 --servable_model_dir /opt/ml/model --training_channel_name training --training_data_dir /opt/ml/input/data/training/ --val_data_dir /opt/ml/input/data/evaluation/\n",
      "\n",
      "\n",
      " Data for JOB [56115,1] offset 0 Total slots allocated 4\n",
      "\n",
      " ========================   JOB MAP   ========================\n",
      "\n",
      " Data for node: ip-10-0-198-41#011Num slots: 4#011Max slots: 0#011Num procs: 4\n",
      " #011Process OMPI jobid: [56115,1] App: 0 Process rank: 0 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [56115,1] App: 0 Process rank: 1 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [56115,1] App: 0 Process rank: 2 Bound: UNBOUND\n",
      " #011Process OMPI jobid: [56115,1] App: 0 Process rank: 3 Bound: UNBOUND\n",
      "\n",
      " =============================================================\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mWARNING: Open MPI tried to bind a process but failed.  This is a\u001b[0m\n",
      "\u001b[34mwarning only; your job will continue, though performance may\u001b[0m\n",
      "\u001b[34mbe degraded.\n",
      "\n",
      "  Local host:        ip-10-0-198-41\n",
      "  Application name:  /usr/bin/python3\n",
      "  Error message:     failed to bind memory\n",
      "  Location:          rtc_hwloc.c:447\n",
      "\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:440: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:440: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:440: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:440: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:440: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:440: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:441: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:441: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:441: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:440: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:440: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:441: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/']\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:['DeepFM-hvd-tfrecord-vectorized-map.py', '--batch_size', '1024', '--deep_layers', '128,64,32', '--enable_s3_shard', 'True', '--evaluation_channel_name', 'evaluation', '--feature_size', '117581', '--field_size', '39', '--log_steps', '10', '--model_dir', '/opt/ml/model', '--num_epochs', '10', '--perform_shuffle', '0', '--pipe_mode', '0', '--servable_model_dir', '/opt/ml/model', '--training_channel_name', 'training', '--training_data_dir', '/opt/ml/input/data/training/', '--val_data_dir', '/opt/ml/input/data/evaluation/']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:task_type  train\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:model_dir  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:training_data_dir  /opt/ml/input/data/training/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:val_data_dir  /opt/ml/input/data/evaluation/\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:num_epochs  10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:feature_size  117581\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:field_size  39\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:embedding_size  32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_size  1024\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:deep_layers  128,64,32\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:dropout  0.5,0.5,0.5\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:loss_type  log_loss\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:optimizer  Adam\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:learning_rate  0.0005\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_norm_decay  0.9\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_norm  False\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:l2_reg  0.0001\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:tr_files: ['/opt/ml/input/data/training/data-2/train.tfrecords', '/opt/ml/input/data/training/data-4/train.tfrecords', '/opt/ml/input/data/training/data-1/train.tfrecords', '/opt/ml/input/data/training/data-3/train.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:va_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:te_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:tr_files: ['/opt/ml/input/data/training/data-1/train.tfrecords', '/opt/ml/input/data/training/data-2/train.tfrecords', '/opt/ml/input/data/training/data-4/train.tfrecords', '/opt/ml/input/data/training/data-3/train.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:va_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:te_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:358: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.232657 139842694027072 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:358: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:358: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.232923 140294389569344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:358: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:current horovod rank is  2\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:current horovod rank is  1\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:tr_files: ['/opt/ml/input/data/training/data-3/train.tfrecords', '/opt/ml/input/data/training/data-4/train.tfrecords', '/opt/ml/input/data/training/data-2/train.tfrecords', '/opt/ml/input/data/training/data-1/train.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:va_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:te_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:tr_files: ['/opt/ml/input/data/training/data-4/train.tfrecords', '/opt/ml/input/data/training/data-3/train.tfrecords', '/opt/ml/input/data/training/data-2/train.tfrecords', '/opt/ml/input/data/training/data-1/train.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:va_files: ['/opt/ml/input/data/evaluation/val.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:te_files: ['/opt/ml/input/data/evaluation/test.tfrecords']\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:358: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:358: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.233520 139830347523904 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:358: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.233618 139627143640896 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:358: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:current horovod rank is  0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:current horovod rank is  3\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:input model dir is  /opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:host is  ['algo-1']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:current host is  algo-1\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmprmcycxr7\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.233788 140294389569344 estimator.py:1821] Using temporary folder as model directory: /tmp/tmprmcycxr7\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpl45zo011\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.233764 139842694027072 estimator.py:1821] Using temporary folder as model directory: /tmp/tmpl45zo011\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmprmcycxr7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  visible_device_list: \"1\"\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f983647df98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 11:17:10.234509 140294389569344 estimator.py:212] Using config: {'_model_dir': '/tmp/tmprmcycxr7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  visible_device_list: \"1\"\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f983647df98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpl45zo011', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  visible_device_list: \"2\"\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2f1d8d3f98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 11:17:10.234694 139842694027072 estimator.py:212] Using config: {'_model_dir': '/tmp/tmpl45zo011', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  visible_device_list: \"2\"\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2f1d8d3f98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpym4d_c77\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.234388 139627143640896 estimator.py:1821] Using temporary folder as model directory: /tmp/tmpym4d_c77\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:channel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:last channel name training\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:channel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:last channel name training\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Using config: {'_model_dir': '/opt/ml/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  visible_device_list: \"0\"\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2c3da48d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 11:17:10.234473 139830347523904 estimator.py:212] Using config: {'_model_dir': '/opt/ml/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  visible_device_list: \"0\"\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2c3da48d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpym4d_c77', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  visible_device_list: \"3\"\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efced3f6f98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 11:17:10.235155 139627143640896 estimator.py:212] Using config: {'_model_dir': '/tmp/tmpym4d_c77', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  allow_growth: true\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  visible_device_list: \"3\"\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:}\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efced3f6f98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:channel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:last channel name training\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:channel name ['evaluation', 'training']\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:first channel evaluation\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:last channel name training\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.340745 139830347523904 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.340723 140294389569344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.340728 139627143640896 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.341027 139842694027072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.421453 139842694027072 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.421600 139830347523904 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.421957 139830347523904 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.421901 139842694027072 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.421946 139627143640896 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.422277 139627143640896 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.422296 140294389569344 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.422648 140294389569344 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:batch_examples first dimension(batch size) is  ()\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:batch_examples first dimension(batch size) is  ()\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:batch_examples first dimension(batch size) is  ()\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:batch_examples first dimension(batch size) is  ()\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:136: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:136: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.526775 139842694027072 deprecation.py:323] From DeepFM-hvd-tfrecord-vectorized-map.py:136: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:136: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.526827 139830347523904 deprecation.py:323] From DeepFM-hvd-tfrecord-vectorized-map.py:136: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.526853 139627143640896 deprecation.py:323] From DeepFM-hvd-tfrecord-vectorized-map.py:136: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:136: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.528229 140294389569344 deprecation.py:323] From DeepFM-hvd-tfrecord-vectorized-map.py:136: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 11:17:10.543663 139842694027072 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 11:17:10.543660 139627143640896 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 11:17:10.543809 139830347523904 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.543876 139842694027072 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.543876 139627143640896 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.544025 139830347523904 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 11:17:10.545852 140294389569344 estimator.py:1148] Calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.546087 140294389569344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:158: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.563263 139627143640896 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.563531 139842694027072 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.563698 139830347523904 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.566467 140294389569344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:169: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.578275 139842694027072 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.578291 139627143640896 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.578488 139830347523904 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.579585 139627143640896 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.579650 139842694027072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.579831 139830347523904 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.581857 140294389569344 lazy_loader.py:50] \u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:The TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:For more information, please see:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/addons\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:If you depend on functionality not listed there, please file an issue.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.583205 140294389569344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `layer.__call__` method instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.596000 139627143640896 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.596458 139830347523904 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.596511 139842694027072 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.600623 140294389569344 deprecation.py:506] From DeepFM-hvd-tfrecord-vectorized-map.py:210: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.674339 139627143640896 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.674945 139842694027072 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.675816 139830347523904 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.676742 139627143640896 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.677610 139842694027072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.678316 139830347523904 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.683069 140294389569344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:227: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.685605 140294389569344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Use tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.686139 139627143640896 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.687436 139842694027072 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.687820 139830347523904 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.695539 140294389569344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:242: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.752115 139627143640896 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.753484 139842694027072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.754156 139830347523904 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.764601 140294389569344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Instructions for updating:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.786266 139627143640896 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:W0222 11:17:10.786481 139627143640896 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.788060 139842694027072 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:W0222 11:17:10.788332 139842694027072 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.788834 139830347523904 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:W0222 11:17:10.789062 139830347523904 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.800782 140294389569344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:253: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:W0222 11:17:10.801012 140294389569344 module_wrapper.py:139] From DeepFM-hvd-tfrecord-vectorized-map.py:263: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 11:17:11.164073 139627143640896 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 11:17:11.165452 139627143640896 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 11:17:11.165837 139830347523904 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 11:17:11.167184 139830347523904 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 11:17:11.175501 139842694027072 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 11:17:11.176845 139842694027072 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 11:17:11.185976 140294389569344 estimator.py:1150] Done calling model_fn.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 11:17:11.187434 140294389569344 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 11:17:11.447256 139627143640896 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 11:17:11.450149 139830347523904 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 11:17:11.452928 139842694027072 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Graph was finalized.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 11:17:11.479601 140294389569344 monitored_session.py:240] Graph was finalized.\u001b[0m\n",
      "\u001b[34m[ip-10-0-198-41.us-west-2.compute.internal:00084] 3 more processes have sent help message help-orte-odls-default.txt / memory not bound\u001b[0m\n",
      "\u001b[34m[ip-10-0-198-41.us-west-2.compute.internal:00084] Set MCA parameter \"orte_base_help_aggregate\" to 0 to see all help / error messages\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 11:17:14.429491 139627143640896 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 11:17:14.433466 140294389569344 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 11:17:14.454287 139627143640896 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 11:17:14.457450 140294389569344 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 11:17:14.492963 139842694027072 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 11:17:14.498416 139830347523904 session_manager.py:500] Running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 11:17:14.517270 139842694027072 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 11:17:14.523003 139830347523904 session_manager.py:502] Done running local_init_op.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmprmcycxr7/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:I0222 11:17:14.940139 140294389569344 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmprmcycxr7/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpym4d_c77/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:I0222 11:17:14.958619 139627143640896 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmpym4d_c77/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpl45zo011/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:I0222 11:17:14.989851 139842694027072 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/tmpl45zo011/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Saving checkpoints for 0 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:I0222 11:17:15.029829 139830347523904 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /opt/ml/model/model.ckpt.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:2021-02-22 11:17:15.905276: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at iterator_ops.cc:867 : Invalid argument: Index must be between 0 and 0 (currently index = 3).\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:#011 [[{{node OptimizeDataset/ShardDataset}}]]\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:2021-02-22 11:17:15.905272: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at iterator_ops.cc:867 : Invalid argument: Index must be between 0 and 0 (currently index = 1).\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:#011 [[{{node OptimizeDataset/ShardDataset}}]]\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:2021-02-22 11:17:15.910893: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at iterator_ops.cc:867 : Invalid argument: Index must be between 0 and 0 (currently index = 2).\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:#011 [[{{node OptimizeDataset/ShardDataset}}]]\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    return fn(*args)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    return fn(*args)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    target_list, run_metadata)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    target_list, run_metadata)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    run_metadata)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:tensorflow.python.framework.errors_impl.InvalidArgumentError: [_Derived_]Index must be between 0 and 0 (currently index = 3).\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:#011 [[{{node OptimizeDataset/ShardDataset}}]]\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:#011 [[OneShotIterator]]\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:During handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    run_metadata)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:tensorflow.python.framework.errors_impl.InvalidArgumentError: [_Derived_]Index must be between 0 and 0 (currently index = 1).\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:#011 [[{{node OptimizeDataset/ShardDataset}}]]\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:#011 [[OneShotIterator]]\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:During handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    \"__main__\", mod_spec)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    \"__main__\", mod_spec)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    exec(code, run_globals)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/__main__.py\", line 7, in <module>\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    exec(code, run_globals)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/__main__.py\", line 7, in <module>\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    main()\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/run.py\", line 196, in main\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    main()\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/run.py\", line 196, in main\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    run_command_line(args)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/run.py\", line 47, in run_command_line\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    run_command_line(args)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/run.py\", line 47, in run_command_line\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    run_path(sys.argv[0], run_name='__main__')\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 263, in run_path\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    run_path(sys.argv[0], run_name='__main__')\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 263, in run_path\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    pkg_name=pkg_name, script_name=fname)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 96, in _run_module_code\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    pkg_name=pkg_name, script_name=fname)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 96, in _run_module_code\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    mod_name, mod_spec, pkg_name, script_name)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    mod_name, mod_spec, pkg_name, script_name)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    exec(code, run_globals)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"DeepFM-hvd-tfrecord-vectorized-map.py\", line 441, in <module>\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    exec(code, run_globals)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"DeepFM-hvd-tfrecord-vectorized-map.py\", line 441, in <module>\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    return fn(*args)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    tf.app.run()\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    tf.app.run()\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    target_list, run_metadata)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    run_metadata)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    _run_main(main, args)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    _run_main(main, args)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:tensorflow.python.framework.errors_impl.InvalidArgumentError: [_Derived_]Index must be between 0 and 0 (currently index = 2).\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:#011 [[{{node OptimizeDataset/ShardDataset}}]]\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:#011 [[OneShotIterator]]\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:During handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    sys.exit(main(argv))\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"DeepFM-hvd-tfrecord-vectorized-map.py\", line 397, in main\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    sys.exit(main(argv))\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"DeepFM-hvd-tfrecord-vectorized-map.py\", line 397, in main\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    \"__main__\", mod_spec)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    exec(code, run_globals)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/__main__.py\", line 7, in <module>\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    main()\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/run.py\", line 196, in main\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    run_command_line(args)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/run.py\", line 47, in run_command_line\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    DeepFM.train(input_fn=lambda: input_fn(tr_files, num_epochs=1, batch_size=FLAGS.batch_size), hooks=[bcast_hook])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/smdebug.py\", line 57, in run\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    DeepFM.train(input_fn=lambda: input_fn(tr_files, num_epochs=1, batch_size=FLAGS.batch_size), hooks=[bcast_hook])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/smdebug.py\", line 57, in run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    run_path(sys.argv[0], run_name='__main__')\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 263, in run_path\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    pkg_name=pkg_name, script_name=fname)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 96, in _run_module_code\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    mod_name, mod_spec, pkg_name, script_name)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    exec(code, run_globals)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"DeepFM-hvd-tfrecord-vectorized-map.py\", line 441, in <module>\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    return_value = function(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    return_value = function(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    tf.app.run()\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    _run_main(main, args)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    sys.exit(main(argv))\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"DeepFM-hvd-tfrecord-vectorized-map.py\", line 397, in main\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    loss = self._train_model(input_fn, hooks, saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    loss = self._train_model(input_fn, hooks, saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    DeepFM.train(input_fn=lambda: input_fn(tr_files, num_epochs=1, batch_size=FLAGS.batch_size), hooks=[bcast_hook])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/smdebug.py\", line 57, in run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    return_value = function(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    return self._train_model_default(input_fn, hooks, saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    return self._train_model_default(input_fn, hooks, saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    loss = self._train_model(input_fn, hooks, saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    return self._train_model_default(input_fn, hooks, saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 760, in run\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 760, in run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 760, in run\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    run_metadata=run_metadata)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1265, in run\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    run_metadata=run_metadata)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1265, in run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    run_metadata=run_metadata)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1265, in run\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    run_metadata=run_metadata)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1366, in run\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    run_metadata=run_metadata)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1366, in run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    run_metadata=run_metadata)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1366, in run\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    raise six.reraise(*original_exc_info)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 703, in reraise\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    raise six.reraise(*original_exc_info)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 703, in reraise\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    raise six.reraise(*original_exc_info)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 703, in reraise\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    raise value\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1351, in run\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    raise value\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1351, in run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    raise value\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1351, in run\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    return self._sess.run(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1424, in run\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    return self._sess.run(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1424, in run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    return self._sess.run(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1424, in run\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    run_metadata=run_metadata)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1182, in run\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    run_metadata=run_metadata)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1182, in run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    run_metadata=run_metadata)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1182, in run\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    return self._sess.run(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    return self._sess.run(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    return self._sess.run(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    run_metadata_ptr)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    run_metadata_ptr)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    run_metadata_ptr)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    feed_dict_tensor, options, run_metadata)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    feed_dict_tensor, options, run_metadata)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    feed_dict_tensor, options, run_metadata)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    run_metadata)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    run_metadata)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    run_metadata)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:    raise type(e)(node_def, op, message)\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:tensorflow.python.framework.errors_impl.InvalidArgumentError: [_Derived_]Index must be between 0 and 0 (currently index = 3).\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:#011 [[{{node OptimizeDataset/ShardDataset}}]]\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:#011 [[OneShotIterator]]\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:    raise type(e)(node_def, op, message)\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:tensorflow.python.framework.errors_impl.InvalidArgumentError: [_Derived_]Index must be between 0 and 0 (currently index = 1).\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:#011 [[{{node OptimizeDataset/ShardDataset}}]]\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:#011 [[OneShotIterator]]\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:    raise type(e)(node_def, op, message)\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:tensorflow.python.framework.errors_impl.InvalidArgumentError: [_Derived_]Index must be between 0 and 0 (currently index = 2).\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:#011 [[{{node OptimizeDataset/ShardDataset}}]]\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:#011 [[OneShotIterator]]\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 11:17:15.961921: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at mpi_ops.cc:302 : Unknown: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 11:17:15.963016: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at mpi_ops.cc:302 : Unknown: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 11:17:15.963091: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at mpi_ops.cc:302 : Unknown: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 11:17:15.964548: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at mpi_ops.cc:302 : Unknown: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 11:17:15.964615: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at mpi_ops.cc:302 : Unknown: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 11:17:15.965380: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at mpi_ops.cc:302 : Unknown: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 11:17:15.965538: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at mpi_ops.cc:302 : Unknown: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 11:17:15.965679: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at mpi_ops.cc:302 : Unknown: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 11:17:15.965816: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at mpi_ops.cc:302 : Unknown: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 11:17:15.965901: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at mpi_ops.cc:302 : Unknown: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 11:17:15.965994: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at mpi_ops.cc:302 : Unknown: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-02-22 11:17:15.988698: W tensorflow/core/kernels/data/cache_dataset_ops.cc:824] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    return fn(*args)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    target_list, run_metadata)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    run_metadata)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:tensorflow.python.framework.errors_impl.UnknownError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:#011 [[{{node DistributedAdamOptimizer_Allreduce/HorovodAllreduce_gradients_Deep_part_deep_out_BiasAdd_grad_tuple_control_dependency_1_0}}]]\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:During handling of the above exception, another exception occurred:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Traceback (most recent call last):\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    \"__main__\", mod_spec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    exec(code, run_globals)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/__main__.py\", line 7, in <module>\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    main()\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/run.py\", line 196, in main\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    run_command_line(args)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/run.py\", line 47, in run_command_line\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    run_path(sys.argv[0], run_name='__main__')\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 263, in run_path\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    pkg_name=pkg_name, script_name=fname)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 96, in _run_module_code\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    mod_name, mod_spec, pkg_name, script_name)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    exec(code, run_globals)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"DeepFM-hvd-tfrecord-vectorized-map.py\", line 441, in <module>\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    tf.app.run()\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    _run_main(main, args)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    sys.exit(main(argv))\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"DeepFM-hvd-tfrecord-vectorized-map.py\", line 397, in main\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    DeepFM.train(input_fn=lambda: input_fn(tr_files, num_epochs=1, batch_size=FLAGS.batch_size), hooks=[bcast_hook])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/smdebug.py\", line 57, in run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    return_value = function(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    loss = self._train_model(input_fn, hooks, saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    return self._train_model_default(input_fn, hooks, saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 760, in run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    run_metadata=run_metadata)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1265, in run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    run_metadata=run_metadata)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1366, in run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    raise six.reraise(*original_exc_info)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 703, in reraise\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    raise value\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1351, in run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    return self._sess.run(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1424, in run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    run_metadata=run_metadata)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1182, in run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    return self._sess.run(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    run_metadata_ptr)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    feed_dict_tensor, options, run_metadata)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    run_metadata)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    raise type(e)(node_def, op, message)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:tensorflow.python.framework.errors_impl.UnknownError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:#011 [[node DistributedAdamOptimizer_Allreduce/HorovodAllreduce_gradients_Deep_part_deep_out_BiasAdd_grad_tuple_control_dependency_1_0 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:Original stack trace for 'DistributedAdamOptimizer_Allreduce/HorovodAllreduce_gradients_Deep_part_deep_out_BiasAdd_grad_tuple_control_dependency_1_0':\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    \"__main__\", mod_spec)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    exec(code, run_globals)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/__main__.py\", line 7, in <module>\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    main()\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/run.py\", line 196, in main\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    run_command_line(args)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/mpi4py/run.py\", line 47, in run_command_line\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    run_path(sys.argv[0], run_name='__main__')\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 263, in run_path\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    pkg_name=pkg_name, script_name=fname)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 96, in _run_module_code\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    mod_name, mod_spec, pkg_name, script_name)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    exec(code, run_globals)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"DeepFM-hvd-tfrecord-vectorized-map.py\", line 441, in <module>\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    tf.app.run()\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    _run_main(main, args)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    sys.exit(main(argv))\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"DeepFM-hvd-tfrecord-vectorized-map.py\", line 397, in main\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    DeepFM.train(input_fn=lambda: input_fn(tr_files, num_epochs=1, batch_size=FLAGS.batch_size), hooks=[bcast_hook])\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/smdebug.py\", line 57, in run\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    return_value = function(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    loss = self._train_model(input_fn, hooks, saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    return self._train_model_default(input_fn, hooks, saving_listeners)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1191, in _train_model_default\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    features, labels, ModeKeys.TRAIN, self.config)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1149, in _call_model_fn\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    model_fn_results = self._model_fn(features=features, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"DeepFM-hvd-tfrecord-vectorized-map.py\", line 263, in model_fn\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/optimizer.py\", line 404, in minimize\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    grad_loss=grad_loss)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py\", line 256, in compute_gradients\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    avg_grads = self._allreduce_grads(grads)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py\", line 210, in allreduce_grads\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    for grad in grads]\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py\", line 210, in <listcomp>\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    for grad in grads]\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py\", line 80, in allreduce\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    summed_tensor_compressed = _allreduce(tensor_compressed)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/horovod/tensorflow/mpi_ops.py\", [1,0]<stderr>:line 86, in _allreduce\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    return MPI_LIB.horovod_allreduce(tensor, name=name)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"<string>\", line 80, in horovod_allreduce\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    op_def=op_def)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    return func(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    attrs, op_def, compute_device)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    op_def=op_def)\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:    self._traceback = tf_stack.extract_stack()\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mPrimary job  terminated normally, but 1 process returned\u001b[0m\n",
      "\u001b[34ma non-zero exit code. Per user-direction, the job has been aborted.\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mmpirun.real detected that one or more processes exited with non-zero status, thus causing\u001b[0m\n",
      "\u001b[34mthe job to be terminated. The first process to do so was:\n",
      "\n",
      "  Process name: [[56115,1],3]\n",
      "  Exit code:    1\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m2021-02-22 11:17:16,760 sagemaker-containers ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"mpirun --host algo-1:4 -np 4 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to socket -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/usr/local/lib/python3.6/dist-packages/gethostname.cpython-36m-x86_64-linux-gnu.so -verbose -x OMPI_MCA_btl_vader_single_copy_mechanism=none -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_EVALUATION -x SM_CHANNEL_TRAINING -x SM_HP_BATCH_SIZE -x SM_HP_VAL_DATA_DIR -x SM_HP_LOG_STEPS -x SM_HP_FIELD_SIZE -x SM_HP_DEEP_LAYERS -x SM_HP_TRAINING_CHANNEL_NAME -x SM_HP_TRAINING_DATA_DIR -x SM_HP_PERFORM_SHUFFLE -x SM_HP_EVALUATION_CHANNEL_NAME -x SM_HP_FEATURE_SIZE -x SM_HP_PIPE_MODE -x SM_HP_SERVABLE_MODEL_DIR -x SM_HP_MODEL_DIR -x SM_HP_ENABLE_S3_SHARD -x SM_HP_NUM_EPOCHS -x PYTHONPATH /usr/bin/python3 -m mpi4py DeepFM-hvd-tfrecord-vectorized-map.py --batch_size 1024 --deep_layers 128,64,32 --enable_s3_shard True --evaluation_channel_name evaluation --feature_size 117581 --field_size 39 --log_steps 10 --model_dir /opt/ml/model --num_epochs 10 --perform_shuffle 0 --pipe_mode 0 --servable_model_dir /opt/ml/model --training_channel_name training --training_data_dir /opt/ml/input/data/training/ --val_data_dir /opt/ml/input/data/evaluation/\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-02-22 11:17:44 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job tf-scriptmode-deepfm-2021-02-22-11-13-17-852: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"mpirun --host algo-1:4 -np 4 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to socket -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/usr/local/lib/python3.6/dist-packages/gethostname.cpython-36m-x86_64-linux-gnu.so -verbose -x OMPI_MCA_btl_vader_single_copy_mechanism=none -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_EVALUATION -x",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f29c8e88ed40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtraining_channel_name\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_channel_name\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mval_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1586\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1588\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1589\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3640\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3641\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3642\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3220\u001b[0m                 ),\n\u001b[1;32m   3221\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3222\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3223\u001b[0m             )\n\u001b[1;32m   3224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job tf-scriptmode-deepfm-2021-02-22-11-13-17-852: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"mpirun --host algo-1:4 -np 4 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to socket -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/usr/local/lib/python3.6/dist-packages/gethostname.cpython-36m-x86_64-linux-gnu.so -verbose -x OMPI_MCA_btl_vader_single_copy_mechanism=none -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_EVALUATION -x"
     ]
    }
   ],
   "source": [
    "#下面这个测试file mode\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/training/'\n",
    "validate_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/val/'\n",
    "\n",
    "if enable_s3_shard:\n",
    "    train_input = TrainingInput(train_s3_uri, distribution='ShardedByS3Key')\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "else :\n",
    "    train_input = TrainingInput(train_s3_uri)\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "\n",
    "inputs = {training_channel_name : train_input, evaluation_channel_name : val_input}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipe mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面用多个spot实例进行parameter server方式的分布式训练。\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow.estimator import TensorFlow\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "bucket = 'sagemaker-us-west-2-169088282855'\n",
    "checkpoint_s3_uri = 's3://{}/deepfm-checkpoint'.format(bucket) #Change to your own path if you want to save ckpt during training\n",
    "checkpoint_local_path = '/opt/ml/checkpoints'\n",
    "model_dir = '/opt/ml/model'\n",
    "output_path= 's3://{}/deepfm-2021'.format(bucket)\n",
    "\n",
    "training_channel_name = 'training'\n",
    "evaluation_channel_name = 'evaluation'\n",
    "\n",
    "train_instance_type = 'ml.p3.8xlarge'\n",
    "hvd_processes_per_host = 4\n",
    "train_instance_count= 2\n",
    "\n",
    "train_use_spot_instances = True\n",
    "enable_s3_shard = True\n",
    "\n",
    "train_max_run=36000*2\n",
    "train_max_wait = 72000 if train_use_spot_instances else None\n",
    "\n",
    "distributions = {'mpi': {\n",
    "                    'enabled': True,\n",
    "                    'processes_per_host': hvd_processes_per_host,\n",
    "                    'custom_mpi_options': '-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none'\n",
    "                        }\n",
    "                }\n",
    "\n",
    "deep_layer = '128,64,32'\n",
    "\n",
    "batch_size = 1024\n",
    "feature_size = 117581\n",
    "\n",
    "base_job_name='tf-scriptmode-deepfm'\n",
    "\n",
    "hyperparameters = {'servable_model_dir': '/opt/ml/model', 'training_data_dir': '/opt/ml/input/data/training/',\n",
    "                   'val_data_dir': '/opt/ml/input/data/evaluation/', 'log_steps': 10, 'num_epochs': 10, \n",
    "                   'field_size': 39, 'feature_size': feature_size, 'deep_layers': deep_layer,\n",
    "                   'perform_shuffle': 0, 'batch_size': batch_size, 'pipe_mode': 1, 'enable_s3_shard': enable_s3_shard,\n",
    "                   'training_channel_name': training_channel_name, 'evaluation_channel_name': evaluation_channel_name\n",
    "                  }\n",
    "\n",
    "estimator = TensorFlow(\n",
    "                       #source_dir='./',\n",
    "                       entry_point='DeepFM-hvd-tfrecord-vectorized-map.py',\n",
    "                       model_dir=model_dir,\n",
    "                       #checkpoint_s3_uri = checkpoint_s3_uri,\n",
    "                       #checkpoint_local_path = checkpoint_local_path,\n",
    "                       output_path= output_path,\n",
    "                       instance_type=train_instance_type,\n",
    "                       instance_count=train_instance_count,\n",
    "                       #volume_size = 500,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       base_job_name=base_job_name,\n",
    "                       framework_version='1.14',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True,\n",
    "                       input_mode='Pipe',\n",
    "                       distribution=distributions,\n",
    "                       use_spot_instances=train_use_spot_instances,\n",
    "                       max_wait=train_max_wait,\n",
    "                       max_run=train_max_run,\n",
    "                       debugger_hook_config =False,\n",
    "                       disable_profiler=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面这个测试pipe mode\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/training/'\n",
    "validate_s3_uri = 's3://sagemaker-us-west-2-169088282855/tf-SM-deepctr-deepfm-sample/data-tfrecord/val/'\n",
    "\n",
    "if enable_s3_shard:\n",
    "    train_input = TrainingInput(train_s3_uri, distribution='ShardedByS3Key')\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "else :\n",
    "    train_input = TrainingInput(train_s3_uri)\n",
    "    val_input = TrainingInput(validate_s3_uri)\n",
    "\n",
    "inputs = {'training':train_s3, 'training-2':train_s3, 'training-3':train_s3, 'evaluation': validate_s3}\n",
    "\n",
    "inputs = {training_channel_name : train_input, evaluation_channel_name : val_input}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
